{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ngdodd_CSE576_Quail_Finetuning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4f54db4d7daa4c02ac1002949c0e197b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_120c01c524bc489b9855fa4062d2ad4b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bb6d8dd9caf846a9866d39edc5ef256d",
              "IPY_MODEL_44b92f74e7b442d78dda15c3b5b5a2e5"
            ]
          }
        },
        "120c01c524bc489b9855fa4062d2ad4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bb6d8dd9caf846a9866d39edc5ef256d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f07b3af984cf42619cd5daf3576d3109",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1c9974509970474a900e53067a9eb57c"
          }
        },
        "44b92f74e7b442d78dda15c3b5b5a2e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_489c0d3327d34e76a4639d128684fd14",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/? [00:00&lt;00:00, 19.38 tables/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eb0b9fa97f284aaaa42b4e9cbf4bc383"
          }
        },
        "f07b3af984cf42619cd5daf3576d3109": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1c9974509970474a900e53067a9eb57c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "489c0d3327d34e76a4639d128684fd14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eb0b9fa97f284aaaa42b4e9cbf4bc383": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ngdodd/transformers/blob/master/ngdodd_CSE576_Quail_Finetuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_Y2PiDf2not"
      },
      "source": [
        "#_________________________\n",
        "# Finetune Pretrained Models for QuAIL\n",
        "\n",
        "QuAIL: http://text-machine.cs.uml.edu/lab2/projects/quail/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Sj_Y8Rm3Phq"
      },
      "source": [
        "Install forked HF transformers repo :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8klpyPsOv3hS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e30dc006-84d3-4f6e-8221-b31c420c8cd3"
      },
      "source": [
        "!rm -rf transformers/\n",
        "!git clone https://github.com/ngdodd/transformers.git\n",
        "%cd transformers\n",
        "!pip install .\n",
        "!pip install -r ./examples/requirements.txt\n",
        "!pip install pyarrow==2.0.0\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 49872, done.\u001b[K\n",
            "remote: Total 49872 (delta 0), reused 0 (delta 0), pack-reused 49872\u001b[K\n",
            "Receiving objects: 100% (49872/49872), 129.43 MiB | 22.83 MiB/s, done.\n",
            "Resolving deltas: 100% (34768/34768), done.\n",
            "Checking out files: 100% (1540/1540), done.\n",
            "/content/transformers\n",
            "Processing /content/transformers\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sentencepiece==0.1.91\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 13.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (1.18.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (3.0.12)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (3.12.4)\n",
            "Collecting tokenizers==0.9.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a5/78be1a55b2ac8d6a956f0a211d372726e2b1dd2666bb537fea9b03abd62c/tokenizers-0.9.2-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 50.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (0.8)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (20.4)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 54.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.4.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.4.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.4.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.4.0) (2020.11.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers==3.4.0) (50.3.2)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers==3.4.0) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.4.0) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.4.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.4.0) (0.17.0)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-3.4.0-cp36-none-any.whl size=1297093 sha256=ad55a8255000cbdbe73183b14ecb032b78f980cdfc60ff881b7544280b1cd92b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-pv54fvew/wheels/23/19/dd/2561a4e47240cf6b307729d58e56f8077dd0c698f5992216cf\n",
            "Successfully built transformers\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=f6e5c84c611c759a0dff3aa1bf80d61288ffd661dc04fcf9dba91649be8c1fdb\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.9.2 transformers-3.4.0\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (from -r ./examples/requirements.txt (line 1)) (2.3.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from -r ./examples/requirements.txt (line 2)) (0.22.2.post1)\n",
            "Collecting seqeval\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from -r ./examples/requirements.txt (line 4)) (5.4.8)\n",
            "Collecting sacrebleu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/c4/8e948f601a4f9609e8b2b58f31966cb13cf17b940b82aa3e767f01c42c52/sacrebleu-1.4.14-py3-none-any.whl (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 6.5MB/s \n",
            "\u001b[?25hCollecting rouge-score\n",
            "  Downloading https://files.pythonhosted.org/packages/1f/56/a81022436c08b9405a5247b71635394d44fe7e1dbedc4b28c740e09c2840/rouge_score-0.0.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tensorflow_datasets in /usr/local/lib/python3.6/dist-packages (from -r ./examples/requirements.txt (line 7)) (4.0.1)\n",
            "Collecting pytorch-lightning==1.0.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/94/e7/d9ac82471c6a6246963726a62dfbd858b81ad63de71ed9dd18fc491596c4/pytorch_lightning-1.0.4-py3-none-any.whl (554kB)\n",
            "\u001b[K     |████████████████████████████████| 563kB 16.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from -r ./examples/requirements.txt (line 9)) (3.2.2)\n",
            "Collecting git-python==1.0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/8a/de/0cc6353a45cdb1e137cffac5383097b300cc578e2e1133eeb847e23a1394/git_python-1.0.3-py2.py3-none-any.whl\n",
            "Collecting faiss-cpu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/f2/ea3c4ae49cd0d1bf21d01244025fd5cb3fb89768aecd5bfb4ef8453a0fdd/faiss_cpu-1.6.5-cp36-cp36m-manylinux2014_x86_64.whl (7.9MB)\n",
            "\u001b[K     |████████████████████████████████| 7.9MB 14.3MB/s \n",
            "\u001b[?25hCollecting streamlit\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/91/5b62c39a4e382e1c376405e73891c4426af576f507281bc2bb896ac1d028/streamlit-0.71.0-py2.py3-none-any.whl (7.4MB)\n",
            "\u001b[K     |████████████████████████████████| 7.4MB 56.2MB/s \n",
            "\u001b[?25hCollecting elasticsearch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/ba/f950bdd9164fb2bbbe5093700162234fbe61f446fe2300a8993761c132ca/elasticsearch-7.10.0-py2.py3-none-any.whl (321kB)\n",
            "\u001b[K     |████████████████████████████████| 327kB 46.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from -r ./examples/requirements.txt (line 14)) (3.2.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from -r ./examples/requirements.txt (line 15)) (1.1.4)\n",
            "Collecting datasets\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/38/0c24dce24767386123d528d27109024220db0e7a04467b658d587695241a/datasets-1.1.3-py3-none-any.whl (153kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 52.6MB/s \n",
            "\u001b[?25hCollecting fire\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/a7/0e22e70778aca01a52b9c899d9c145c6396d7b613719cd63db97ffa13f2f/fire-0.3.1.tar.gz (81kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 10.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from -r ./examples/requirements.txt (line 18)) (3.6.4)\n",
            "Collecting conllu\n",
            "  Downloading https://files.pythonhosted.org/packages/1c/20/39bf21e3a0304c874c40c9cec96e3f70d2ef4b1ada3585f7dbee91dc8c05/conllu-4.2.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from -r ./examples/requirements.txt (line 20)) (0.1.91)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 1)) (3.12.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 1)) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 1)) (1.17.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 1)) (0.10.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 1)) (0.4.2)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 1)) (1.18.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 1)) (3.3.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 1)) (1.7.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 1)) (2.23.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 1)) (0.35.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 1)) (50.3.2)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 1)) (1.33.2)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r ./examples/requirements.txt (line 2)) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r ./examples/requirements.txt (line 2)) (0.17.0)\n",
            "Collecting portalocker\n",
            "  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->-r ./examples/requirements.txt (line 7)) (0.8)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->-r ./examples/requirements.txt (line 7)) (2.3)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->-r ./examples/requirements.txt (line 7)) (1.1.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->-r ./examples/requirements.txt (line 7)) (0.1.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->-r ./examples/requirements.txt (line 7)) (4.41.1)\n",
            "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->-r ./examples/requirements.txt (line 7)) (3.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->-r ./examples/requirements.txt (line 7)) (0.16.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->-r ./examples/requirements.txt (line 7)) (0.3.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->-r ./examples/requirements.txt (line 7)) (0.25.0)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->-r ./examples/requirements.txt (line 7)) (20.3.0)\n",
            "Collecting PyYAML>=5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 59.1MB/s \n",
            "\u001b[?25hCollecting fsspec>=0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/8b/1df260f860f17cb08698170153ef7db672c497c1840dcc8613ce26a8a005/fsspec-0.8.4-py3-none-any.whl (91kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 11.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.3 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning==1.0.4->-r ./examples/requirements.txt (line 8)) (1.7.0+cu101)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r ./examples/requirements.txt (line 9)) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r ./examples/requirements.txt (line 9)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r ./examples/requirements.txt (line 9)) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r ./examples/requirements.txt (line 9)) (2.4.7)\n",
            "Collecting gitpython\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/d1/a7f8fe3df258549b303415157328bfcc63e9b11d06a7ad7a3327f3d32606/GitPython-3.1.11-py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 62.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: tornado>=5.0 in /usr/local/lib/python3.6/dist-packages (from streamlit->-r ./examples/requirements.txt (line 12)) (5.1.1)\n",
            "Requirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.6/dist-packages (from streamlit->-r ./examples/requirements.txt (line 12)) (4.1.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.6/dist-packages (from streamlit->-r ./examples/requirements.txt (line 12)) (7.1.2)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.6/dist-packages (from streamlit->-r ./examples/requirements.txt (line 12)) (0.8.1)\n",
            "Collecting validators\n",
            "  Downloading https://files.pythonhosted.org/packages/41/4a/3360ff3cf2b4a1b9721ac1fbff5f84663f41047d9874b3aa1ac82e862c44/validators-0.18.1-py3-none-any.whl\n",
            "Collecting enum-compat\n",
            "  Downloading https://files.pythonhosted.org/packages/55/ae/467bc4509246283bb59746e21a1a2f5a8aecbef56b1fa6eaca78cd438c8b/enum_compat-0.0.3-py3-none-any.whl\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from streamlit->-r ./examples/requirements.txt (line 12)) (20.4)\n",
            "Collecting blinker\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/51/e2a9f3b757eb802f61dc1f2b09c8c99f6eb01cf06416c0671253536517b6/blinker-1.4.tar.gz (111kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 62.5MB/s \n",
            "\u001b[?25hCollecting botocore>=1.13.44\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ef/d5/c0c33ca15e31062220ac5964f3492409eaf90a5cf5399503cd8264f2f8e9/botocore-1.19.25-py2.py3-none-any.whl (6.9MB)\n",
            "\u001b[K     |████████████████████████████████| 6.9MB 49.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: altair>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from streamlit->-r ./examples/requirements.txt (line 12)) (4.1.0)\n",
            "Collecting watchdog\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/10/500580a0987363a0d9e1f3dd5cb1bba94a47e19266c6ce9dfb6cdd455758/watchdog-0.10.4.tar.gz (98kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 12.8MB/s \n",
            "\u001b[?25hCollecting pydeck>=0.1.dev5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/9d/8fbf1f56cc5891e6c3295bf94fc176e9ab0a3ffdd090cc8b354ac2640f9a/pydeck-0.5.0-py2.py3-none-any.whl (4.5MB)\n",
            "\u001b[K     |████████████████████████████████| 4.5MB 58.6MB/s \n",
            "\u001b[?25hCollecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/7f/4ade91fbb684c6f28a6e56028d9f9d2de4297761850d083579779f07c0de/boto3-1.16.25-py2.py3-none-any.whl (129kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 63.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: toml in /usr/local/lib/python3.6/dist-packages (from streamlit->-r ./examples/requirements.txt (line 12)) (0.10.2)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.6/dist-packages (from streamlit->-r ./examples/requirements.txt (line 12)) (0.14.1)\n",
            "Collecting base58\n",
            "  Downloading https://files.pythonhosted.org/packages/3c/03/58572025c77b9e6027155b272a1b96298e711cd4f95c24967f7137ab0c4b/base58-2.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.6/dist-packages (from streamlit->-r ./examples/requirements.txt (line 12)) (1.5.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.6/dist-packages (from streamlit->-r ./examples/requirements.txt (line 12)) (7.0.0)\n",
            "Requirement already satisfied: urllib3<2,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from elasticsearch->-r ./examples/requirements.txt (line 13)) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from elasticsearch->-r ./examples/requirements.txt (line 13)) (2020.11.8)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->-r ./examples/requirements.txt (line 15)) (2018.9)\n",
            "Collecting xxhash\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/73/826b19f3594756cb1c6c23d2fbd8ca6a77a9cd3b650c9dec5acc85004c38/xxhash-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (242kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 65.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.6/dist-packages (from datasets->-r ./examples/requirements.txt (line 16)) (0.70.11.1)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->-r ./examples/requirements.txt (line 18)) (1.9.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->-r ./examples/requirements.txt (line 18)) (0.7.1)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->-r ./examples/requirements.txt (line 18)) (1.4.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->-r ./examples/requirements.txt (line 18)) (8.6.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r ./examples/requirements.txt (line 1)) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r ./examples/requirements.txt (line 1)) (4.6)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r ./examples/requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard->-r ./examples/requirements.txt (line 1)) (2.0.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r ./examples/requirements.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r ./examples/requirements.txt (line 1)) (2.10)\n",
            "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow_datasets->-r ./examples/requirements.txt (line 7)) (3.4.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow_datasets->-r ./examples/requirements.txt (line 7)) (1.52.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.3->pytorch-lightning==1.0.4->-r ./examples/requirements.txt (line 8)) (3.7.4.3)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from validators->streamlit->-r ./examples/requirements.txt (line 12)) (4.4.2)\n",
            "Collecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from altair>=3.2.0->streamlit->-r ./examples/requirements.txt (line 12)) (0.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from altair>=3.2.0->streamlit->-r ./examples/requirements.txt (line 12)) (2.11.2)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.6/dist-packages (from altair>=3.2.0->streamlit->-r ./examples/requirements.txt (line 12)) (2.6.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.6/dist-packages (from altair>=3.2.0->streamlit->-r ./examples/requirements.txt (line 12)) (0.11.1)\n",
            "Collecting pathtools>=0.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Requirement already satisfied: ipywidgets>=7.0.0 in /usr/local/lib/python3.6/dist-packages (from pydeck>=0.1.dev5->streamlit->-r ./examples/requirements.txt (line 12)) (7.5.1)\n",
            "Collecting ipykernel>=5.1.2; python_version >= \"3.4\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/19/c2812690d8b340987eecd2cbc18549b1d130b94c5d97fcbe49f5f8710edf/ipykernel-5.3.4-py3-none-any.whl (120kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 62.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: traitlets>=4.3.2 in /usr/local/lib/python3.6/dist-packages (from pydeck>=0.1.dev5->streamlit->-r ./examples/requirements.txt (line 12)) (4.3.3)\n",
            "Collecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 9.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->-r ./examples/requirements.txt (line 1)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r ./examples/requirements.txt (line 1)) (3.1.0)\n",
            "Collecting smmap<4,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/b0/9a/4d409a6234eb940e6a78dfdfc66156e7522262f5f2fecca07dc55915952d/smmap-3.0.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->altair>=3.2.0->streamlit->-r ./examples/requirements.txt (line 12)) (1.1.1)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r ./examples/requirements.txt (line 12)) (5.0.8)\n",
            "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.6/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r ./examples/requirements.txt (line 12)) (5.5.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r ./examples/requirements.txt (line 12)) (3.5.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit->-r ./examples/requirements.txt (line 12)) (5.3.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.3.2->pydeck>=0.1.dev5->streamlit->-r ./examples/requirements.txt (line 12)) (0.2.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r ./examples/requirements.txt (line 12)) (4.7.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r ./examples/requirements.txt (line 12)) (2.6.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r ./examples/requirements.txt (line 12)) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r ./examples/requirements.txt (line 12)) (0.8.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r ./examples/requirements.txt (line 12)) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r ./examples/requirements.txt (line 12)) (0.7.5)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r ./examples/requirements.txt (line 12)) (5.3.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit->-r ./examples/requirements.txt (line 12)) (20.0.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r ./examples/requirements.txt (line 12)) (0.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r ./examples/requirements.txt (line 12)) (0.2.5)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r ./examples/requirements.txt (line 12)) (5.6.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r ./examples/requirements.txt (line 12)) (0.9.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r ./examples/requirements.txt (line 12)) (1.5.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r ./examples/requirements.txt (line 12)) (0.8.4)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r ./examples/requirements.txt (line 12)) (0.4.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r ./examples/requirements.txt (line 12)) (1.4.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r ./examples/requirements.txt (line 12)) (3.2.1)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r ./examples/requirements.txt (line 12)) (0.6.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r ./examples/requirements.txt (line 12)) (0.5.1)\n",
            "Building wheels for collected packages: seqeval, fire, PyYAML, blinker, watchdog, pathtools\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-cp36-none-any.whl size=16171 sha256=2b528e296b89d66d9137d69c95193917d93bcecb42a7521c2362a5e91cb1f1c3\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.3.1-py2.py3-none-any.whl size=111005 sha256=7ff6a00670edab5ba80bc23a45074ccf6f50cf2b604c6942e8984e3f2a9f17d9\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/61/df/768b03527bf006b546dce284eb4249b185669e65afc5fbb2ac\n",
            "  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyYAML: filename=PyYAML-5.3.1-cp36-cp36m-linux_x86_64.whl size=44619 sha256=2e97a523da55eb19ac078aa4595ece54cd7a351a8bfd3c0deae3975d29801254\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd\n",
            "  Building wheel for blinker (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for blinker: filename=blinker-1.4-cp36-none-any.whl size=13450 sha256=4072716f661c50bc86734b35b738c7833b62d0a6d78d49438fecaa716f5835f6\n",
            "  Stored in directory: /root/.cache/pip/wheels/92/a0/00/8690a57883956a301d91cf4ec999cc0b258b01e3f548f86e89\n",
            "  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for watchdog: filename=watchdog-0.10.4-cp36-none-any.whl size=74841 sha256=0e2949104d10c5134e6f0a8b11317a930661d7b32f9435233f834e11d4c8078e\n",
            "  Stored in directory: /root/.cache/pip/wheels/9e/11/04/5160b8815b0cc7cf574bdc6d053e510169ec264c8791b4ec3a\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp36-none-any.whl size=8785 sha256=7167a4a22388f3b28f84df09219dd7ab81cecfe6e00a616a871ef964bce4caa1\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "Successfully built seqeval fire PyYAML blinker watchdog pathtools\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement ipykernel~=4.10, but you'll have ipykernel 5.3.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pytorch-lightning 1.0.4 has requirement future>=0.17.1, but you'll have future 0.16.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: botocore 1.19.25 has requirement urllib3<1.27,>=1.25.4; python_version != \"3.4\", but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datasets 1.1.3 has requirement pyarrow>=0.17.1, but you'll have pyarrow 0.14.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: seqeval, portalocker, sacrebleu, rouge-score, PyYAML, fsspec, pytorch-lightning, smmap, gitdb, gitpython, git-python, faiss-cpu, validators, enum-compat, blinker, jmespath, botocore, pathtools, watchdog, ipykernel, pydeck, s3transfer, boto3, base58, streamlit, elasticsearch, xxhash, datasets, fire, conllu\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Found existing installation: ipykernel 4.10.1\n",
            "    Uninstalling ipykernel-4.10.1:\n",
            "      Successfully uninstalled ipykernel-4.10.1\n",
            "Successfully installed PyYAML-5.3.1 base58-2.0.1 blinker-1.4 boto3-1.16.25 botocore-1.19.25 conllu-4.2.1 datasets-1.1.3 elasticsearch-7.10.0 enum-compat-0.0.3 faiss-cpu-1.6.5 fire-0.3.1 fsspec-0.8.4 git-python-1.0.3 gitdb-4.0.5 gitpython-3.1.11 ipykernel-5.3.4 jmespath-0.10.0 pathtools-0.1.2 portalocker-2.0.0 pydeck-0.5.0 pytorch-lightning-1.0.4 rouge-score-0.0.4 s3transfer-0.3.3 sacrebleu-1.4.14 seqeval-1.2.2 smmap-3.0.4 streamlit-0.71.0 validators-0.18.1 watchdog-0.10.4 xxhash-2.0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "ipykernel"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting pyarrow==2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e1/27958a70848f8f7089bff8d6ebe42519daf01f976d28b481e1bfd52c8097/pyarrow-2.0.0-cp36-cp36m-manylinux2014_x86_64.whl (17.7MB)\n",
            "\u001b[K     |████████████████████████████████| 17.7MB 219kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.6/dist-packages (from pyarrow==2.0.0) (1.18.5)\n",
            "Installing collected packages: pyarrow\n",
            "  Found existing installation: pyarrow 0.14.1\n",
            "    Uninstalling pyarrow-0.14.1:\n",
            "      Successfully uninstalled pyarrow-0.14.1\n",
            "Successfully installed pyarrow-2.0.0\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qr1BdjjG3n5i"
      },
      "source": [
        "Mount google drive for direct file access if desired."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ospdLh5k3odV"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6piL7gWD3IGu"
      },
      "source": [
        "Download project data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riWBWeaowbSU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebb4d728-9801-4a86-e132-664ace5783c0"
      },
      "source": [
        "!mkdir data\n",
        "!wget https://raw.githubusercontent.com/text-machine-lab/quail/master/quail_v1.3/json/train.jsonl -O data/train.jsonl\n",
        "!wget https://raw.githubusercontent.com/text-machine-lab/quail/master/quail_v1.3/json/dev.jsonl -O data/dev.jsonl\n",
        "!wget https://raw.githubusercontent.com/text-machine-lab/quail/master/quail_v1.3/json/challenge.jsonl -O data/challenge.jsonl\n",
        "!wget https://raw.githubusercontent.com/ngdodd/transformers/master/examples/multiple-choice/datasets/synthetic/with_sequential/synthetic_with_nei_cleaned_dev.jsonl -O data/synthetic_dev.jsonl\n",
        "!wget https://raw.githubusercontent.com/ngdodd/transformers/master/examples/multiple-choice/datasets/synthetic/with_sequential/synthetic_with_nei_cleaned_train.jsonl -O data/synthetic_train.jsonl\n",
        "!wget https://raw.githubusercontent.com/ngdodd/transformers/master/examples/multiple-choice/datasets/synthetic/without_sequential/synthetic_with_nei_without_sequential_cleaned_dev.jsonl -O data/synthetic_without_sequential_dev.jsonl\n",
        "!wget https://raw.githubusercontent.com/ngdodd/transformers/master/examples/multiple-choice/datasets/synthetic/without_sequential/synthetic_with_nei_wihtout_sequential_cleaned_train.jsonl -O data/synthetic_without_sequential_train.jsonl\n",
        "!wget https://raw.githubusercontent.com/ngdodd/transformers/60ac3314e2059cad0fa2e7f7c3d1944b870a238f/examples/multiple-choice/datasets/synthetic/with_quail/with_sequential/synthetic_with_quail_train.jsonl -O data/synthetic_with_quail_train.jsonl\n",
        "!wget https://raw.githubusercontent.com/ngdodd/transformers/master/examples/multiple-choice/datasets/synthetic/with_quail/with_sequential/synthetic_with_quail_dev.jsonl -O data/synthetic_with_quail_dev.jsonl\n",
        "!wget https://raw.githubusercontent.com/ngdodd/transformers/60ac3314e2059cad0fa2e7f7c3d1944b870a238f/examples/multiple-choice/datasets/synthetic/with_quail/without_sequential/synthetic_without_seq_with_quail_train.jsonl -O data/synthetic_without_seq_with_quail_train.jsonl\n",
        "!wget https://raw.githubusercontent.com/ngdodd/transformers/60ac3314e2059cad0fa2e7f7c3d1944b870a238f/examples/multiple-choice/datasets/synthetic/with_quail/without_sequential/synthetic_without_seq_with_quail_dev.jsonl -O data/synthetic_without_seq_with_quail_dev.jsonl\n",
        "!wget https://raw.githubusercontent.com/ngdodd/transformers/master/examples/multiple-choice/datasets/synthetic/quail_dev_key.json -O data/quail_dev_key.json\n",
        "!wget https://raw.githubusercontent.com/ngdodd/transformers/master/examples/multiple-choice/datasets/synthetic/synthetic_dev_key.json -O data/synthetic_dev_key.json\n",
        "!wget https://raw.githubusercontent.com/ngdodd/transformers/master/examples/multiple-choice/datasets/synthetic/synthetic_with_quail_dev_key.json -O data/synthetic_with_quail_dev_key.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-30 10:07:30--  https://raw.githubusercontent.com/text-machine-lab/quail/master/quail_v1.3/json/train.jsonl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 24941234 (24M) [text/plain]\n",
            "Saving to: ‘data/train.jsonl’\n",
            "\n",
            "data/train.jsonl    100%[===================>]  23.79M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-11-30 10:07:32 (196 MB/s) - ‘data/train.jsonl’ saved [24941234/24941234]\n",
            "\n",
            "--2020-11-30 10:07:32--  https://raw.githubusercontent.com/text-machine-lab/quail/master/quail_v1.3/json/dev.jsonl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5310404 (5.1M) [text/plain]\n",
            "Saving to: ‘data/dev.jsonl’\n",
            "\n",
            "data/dev.jsonl      100%[===================>]   5.06M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2020-11-30 10:07:32 (67.6 MB/s) - ‘data/dev.jsonl’ saved [5310404/5310404]\n",
            "\n",
            "--2020-11-30 10:07:32--  https://raw.githubusercontent.com/text-machine-lab/quail/master/quail_v1.3/json/challenge.jsonl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1282446 (1.2M) [text/plain]\n",
            "Saving to: ‘data/challenge.jsonl’\n",
            "\n",
            "data/challenge.json 100%[===================>]   1.22M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2020-11-30 10:07:33 (22.9 MB/s) - ‘data/challenge.jsonl’ saved [1282446/1282446]\n",
            "\n",
            "--2020-11-30 10:07:33--  https://raw.githubusercontent.com/ngdodd/transformers/master/examples/multiple-choice/datasets/synthetic/with_sequential/synthetic_with_nei_cleaned_dev.jsonl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1093154 (1.0M) [text/plain]\n",
            "Saving to: ‘data/synthetic_dev.jsonl’\n",
            "\n",
            "data/synthetic_dev. 100%[===================>]   1.04M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2020-11-30 10:07:34 (39.5 MB/s) - ‘data/synthetic_dev.jsonl’ saved [1093154/1093154]\n",
            "\n",
            "--2020-11-30 10:07:34--  https://raw.githubusercontent.com/ngdodd/transformers/master/examples/multiple-choice/datasets/synthetic/with_sequential/synthetic_with_nei_cleaned_train.jsonl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20781358 (20M) [text/plain]\n",
            "Saving to: ‘data/synthetic_train.jsonl’\n",
            "\n",
            "data/synthetic_trai 100%[===================>]  19.82M   104MB/s    in 0.2s    \n",
            "\n",
            "2020-11-30 10:07:35 (104 MB/s) - ‘data/synthetic_train.jsonl’ saved [20781358/20781358]\n",
            "\n",
            "--2020-11-30 10:07:36--  https://raw.githubusercontent.com/ngdodd/transformers/master/examples/multiple-choice/datasets/synthetic/without_sequential/synthetic_with_nei_without_sequential_cleaned_dev.jsonl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 912689 (891K) [text/plain]\n",
            "Saving to: ‘data/synthetic_without_sequential_dev.jsonl’\n",
            "\n",
            "data/synthetic_with 100%[===================>] 891.30K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2020-11-30 10:07:36 (28.7 MB/s) - ‘data/synthetic_without_sequential_dev.jsonl’ saved [912689/912689]\n",
            "\n",
            "--2020-11-30 10:07:36--  https://raw.githubusercontent.com/ngdodd/transformers/master/examples/multiple-choice/datasets/synthetic/without_sequential/synthetic_with_nei_wihtout_sequential_cleaned_train.jsonl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17249753 (16M) [text/plain]\n",
            "Saving to: ‘data/synthetic_without_sequential_train.jsonl’\n",
            "\n",
            "data/synthetic_with 100%[===================>]  16.45M  76.7MB/s    in 0.2s    \n",
            "\n",
            "2020-11-30 10:07:38 (76.7 MB/s) - ‘data/synthetic_without_sequential_train.jsonl’ saved [17249753/17249753]\n",
            "\n",
            "--2020-11-30 10:07:38--  https://raw.githubusercontent.com/ngdodd/transformers/60ac3314e2059cad0fa2e7f7c3d1944b870a238f/examples/multiple-choice/datasets/synthetic/with_quail/with_sequential/synthetic_with_quail_train.jsonl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 47592745 (45M) [text/plain]\n",
            "Saving to: ‘data/synthetic_with_quail_train.jsonl’\n",
            "\n",
            "data/synthetic_with 100%[===================>]  45.39M   142MB/s    in 0.3s    \n",
            "\n",
            "2020-11-30 10:07:41 (142 MB/s) - ‘data/synthetic_with_quail_train.jsonl’ saved [47592745/47592745]\n",
            "\n",
            "--2020-11-30 10:07:41--  https://raw.githubusercontent.com/ngdodd/transformers/master/examples/multiple-choice/datasets/synthetic/with_quail/with_sequential/synthetic_with_quail_dev.jsonl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6545718 (6.2M) [text/plain]\n",
            "Saving to: ‘data/synthetic_with_quail_dev.jsonl’\n",
            "\n",
            "data/synthetic_with 100%[===================>]   6.24M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-11-30 10:07:42 (42.3 MB/s) - ‘data/synthetic_with_quail_dev.jsonl’ saved [6545718/6545718]\n",
            "\n",
            "--2020-11-30 10:07:42--  https://raw.githubusercontent.com/ngdodd/transformers/60ac3314e2059cad0fa2e7f7c3d1944b870a238f/examples/multiple-choice/datasets/synthetic/with_quail/without_sequential/synthetic_without_seq_with_quail_train.jsonl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 43548572 (42M) [text/plain]\n",
            "Saving to: ‘data/synthetic_without_seq_with_quail_train.jsonl’\n",
            "\n",
            "data/synthetic_with 100%[===================>]  41.53M   136MB/s    in 0.3s    \n",
            "\n",
            "2020-11-30 10:07:45 (136 MB/s) - ‘data/synthetic_without_seq_with_quail_train.jsonl’ saved [43548572/43548572]\n",
            "\n",
            "--2020-11-30 10:07:45--  https://raw.githubusercontent.com/ngdodd/transformers/60ac3314e2059cad0fa2e7f7c3d1944b870a238f/examples/multiple-choice/datasets/synthetic/with_quail/without_sequential/synthetic_without_seq_with_quail_dev.jsonl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6338307 (6.0M) [text/plain]\n",
            "Saving to: ‘data/synthetic_without_seq_with_quail_dev.jsonl’\n",
            "\n",
            "data/synthetic_with 100%[===================>]   6.04M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2020-11-30 10:07:46 (72.2 MB/s) - ‘data/synthetic_without_seq_with_quail_dev.jsonl’ saved [6338307/6338307]\n",
            "\n",
            "--2020-11-30 10:07:46--  https://raw.githubusercontent.com/ngdodd/transformers/master/examples/multiple-choice/datasets/synthetic/quail_dev_key.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 37982 (37K) [text/plain]\n",
            "Saving to: ‘data/quail_dev_key.json’\n",
            "\n",
            "data/quail_dev_key. 100%[===================>]  37.09K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2020-11-30 10:07:46 (49.4 MB/s) - ‘data/quail_dev_key.json’ saved [37982/37982]\n",
            "\n",
            "--2020-11-30 10:07:46--  https://raw.githubusercontent.com/ngdodd/transformers/master/examples/multiple-choice/datasets/synthetic/synthetic_dev_key.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 617431 (603K) [text/plain]\n",
            "Saving to: ‘data/synthetic_dev_key.json’\n",
            "\n",
            "data/synthetic_dev_ 100%[===================>] 602.96K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2020-11-30 10:07:47 (19.2 MB/s) - ‘data/synthetic_dev_key.json’ saved [617431/617431]\n",
            "\n",
            "--2020-11-30 10:07:47--  https://raw.githubusercontent.com/ngdodd/transformers/master/examples/multiple-choice/datasets/synthetic/synthetic_with_quail_dev_key.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 784488 (766K) [text/plain]\n",
            "Saving to: ‘data/synthetic_with_quail_dev_key.json’\n",
            "\n",
            "data/synthetic_with 100%[===================>] 766.10K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2020-11-30 10:07:47 (19.7 MB/s) - ‘data/synthetic_with_quail_dev_key.json’ saved [784488/784488]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCv3L8Du4FnM"
      },
      "source": [
        "Initialize wandb to track and monitor the training session:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJkayK5Rl9QQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e95c4b38-d9d4-4cfd-e897-e7b38acb4c12"
      },
      "source": [
        "!pip install wandb\n",
        "import wandb\n",
        "wandb.init()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wandb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/7c/bf3cba8513f02c92fff0f0dab49846f1aa3da93c71fb4de7f34f501d15f0/wandb-0.10.11-py2.py3-none-any.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 14.8MB/s \n",
            "\u001b[?25hCollecting sentry-sdk>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/e1/3a9f8ca1009fc6a1e850801f2386e9d88b95147218cbe8c33bc4d60b3695/sentry_sdk-0.19.4-py2.py3-none-any.whl (128kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 50.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from wandb) (5.3.1)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.12.4)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: watchdog>=0.8.3 in /usr/local/lib/python3.6/dist-packages (from wandb) (0.10.4)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.23.0)\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/08/b2/ef713e0e67f6e7ec7d59aea3ee78d05b39c15930057e724cc6d362a8c3bb/configparser-5.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.1.11)\n",
            "Collecting subprocess32>=3.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 12.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.8.1)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: urllib3>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from sentry-sdk>=0.4.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from sentry-sdk>=0.4.0->wandb) (2020.11.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.12.0->wandb) (50.3.2)\n",
            "Requirement already satisfied: pathtools>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from watchdog>=0.8.3->wandb) (0.1.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.6/dist-packages (from GitPython>=1.0.0->wandb) (4.0.5)\n",
            "Requirement already satisfied: smmap<4,>=3.0.1 in /usr/local/lib/python3.6/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (3.0.4)\n",
            "Building wheels for collected packages: subprocess32\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp36-none-any.whl size=6489 sha256=dad12c840458c592252eac2c0da4102ed8389ad1ac569306fe45304b80ef1f59\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "Successfully built subprocess32\n",
            "Installing collected packages: sentry-sdk, configparser, subprocess32, docker-pycreds, shortuuid, wandb\n",
            "Successfully installed configparser-5.0.1 docker-pycreds-0.4.0 sentry-sdk-0.19.4 shortuuid-1.0.1 subprocess32-3.5.4 wandb-0.10.11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.11<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">charmed-firebrand-23</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/ngdodd/uncategorized\" target=\"_blank\">https://wandb.ai/ngdodd/uncategorized</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/ngdodd/uncategorized/runs/ot6gkhsg\" target=\"_blank\">https://wandb.ai/ngdodd/uncategorized/runs/ot6gkhsg</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20201130_100840-ot6gkhsg</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f6a1ebec048>"
            ],
            "text/html": [
              "<h1>Run(ot6gkhsg)</h1><p></p><iframe src=\"https://wandb.ai/ngdodd/uncategorized/runs/ot6gkhsg\" style=\"border:none;width:100%;height:400px\"></iframe>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feSe82xh216x"
      },
      "source": [
        "#_________________________\n",
        "\n",
        "#Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3nhFe1y4iaV"
      },
      "source": [
        "**Baseline Bert** (from QuAIL paper):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bwz9FeWI4u5K"
      },
      "source": [
        "!python ./transformers/examples/multiple-choice/run_multiple_choice.py \\\n",
        "  --task_name quail \\\n",
        "  --model_name_or_path bert-base-uncased \\\n",
        "  --do_train \\\n",
        "  --do_eval \\\n",
        "  --data_dir ./quail \\\n",
        "  --learning_rate 1e-5 \\\n",
        "  --num_train_epochs 2 \\\n",
        "  --max_seq_length 400 \\\n",
        "  --output_dir quail_out/bert_base_uncased_400 \\\n",
        "  --per_device_eval_batch_size=1 \\\n",
        "  --per_device_train_batch_size=1 \\\n",
        "  --gradient_accumulation_steps 25 \\\n",
        "  --overwrite_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o68_-n5q5l1v"
      },
      "source": [
        "**RoBERTa-Base**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOoMntNj5wEp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3bc59e8-e0d0-4221-9419-2bcdde79aa50"
      },
      "source": [
        "!python ./transformers/examples/multiple-choice/run_multiple_choice.py \\\n",
        "  --task_name quail \\\n",
        "  --model_name_or_path /content/quail_out/roberta_base \\\n",
        "  --do_train \\\n",
        "  --do_eval \\\n",
        "  --data_dir ./data \\\n",
        "  --learning_rate 1e-5 \\\n",
        "  --num_train_epochs 1 \\\n",
        "  --max_seq_length 512 \\\n",
        "  --output_dir quail_out/roberta_base \\\n",
        "  --per_device_eval_batch_size=2 \\\n",
        "  --per_device_train_batch_size=2 \\\n",
        "  --gradient_accumulation_steps 25 \\\n",
        "  --overwrite_output \\\n",
        "  --cache_dir colab_cache \\\n",
        "  --run_name roberta-base-reasoning_classification_emulation-2 \\\n",
        "  --logging_steps 25 \\\n",
        "  --quail_dev_key_path ./data/quail_dev_key.json \\\n",
        "  --custom_dev_key_path ./data/quail_dev_key.json \\\n",
        "  --eval_on_training_set \\"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-11-30 05:25:07.020188: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "11/30/2020 05:25:09 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "11/30/2020 05:25:09 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='quail_out/roberta_base', overwrite_output_dir=True, do_train=True, do_eval=True, do_predict=False, evaluate_during_training=False, evaluation_strategy=<EvaluationStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=2, per_device_eval_batch_size=2, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=25, eval_accumulation_steps=None, learning_rate=1e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=1.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Nov30_05-25-09_dc39da6ca396', logging_first_step=False, logging_steps=25, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=25, dataloader_num_workers=0, past_index=-1, run_name='roberta-base-reasoning_classification_emulation-2', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None)\n",
            "11/30/2020 05:25:13 - INFO - filelock -   Lock 140393509749032 acquired on ./data/cached_train_RobertaTokenizer_512_quail.lock\n",
            "11/30/2020 05:25:13 - INFO - utils_multiple_choice -   Loading features from cached file ./data/cached_train_RobertaTokenizer_512_quail\n",
            "11/30/2020 05:25:19 - INFO - filelock -   Lock 140393509749032 released on ./data/cached_train_RobertaTokenizer_512_quail.lock\n",
            "11/30/2020 05:25:19 - INFO - filelock -   Lock 140393509749256 acquired on ./data/cached_dev_RobertaTokenizer_512_quail.lock\n",
            "11/30/2020 05:25:19 - INFO - utils_multiple_choice -   Loading features from cached file ./data/cached_dev_RobertaTokenizer_512_quail\n",
            "11/30/2020 05:25:21 - INFO - filelock -   Lock 140393509749256 released on ./data/cached_dev_RobertaTokenizer_512_quail.lock\n",
            "roberta-base-reasoning_classification_emulation-2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mngdodd\u001b[0m (use `wandb login --relogin` to force relogin)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.11\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mroberta-base-reasoning_classification_emulation-2\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ngdodd/huggingface\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ngdodd/huggingface/runs/28fyhu5o\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /content/wandb/run-20201130_052526-28fyhu5o\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n",
            "\n",
            "{'loss': 0.22306724548339843, 'learning_rate': 8.774509803921569e-06, 'epoch': 0.12199882881124341}\n",
            " 25%|██▍       | 50/204 [05:07<15:47,  6.15s/it]\n",
            "                                                \n",
            "                                                 {'loss': 0.31156700134277343, 'learning_rate': 5.098039215686274e-06, 'epoch': 0.48799531524497364}\n",
            " 61%|██████▏   | 125/204 [12:48<08:06,  6.15s/it]\n",
            " 74%|███████▎  | 150/204 [15:22<05:31,  6.14s/it]\n",
            "{'loss': 0.410450439453125, 'learning_rate': 1.4215686274509805e-06, 'epoch': 0.8539918016787039}\n",
            "                                                 {'loss': 0.45221038818359377, 'learning_rate': 1.9607843137254904e-07, 'epoch': 0.9759906304899473}\n",
            "                                                 {'epoch': 0.9955104430997462}\n",
            "100%|██████████| 204/204 [20:54<00:00,  6.15s/it]\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/trainer.py:1174: FutureWarning: This method is deprecated, use `Trainer.is_world_process_zero()` instead.\n",
            "  warnings.warn(\"This method is deprecated, use `Trainer.is_world_process_zero()` instead.\", FutureWarning)\n",
            "11/30/2020 05:46:24 - INFO - __main__ -   *** Evaluate ***\n",
            "100%|█████████▉| 1081/1082 [01:25<00:00, 12.69it/s]11/30/2020 05:47:49 - INFO - __main__ -   \n",
            "\n",
            "\n",
            "\n",
            "***** Quail_Dev_Eval Results *****\n",
            "11/30/2020 05:47:49 - INFO - __main__ -     eval_loss = 0.749735414981842\n",
            "11/30/2020 05:47:49 - INFO - __main__ -     eval_acc = 0.7393715341959335\n",
            "11/30/2020 05:47:49 - INFO - utils_multiple_choice -   \n",
            "***** Reasoning Type Accuracies *****\n",
            "11/30/2020 05:47:49 - INFO - utils_multiple_choice -     Event_duration = 70.2928870292887\n",
            "11/30/2020 05:47:49 - INFO - utils_multiple_choice -     Entity_properties = 61.25\n",
            "11/30/2020 05:47:49 - INFO - utils_multiple_choice -     Factual = 77.91666666666667\n",
            "11/30/2020 05:47:49 - INFO - utils_multiple_choice -     Causality = 77.59336099585062\n",
            "11/30/2020 05:47:49 - INFO - utils_multiple_choice -     Character_identity = 78.00829875518673\n",
            "11/30/2020 05:47:49 - INFO - utils_multiple_choice -     Unanswerable = 100.0\n",
            "11/30/2020 05:47:49 - INFO - utils_multiple_choice -     Subsequent_state = 66.66666666666667\n",
            "11/30/2020 05:47:49 - INFO - utils_multiple_choice -     Temporal_order = 69.95884773662551\n",
            "11/30/2020 05:47:49 - INFO - utils_multiple_choice -     Belief_states = 63.75\n",
            "11/30/2020 05:47:49 - INFO - utils_multiple_choice -     Total = 73.93715341959334\n",
            "11/30/2020 05:47:49 - INFO - utils_multiple_choice -   \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "11/30/2020 05:47:49 - INFO - __main__ -   *** Evaluate ***\n",
            "6205it [08:08, 12.68it/s]11/30/2020 05:54:33 - INFO - __main__ -   \n",
            "\n",
            "\n",
            "\n",
            "***** Train_Eval Results *****\n",
            "11/30/2020 05:54:33 - INFO - __main__ -     eval_loss = 0.41615596413612366\n",
            "11/30/2020 05:54:33 - INFO - __main__ -     eval_acc = 0.8386687487800117\n",
            "Traceback (most recent call last):\n",
            "  File \"./transformers/examples/multiple-choice/run_multiple_choice.py\", line 350, in <module>\n",
            "    main()\n",
            "  File \"./transformers/examples/multiple-choice/run_multiple_choice.py\", line 340, in main\n",
            "    dev_key=data_args.custom_dev_key_path\n",
            "  File \"./transformers/examples/multiple-choice/run_multiple_choice.py\", line 168, in evaluate_model\n",
            "    save_path=os.path.join(training_args.output_dir, \"{}_results.json\".format(eval_name))\n",
            "  File \"/content/transformers/examples/multiple-choice/utils_multiple_choice.py\", line 657, in breakdown_reasoning_accuracy\n",
            "    q_type = type_lookup[id_]\n",
            "KeyError: 'f001_0'\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 878\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Program failed with code 1.  Press ctrl-c to abort syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: /content/wandb/run-20201130_052526-28fyhu5o/logs/debug.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: /content/wandb/run-20201130_052526-28fyhu5o/logs/debug-internal.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                  _step 204\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                               _runtime 1747\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                             _timestamp 1606715673\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                             train/loss 0.45221\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                    train/learning_rate 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            train/epoch 0.99551\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                       train/total_flos 15622880749977600\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ▁▂▃▄▄▅▆▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ▁▂▂▃▄▄▅▆▆█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ▁▂▂▃▄▄▅▆▆█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/loss ▁▄▄▄▅▅▇█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/learning_rate █▇▆▅▄▃▂▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           train/epoch ▁▂▃▄▅▆▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      train/total_flos ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mroberta-base-reasoning_classification_emulation-2\u001b[0m: \u001b[34mhttps://wandb.ai/ngdodd/huggingface/runs/28fyhu5o\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfnEE_EhAxBq"
      },
      "source": [
        "**RoBERTa-Large**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYYWyHWHA9tZ"
      },
      "source": [
        " !python ./transformers/examples/multiple-choice/run_multiple_choice.py \\\n",
        "  --task_name quail \\\n",
        "  --model_name_or_path roberta-large \\\n",
        "  --do_train \\\n",
        "  --do_eval \\\n",
        "  --data_dir ./quail \\\n",
        "  --learning_rate 1e-5 \\\n",
        "  --num_train_epochs 2 \\\n",
        "  --max_seq_length 512 \\\n",
        "  --output_dir quail_out/roberta_large \\\n",
        "  --per_device_eval_batch_size=1 \\\n",
        "  --per_device_train_batch_size=1 \\\n",
        "  --gradient_accumulation_steps 25 \\\n",
        "  --overwrite_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ut1OjxGn4U0G"
      },
      "source": [
        "**Longformer**:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkJ-qHvK3cJX"
      },
      "source": [
        "Install longformer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WgBP7JNbt-P"
      },
      "source": [
        "pip install git+https://github.com/allenai/longformer.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROQjZ-AB9XAD"
      },
      "source": [
        "Train:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q75NAj12wT7T"
      },
      "source": [
        "!python ./transformers/examples/multiple-choice/run_multiple_choice.py \\\n",
        "  --task_name quail \\\n",
        "  --model_name_or_path allenai/longformer-base-4096 \\\n",
        "  --do_train \\\n",
        "  --do_eval \\\n",
        "  --data_dir ./quail \\\n",
        "  --learning_rate 1e-5 \\\n",
        "  --num_train_epochs 2 \\\n",
        "  --max_seq_length 650 \\\n",
        "  --output_dir quail_out/longformer_base_4096 \\\n",
        "  --per_device_eval_batch_size=1 \\\n",
        "  --per_device_train_batch_size=1 \\\n",
        "  --gradient_accumulation_steps 25 \\\n",
        "  --overwrite_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUkOXr316SFf"
      },
      "source": [
        "**RoBERTA** (using Quail dataset originally in the Swag dataset format)\n",
        "\n",
        "Note: the only thing different here is that the source dataset files used are in the Swag dataset format. Prior to the training loop, the script will parse/format, tokenize, and then cache the entire train and dev datasets into a common data structure that is used across all of the data Processors. This was done originally due to there not being a data Processor available for QuAIL in huggingface/transformers out of the box. The prior RoBERTa training block above uses the newly introduced QuAIL data Processor, and results for the two should be equivalent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iziesHgN8Fb_"
      },
      "source": [
        "Reformat Quail data into the Swag format for use with the multiple choice script's Swag data processor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAj8u_3R79CX"
      },
      "source": [
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load and process the quail train, val, and test datasets\n",
        "quail = load_dataset('quail').map(lambda e: e.update({'a':e['answers'][0], 'b':e['answers'][1], 'c':e['answers'][2], 'd':e['answers'][3]}) or e)\n",
        "\n",
        "# Convert and write quail data to swag formatted csv files\n",
        "reindex = ['context_id', 'id', 'domain', 'context', 'question', 'question_id', 'a', 'b', 'c', 'd', 'correct_answer_id']\n",
        "pd.DataFrame(list(quail['train'])).reindex(columns=reindex).to_csv('quail/train.csv')\n",
        "pd.DataFrame(list(quail['validation'])).reindex(columns=reindex).to_csv('quail/val.csv')\n",
        "pd.DataFrame(list(quail['challenge'])).reindex(columns=reindex).to_csv('quail/test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BgVWt168QJD"
      },
      "source": [
        "Train:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osH0vtb78O0M"
      },
      "source": [
        " !python ./transformers/examples/multiple-choice/run_multiple_choice.py \\\n",
        "  --task_name swag \\\n",
        "  --model_name_or_path roberta-base \\\n",
        "  --do_train \\\n",
        "  --do_eval \\\n",
        "  --data_dir ./quail \\\n",
        "  --learning_rate 1e-5 \\\n",
        "  --num_train_epochs 2 \\\n",
        "  --max_seq_length 512 \\\n",
        "  --output_dir quail_out/roberta_base_swag \\\n",
        "  --per_device_eval_batch_size=1 \\\n",
        "  --per_device_train_batch_size=1 \\\n",
        "  --gradient_accumulation_steps 25 \\\n",
        "  --overwrite_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lMbfUFk-PDm"
      },
      "source": [
        "#Results Summary\n",
        "\n",
        "Model Name | Eval Accuracy\n",
        "--- | ---\n",
        "Baseline BERT | 0.56\n",
        "Roberta | 0.65\n",
        "Longformer | 0.68"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYGXeKqXywr-"
      },
      "source": [
        "#Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1gZ5pqDasXP"
      },
      "source": [
        "Test with pre-trained model (no-finetuning)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iBySaCVy0fG"
      },
      "source": [
        "!python ./transformers/examples/multiple-choice/run_multiple_choice.py \\\n",
        "  --task_name quail \\\n",
        "  --model_name_or_path roberta-base \\\n",
        "  --do_eval \\\n",
        "  --data_dir ./quail \\\n",
        "  --learning_rate 1e-5 \\\n",
        "  --num_train_epochs 2 \\\n",
        "  --max_seq_length 512 \\\n",
        "  --output_dir quail_out/roberta_base \\\n",
        "  --per_device_eval_batch_size=1 \\\n",
        "  --per_device_train_batch_size=1 \\\n",
        "  --gradient_accumulation_steps 25 \\\n",
        "  --overwrite_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhcEY71cawGx"
      },
      "source": [
        "#Experimental"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4VysaWYa-Ia"
      },
      "source": [
        "#### Deberta for MCQ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ba8GuUObjiUb"
      },
      "source": [
        "Delete any current transformers repo and clone+install the deberta mcq branch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "He3vsc_ObAk3"
      },
      "source": [
        "!rm -rf transformers\n",
        "!git clone -b deberta-for-multiple-choice https://github.com/ngdodd/transformers.git\n",
        "%cd transformers\n",
        "!pip install .\n",
        "!pip install -r ./examples/requirements.txt\n",
        "!pip install pyarrow==2.0.0\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-9pkY-bjx2D"
      },
      "source": [
        "Train:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWR24ZMObIjD"
      },
      "source": [
        "!python ./transformers/examples/multiple-choice/run_multiple_choice.py \\\n",
        "  --task_name quail \\\n",
        "  --model_name_or_path microsoft/deberta-base \\\n",
        "  --do_train \\\n",
        "  --do_eval \\\n",
        "  --data_dir ./quail \\\n",
        "  --learning_rate 1e-5 \\\n",
        "  --num_train_epochs 2 \\\n",
        "  --max_seq_length 512 \\\n",
        "  --output_dir quail_out/deberta_base \\\n",
        "  --per_device_eval_batch_size=1 \\\n",
        "  --per_device_train_batch_size=1 \\\n",
        "  --gradient_accumulation_steps 25 \\\n",
        "  --overwrite_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPtsK56jVWy7"
      },
      "source": [
        "#### DeBERTa MCQ with Reasoning Task Labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RK9BJtteVhID"
      },
      "source": [
        "Delete any current transformers repo and clone+install the mcq-with-reasoning-type branch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uF5zH_ZBVoJ8"
      },
      "source": [
        "!rm -rf transformers\n",
        "!git clone -b mcq-with-reasoning-type https://github.com/ngdodd/transformers.git\n",
        "%cd transformers\n",
        "!pip install .\n",
        "!pip install -r ./examples/requirements.txt\n",
        "!pip install pyarrow==2.0.0\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NRfDQt2Vscm"
      },
      "source": [
        "Train:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AC9p7KZoVuTZ"
      },
      "source": [
        "!python ./transformers/examples/multiple-choice/run_multiple_choice.py \\\n",
        "  --task_name quail \\\n",
        "  --model_name_or_path microsoft/deberta-base \\\n",
        "  --do_train \\\n",
        "  --do_eval \\\n",
        "  --data_dir ./quail \\\n",
        "  --learning_rate 1e-5 \\\n",
        "  --num_train_epochs 2 \\\n",
        "  --max_seq_length 512 \\\n",
        "  --output_dir quail_out/deberta_base \\\n",
        "  --per_device_eval_batch_size=1 \\\n",
        "  --per_device_train_batch_size=1 \\\n",
        "  --gradient_accumulation_steps 25 \\\n",
        "  --overwrite_output \\\n",
        "  --with_reasoning_types"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YKkeASoLi5f"
      },
      "source": [
        "#### RoBERTa-Base MCQ with Reasoning Task Labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5I-47nimLwsh"
      },
      "source": [
        "Delete any current transformers repo and clone+install the roberta-mcq-with-reasoning-types branch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11RMMThPL1rf"
      },
      "source": [
        "!rm -rf transformers\n",
        "!git clone -b roberta-mcq-with-reasoning-types https://github.com/ngdodd/transformers.git\n",
        "%cd transformers\n",
        "!pip install .\n",
        "!pip install -r ./examples/requirements.txt\n",
        "!pip install pyarrow==2.0.0\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUxP__aUL5gT"
      },
      "source": [
        "Train:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZOaIqwyL7uf"
      },
      "source": [
        "!python ./transformers/examples/multiple-choice/run_multiple_choice.py \\\n",
        "  --task_name quail \\\n",
        "  --model_name_or_path roberta-base \\\n",
        "  --do_train \\\n",
        "  --do_eval \\\n",
        "  --data_dir ./quail \\\n",
        "  --learning_rate 1e-5 \\\n",
        "  --num_train_epochs 2 \\\n",
        "  --max_seq_length 512 \\\n",
        "  --output_dir quail_out/roberta_base \\\n",
        "  --per_device_eval_batch_size=1 \\\n",
        "  --per_device_train_batch_size=1 \\\n",
        "  --gradient_accumulation_steps 25 \\\n",
        "  --overwrite_output \\\n",
        "  --cache_dir colab_cache \\\n",
        "  --run_name roberta-swag+hellaswag+cosmos_qa \\\n",
        "  --logging_steps 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNSM-GNtnplt"
      },
      "source": [
        "## Upstream Reasoning Classification --> Downstream QA Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruHOfhLGnrZD"
      },
      "source": [
        "!rm -rf transformers/\n",
        "!git clone https://github.com/ngdodd/transformers.git\n",
        "%cd transformers\n",
        "!pip install .\n",
        "!pip install -r ./examples/requirements.txt\n",
        "!pip install pyarrow==2.0.0\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIrqYjS9oClv"
      },
      "source": [
        "Emulate perfect reasoning type classifier by prepending reasoning type to each question. This will be used to validate the approach is useful for the downstream QA task in the best possible scenario (perfect reasoning type classification). If the downstream QA task doesn't perform well on this, then the idea isn't worth pursuing further."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bxq3f4Ssn4SD"
      },
      "source": [
        "import json\n",
        "\n",
        "with open('./data/train.jsonl', 'r') as f, open('train.jsonl', 'w') as w:\n",
        "  for line in f:\n",
        "    data = json.loads(line)\n",
        "    data['question'] = \"Question type: {}. {}\".format(data['question_type'].replace('_', ' '), data['question'])\n",
        "    w.write(json.dumps(data) + '\\n')\n",
        "\n",
        "with open('./data/dev.jsonl', 'r') as f, open('dev.jsonl', 'w') as w:\n",
        "  for line in f:\n",
        "    data = json.loads(line)\n",
        "    data['question'] = \"Question type: {}. {}\".format(data['question_type'].replace('_', ' '), data['question'])\n",
        "    w.write(json.dumps(data) + '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMRTRGMqpaur"
      },
      "source": [
        "Paste the following as a new class in utils_multiple_choice.py and create a new entry corresponding to it in processors and MULTIPLE_CHOICE_TASKS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pY9Js3G0ogSx"
      },
      "source": [
        "\"\"\"\n",
        "class QuailReasoningProcessor(QuailProcessor):\n",
        "    def __init__(self):\n",
        "        self.reasoning_type_dict = {'Character_identity': 0, 'Causality': 1, 'Event_duration': 2,\n",
        "                                    'Subsequent_state': 3, 'Factual': 4, 'Belief_states': 5,\n",
        "                                    'Entity_properties': 6, 'Unanswerable':7, 'Temporal_order':8}\n",
        "    \n",
        "    def get_labels(self):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        return list(self.reasoning_type_dict.keys())\n",
        "    \n",
        "    def _create_examples(self, lines, type):\n",
        "        examples = [\n",
        "            InputExample(\n",
        "                example_id=qa_entry[\"id\"],\n",
        "                question=qa_entry[\"question\"],\n",
        "                contexts=[qa_entry[\"context\"] for _ in range(len(self.reasoning_type_dict))],\n",
        "                endings=[list(self.reasoning_type_dict.keys())[k] for k in range(len(self.reasoning_type_dict))],\n",
        "                label=qa_entry[\"question_type\"],\n",
        "            )\n",
        "            for qa_entry in [json.loads(line) for line in lines]\n",
        "        ]\n",
        "        return examples\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4naMGoZop3J1"
      },
      "source": [
        "Reinstall package with modified utils_multiple_choice.py file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "id": "EgIRXUiDp-fM",
        "outputId": "9e74a5eb-e9f6-4252-e5ae-d37dd2663f54"
      },
      "source": [
        "%cd transformers/\n",
        "!pip install .\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/transformers\n",
            "Processing /content/transformers\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (20.4)\n",
            "Requirement already satisfied: sentencepiece==0.1.91 in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (0.1.91)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (3.0.12)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (0.0.43)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (0.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (1.18.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (4.41.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (3.12.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers==0.9.2 in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (0.9.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.4.0) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.4.0) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.4.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.4.0) (0.17.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers==3.4.0) (50.3.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.4.0) (2020.11.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.4.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.4.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.4.0) (1.24.3)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-3.4.0-cp36-none-any.whl size=1297093 sha256=c8949a16448009a2e89d68e5cad9b8e48bf362c7f5deaa455aabd690bc833d37\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-2s_o7ydt/wheels/23/19/dd/2561a4e47240cf6b307729d58e56f8077dd0c698f5992216cf\n",
            "Successfully built transformers\n",
            "Installing collected packages: transformers\n",
            "  Found existing installation: transformers 3.4.0\n",
            "    Uninstalling transformers-3.4.0:\n",
            "      Successfully uninstalled transformers-3.4.0\n",
            "Successfully installed transformers-3.4.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "transformers"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmPRWt9BqLD1"
      },
      "source": [
        "Create new dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1sM4xvwqJlw",
        "outputId": "6076420e-edac-4edf-e414-0ade7c364f91"
      },
      "source": [
        "import json\n",
        "from datasets import load_dataset\n",
        "\n",
        "synthetic_with_quail_without_seq_train = load_dataset('json', data_files='./data/synthetic_without_seq_with_quail_train.jsonl')['train']\n",
        "synthetic_with_quail_without_seq_dev = load_dataset('json', data_files='./data/synthetic_without_seq_with_quail_dev.jsonl')['train']\n",
        "\n",
        "with open('./data/synthetic_without_seq_with_quail_reasoning_train.jsonl', 'w', encoding='utf-8') as w:\n",
        "    for entry in synthetic_with_quail_without_seq_train:\n",
        "        entry['correct_answer_id'] = entry['question_type']\n",
        "        w.write(json.dumps(entry) + '\\n')\n",
        "\n",
        "with open('./data/synthetic_without_seq_with_quail_reasoning_dev.jsonl', 'w', encoding='utf-8') as w:\n",
        "    for entry in synthetic_with_quail_without_seq_dev:\n",
        "        entry['correct_answer_id'] = entry['question_type']\n",
        "        w.write(json.dumps(entry) + '\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using custom data configuration default\n",
            "Reusing dataset json (/root/.cache/huggingface/datasets/json/default-75d56dec875ca6ab/0.0.0/70d89ed4db1394f028c651589fcab6d6b28dddcabbe39d3b21b4d41f9a708514)\n",
            "Using custom data configuration default\n",
            "Reusing dataset json (/root/.cache/huggingface/datasets/json/default-e6bf455afbabcf80/0.0.0/70d89ed4db1394f028c651589fcab6d6b28dddcabbe39d3b21b4d41f9a708514)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMoTU-KUs71S"
      },
      "source": [
        "Train the upstream reasoning classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPpjBQoBr24w",
        "outputId": "8c41d39a-2f43-493f-901d-dee721ef5cfa"
      },
      "source": [
        "!python ./transformers/examples/multiple-choice/run_multiple_choice.py \\\n",
        "  --task_name quail-reasoning \\\n",
        "  --model_name_or_path roberta-base \\\n",
        "  --do_train \\\n",
        "  --do_eval \\\n",
        "  --data_dir ./data \\\n",
        "  --learning_rate 1e-5 \\\n",
        "  --num_train_epochs 2 \\\n",
        "  --max_seq_length 512 \\\n",
        "  --output_dir quail_out/roberta_base \\\n",
        "  --per_device_eval_batch_size=1 \\\n",
        "  --per_device_train_batch_size=1 \\\n",
        "  --gradient_accumulation_steps 25 \\\n",
        "  --overwrite_output \\\n",
        "  --cache_dir colab_cache \\\n",
        "  --run_name roberta-base-reasoning_classification \\\n",
        "  --logging_steps 25 \\\n",
        "  --custom_training_filename synthetic_without_seq_with_quail_reasoning_train.jsonl \\\n",
        "  --custom_eval_filename synthetic_without_seq_with_quail_reasoning_dev.jsonl \\\n",
        "  --eval_on_training_set \\\n",
        "  --overwrite_cache"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-11-30 10:51:59.949551: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "11/30/2020 10:52:01 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "11/30/2020 10:52:01 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='quail_out/roberta_base', overwrite_output_dir=True, do_train=True, do_eval=True, do_predict=False, evaluate_during_training=False, evaluation_strategy=<EvaluationStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=1, per_device_eval_batch_size=1, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=25, eval_accumulation_steps=None, learning_rate=1e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=2.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Nov30_10-52-01_650e5d6ad2e4', logging_first_step=False, logging_steps=25, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=25, dataloader_num_workers=0, past_index=-1, run_name='roberta-base-reasoning_classification', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None)\n",
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForMultipleChoice: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
            "- This IS expected if you are initializing RobertaForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForMultipleChoice were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "11/30/2020 10:52:08 - INFO - filelock -   Lock 140668232594152 acquired on ./data/cached_train_RobertaTokenizer_512_quail-reasoning.lock\n",
            "11/30/2020 10:52:08 - INFO - utils_multiple_choice -   Creating features from dataset file at ./data\n",
            "LOOKING AT ./data train\n",
            "11/30/2020 10:52:09 - INFO - utils_multiple_choice -   Training examples: 32039\n",
            "convert examples to features: 0it [00:00, ?it/s]11/30/2020 10:52:09 - INFO - utils_multiple_choice -   Writing example 0 of 32039\n",
            "convert examples to features: 992it [00:10, 110.43it/s]11/30/2020 10:52:19 - INFO - utils_multiple_choice -   Writing example 1000 of 32039\n",
            "convert examples to features: 1998it [00:20, 106.48it/s]11/30/2020 10:52:29 - INFO - utils_multiple_choice -   Writing example 2000 of 32039\n",
            "convert examples to features: 2999it [00:29, 102.00it/s]11/30/2020 10:52:38 - INFO - utils_multiple_choice -   Writing example 3000 of 32039\n",
            "convert examples to features: 3996it [00:39, 115.13it/s]11/30/2020 10:52:48 - INFO - utils_multiple_choice -   Writing example 4000 of 32039\n",
            "convert examples to features: 4994it [00:48, 113.52it/s]11/30/2020 10:52:58 - INFO - utils_multiple_choice -   Writing example 5000 of 32039\n",
            "convert examples to features: 5999it [00:58, 101.35it/s]11/30/2020 10:53:07 - INFO - utils_multiple_choice -   Writing example 6000 of 32039\n",
            "convert examples to features: 6992it [01:08, 91.14it/s]11/30/2020 10:53:17 - INFO - utils_multiple_choice -   Writing example 7000 of 32039\n",
            "convert examples to features: 7990it [01:18, 99.02it/s] 11/30/2020 10:53:27 - INFO - utils_multiple_choice -   Writing example 8000 of 32039\n",
            "convert examples to features: 8998it [01:28, 104.89it/s]11/30/2020 10:53:37 - INFO - utils_multiple_choice -   Writing example 9000 of 32039\n",
            "convert examples to features: 9992it [01:37, 116.10it/s]11/30/2020 10:53:46 - INFO - utils_multiple_choice -   Writing example 10000 of 32039\n",
            "convert examples to features: 10999it [01:47, 98.38it/s]11/30/2020 10:53:56 - INFO - utils_multiple_choice -   Writing example 11000 of 32039\n",
            "convert examples to features: 11995it [01:57, 108.98it/s]11/30/2020 10:54:06 - INFO - utils_multiple_choice -   Writing example 12000 of 32039\n",
            "convert examples to features: 12992it [02:07, 110.10it/s]11/30/2020 10:54:16 - INFO - utils_multiple_choice -   Writing example 13000 of 32039\n",
            "convert examples to features: 13990it [02:16, 98.45it/s] 11/30/2020 10:54:26 - INFO - utils_multiple_choice -   Writing example 14000 of 32039\n",
            "convert examples to features: 14997it [02:27, 110.53it/s]11/30/2020 10:54:36 - INFO - utils_multiple_choice -   Writing example 15000 of 32039\n",
            "convert examples to features: 16000it [02:37, 104.79it/s]11/30/2020 10:54:46 - INFO - utils_multiple_choice -   Writing example 16000 of 32039\n",
            "convert examples to features: 16999it [02:47, 93.55it/s] 11/30/2020 10:54:56 - INFO - utils_multiple_choice -   Writing example 17000 of 32039\n",
            "convert examples to features: 17997it [02:56, 98.73it/s]11/30/2020 10:55:05 - INFO - utils_multiple_choice -   Writing example 18000 of 32039\n",
            "convert examples to features: 18991it [03:06, 110.07it/s]11/30/2020 10:55:15 - INFO - utils_multiple_choice -   Writing example 19000 of 32039\n",
            "convert examples to features: 19990it [03:15, 98.95it/s] 11/30/2020 10:55:25 - INFO - utils_multiple_choice -   Writing example 20000 of 32039\n",
            "convert examples to features: 20998it [03:25, 106.97it/s]11/30/2020 10:55:34 - INFO - utils_multiple_choice -   Writing example 21000 of 32039\n",
            "convert examples to features: 21990it [03:35, 103.59it/s]11/30/2020 10:55:44 - INFO - utils_multiple_choice -   Writing example 22000 of 32039\n",
            "convert examples to features: 22999it [03:45, 100.40it/s]11/30/2020 10:55:54 - INFO - utils_multiple_choice -   Writing example 23000 of 32039\n",
            "convert examples to features: 23997it [03:56, 99.77it/s] 11/30/2020 10:56:05 - INFO - utils_multiple_choice -   Writing example 24000 of 32039\n",
            "convert examples to features: 24992it [04:05, 107.77it/s]11/30/2020 10:56:15 - INFO - utils_multiple_choice -   Writing example 25000 of 32039\n",
            "convert examples to features: 25998it [04:15, 101.77it/s]11/30/2020 10:56:24 - INFO - utils_multiple_choice -   Writing example 26000 of 32039\n",
            "convert examples to features: 26999it [04:25, 95.41it/s]11/30/2020 10:56:34 - INFO - utils_multiple_choice -   Writing example 27000 of 32039\n",
            "convert examples to features: 27992it [04:35, 104.43it/s]11/30/2020 10:56:44 - INFO - utils_multiple_choice -   Writing example 28000 of 32039\n",
            "convert examples to features: 29000it [04:44, 100.42it/s]11/30/2020 10:56:53 - INFO - utils_multiple_choice -   Writing example 29000 of 32039\n",
            "convert examples to features: 29998it [04:54, 112.79it/s]11/30/2020 10:57:03 - INFO - utils_multiple_choice -   Writing example 30000 of 32039\n",
            "convert examples to features: 30999it [05:03, 109.68it/s]11/30/2020 10:57:12 - INFO - utils_multiple_choice -   Writing example 31000 of 32039\n",
            "convert examples to features: 31990it [05:13, 90.66it/s]11/30/2020 10:57:22 - INFO - utils_multiple_choice -   Writing example 32000 of 32039\n",
            "convert examples to features: 32039it [05:13, 102.16it/s]\n",
            "11/30/2020 10:57:22 - INFO - utils_multiple_choice -   *** Example ***\n",
            "11/30/2020 10:57:22 - INFO - utils_multiple_choice -   feature: InputFeatures(example_id='custom_9617', input_ids=[[0, 170, 95, 56, 123, 42836, 30, 10, 400, 13174, 8, 14, 817, 201, 619, 357, 4, 345, 16, 10, 778, 14, 37, 189, 45, 6008, 53, 38, 216, 127, 910, 7010, 8, 37, 16, 10, 7251, 4, 38, 216, 52, 40, 1137, 47, 14, 37, 16, 567, 124, 4, 3401, 10745, 13, 123, 8, 3392, 47, 182, 203, 4, 2, 2, 2264, 189, 28, 10, 27099, 754, 59, 1774, 17487, 35177, 1215, 8009, 1571, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 170, 95, 56, 123, 42836, 30, 10, 400, 13174, 8, 14, 817, 201, 619, 357, 4, 345, 16, 10, 778, 14, 37, 189, 45, 6008, 53, 38, 216, 127, 910, 7010, 8, 37, 16, 10, 7251, 4, 38, 216, 52, 40, 1137, 47, 14, 37, 16, 567, 124, 4, 3401, 10745, 13, 123, 8, 3392, 47, 182, 203, 4, 2, 2, 2264, 189, 28, 10, 27099, 754, 59, 1774, 17487, 8316, 687, 6948, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 170, 95, 56, 123, 42836, 30, 10, 400, 13174, 8, 14, 817, 201, 619, 357, 4, 345, 16, 10, 778, 14, 37, 189, 45, 6008, 53, 38, 216, 127, 910, 7010, 8, 37, 16, 10, 7251, 4, 38, 216, 52, 40, 1137, 47, 14, 37, 16, 567, 124, 4, 3401, 10745, 13, 123, 8, 3392, 47, 182, 203, 4, 2, 2, 2264, 189, 28, 10, 27099, 754, 59, 1774, 17487, 11373, 1215, 41218, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 170, 95, 56, 123, 42836, 30, 10, 400, 13174, 8, 14, 817, 201, 619, 357, 4, 345, 16, 10, 778, 14, 37, 189, 45, 6008, 53, 38, 216, 127, 910, 7010, 8, 37, 16, 10, 7251, 4, 38, 216, 52, 40, 1137, 47, 14, 37, 16, 567, 124, 4, 3401, 10745, 13, 123, 8, 3392, 47, 182, 203, 4, 2, 2, 2264, 189, 28, 10, 27099, 754, 59, 1774, 17487, 4052, 39022, 1215, 4897, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 170, 95, 56, 123, 42836, 30, 10, 400, 13174, 8, 14, 817, 201, 619, 357, 4, 345, 16, 10, 778, 14, 37, 189, 45, 6008, 53, 38, 216, 127, 910, 7010, 8, 37, 16, 10, 7251, 4, 38, 216, 52, 40, 1137, 47, 14, 37, 16, 567, 124, 4, 3401, 10745, 13, 123, 8, 3392, 47, 182, 203, 4, 2, 2, 2264, 189, 28, 10, 27099, 754, 59, 1774, 17487, 18454, 5564, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 170, 95, 56, 123, 42836, 30, 10, 400, 13174, 8, 14, 817, 201, 619, 357, 4, 345, 16, 10, 778, 14, 37, 189, 45, 6008, 53, 38, 216, 127, 910, 7010, 8, 37, 16, 10, 7251, 4, 38, 216, 52, 40, 1137, 47, 14, 37, 16, 567, 124, 4, 3401, 10745, 13, 123, 8, 3392, 47, 182, 203, 4, 2, 2, 2264, 189, 28, 10, 27099, 754, 59, 1774, 17487, 45731, 1215, 26947, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 170, 95, 56, 123, 42836, 30, 10, 400, 13174, 8, 14, 817, 201, 619, 357, 4, 345, 16, 10, 778, 14, 37, 189, 45, 6008, 53, 38, 216, 127, 910, 7010, 8, 37, 16, 10, 7251, 4, 38, 216, 52, 40, 1137, 47, 14, 37, 16, 567, 124, 4, 3401, 10745, 13, 123, 8, 3392, 47, 182, 203, 4, 2, 2, 2264, 189, 28, 10, 27099, 754, 59, 1774, 17487, 46718, 1215, 47276, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 170, 95, 56, 123, 42836, 30, 10, 400, 13174, 8, 14, 817, 201, 619, 357, 4, 345, 16, 10, 778, 14, 37, 189, 45, 6008, 53, 38, 216, 127, 910, 7010, 8, 37, 16, 10, 7251, 4, 38, 216, 52, 40, 1137, 47, 14, 37, 16, 567, 124, 4, 3401, 10745, 13, 123, 8, 3392, 47, 182, 203, 4, 2, 2, 2264, 189, 28, 10, 27099, 754, 59, 1774, 17487, 1890, 27740, 868, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 170, 95, 56, 123, 42836, 30, 10, 400, 13174, 8, 14, 817, 201, 619, 357, 4, 345, 16, 10, 778, 14, 37, 189, 45, 6008, 53, 38, 216, 127, 910, 7010, 8, 37, 16, 10, 7251, 4, 38, 216, 52, 40, 1137, 47, 14, 37, 16, 567, 124, 4, 3401, 10745, 13, 123, 8, 3392, 47, 182, 203, 4, 2, 2, 2264, 189, 28, 10, 27099, 754, 59, 1774, 17487, 9188, 46249, 1215, 10337, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], attention_mask=[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], token_type_ids=None, label=1)\n",
            "11/30/2020 10:57:22 - INFO - utils_multiple_choice -   *** Example ***\n",
            "11/30/2020 10:57:22 - INFO - utils_multiple_choice -   feature: InputFeatures(example_id='custom_4690', input_ids=[[0, 100, 64, 3581, 13, 10, 186, 4, 1437, 1554, 5186, 181, 19747, 10, 19489, 9, 1637, 15750, 15, 39, 7494, 4, 1437, 345, 16, 1819, 117, 936, 19, 1055, 122, 111, 960, 16, 11, 1707, 4, 1437, 22995, 2327, 39, 8413, 4, 1437, 38, 109, 45, 679, 47, 95, 362, 14, 418, 1666, 1437, 1437, 1437, 1437, 2156, 25, 114, 51, 956, 42, 418, 116, 2, 2, 13841, 429, 33, 1554, 5186, 303, 5, 1637, 15750, 17487, 35177, 1215, 8009, 1571, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 100, 64, 3581, 13, 10, 186, 4, 1437, 1554, 5186, 181, 19747, 10, 19489, 9, 1637, 15750, 15, 39, 7494, 4, 1437, 345, 16, 1819, 117, 936, 19, 1055, 122, 111, 960, 16, 11, 1707, 4, 1437, 22995, 2327, 39, 8413, 4, 1437, 38, 109, 45, 679, 47, 95, 362, 14, 418, 1666, 1437, 1437, 1437, 1437, 2156, 25, 114, 51, 956, 42, 418, 116, 2, 2, 13841, 429, 33, 1554, 5186, 303, 5, 1637, 15750, 17487, 8316, 687, 6948, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 100, 64, 3581, 13, 10, 186, 4, 1437, 1554, 5186, 181, 19747, 10, 19489, 9, 1637, 15750, 15, 39, 7494, 4, 1437, 345, 16, 1819, 117, 936, 19, 1055, 122, 111, 960, 16, 11, 1707, 4, 1437, 22995, 2327, 39, 8413, 4, 1437, 38, 109, 45, 679, 47, 95, 362, 14, 418, 1666, 1437, 1437, 1437, 1437, 2156, 25, 114, 51, 956, 42, 418, 116, 2, 2, 13841, 429, 33, 1554, 5186, 303, 5, 1637, 15750, 17487, 11373, 1215, 41218, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 100, 64, 3581, 13, 10, 186, 4, 1437, 1554, 5186, 181, 19747, 10, 19489, 9, 1637, 15750, 15, 39, 7494, 4, 1437, 345, 16, 1819, 117, 936, 19, 1055, 122, 111, 960, 16, 11, 1707, 4, 1437, 22995, 2327, 39, 8413, 4, 1437, 38, 109, 45, 679, 47, 95, 362, 14, 418, 1666, 1437, 1437, 1437, 1437, 2156, 25, 114, 51, 956, 42, 418, 116, 2, 2, 13841, 429, 33, 1554, 5186, 303, 5, 1637, 15750, 17487, 4052, 39022, 1215, 4897, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 100, 64, 3581, 13, 10, 186, 4, 1437, 1554, 5186, 181, 19747, 10, 19489, 9, 1637, 15750, 15, 39, 7494, 4, 1437, 345, 16, 1819, 117, 936, 19, 1055, 122, 111, 960, 16, 11, 1707, 4, 1437, 22995, 2327, 39, 8413, 4, 1437, 38, 109, 45, 679, 47, 95, 362, 14, 418, 1666, 1437, 1437, 1437, 1437, 2156, 25, 114, 51, 956, 42, 418, 116, 2, 2, 13841, 429, 33, 1554, 5186, 303, 5, 1637, 15750, 17487, 18454, 5564, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 100, 64, 3581, 13, 10, 186, 4, 1437, 1554, 5186, 181, 19747, 10, 19489, 9, 1637, 15750, 15, 39, 7494, 4, 1437, 345, 16, 1819, 117, 936, 19, 1055, 122, 111, 960, 16, 11, 1707, 4, 1437, 22995, 2327, 39, 8413, 4, 1437, 38, 109, 45, 679, 47, 95, 362, 14, 418, 1666, 1437, 1437, 1437, 1437, 2156, 25, 114, 51, 956, 42, 418, 116, 2, 2, 13841, 429, 33, 1554, 5186, 303, 5, 1637, 15750, 17487, 45731, 1215, 26947, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 100, 64, 3581, 13, 10, 186, 4, 1437, 1554, 5186, 181, 19747, 10, 19489, 9, 1637, 15750, 15, 39, 7494, 4, 1437, 345, 16, 1819, 117, 936, 19, 1055, 122, 111, 960, 16, 11, 1707, 4, 1437, 22995, 2327, 39, 8413, 4, 1437, 38, 109, 45, 679, 47, 95, 362, 14, 418, 1666, 1437, 1437, 1437, 1437, 2156, 25, 114, 51, 956, 42, 418, 116, 2, 2, 13841, 429, 33, 1554, 5186, 303, 5, 1637, 15750, 17487, 46718, 1215, 47276, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 100, 64, 3581, 13, 10, 186, 4, 1437, 1554, 5186, 181, 19747, 10, 19489, 9, 1637, 15750, 15, 39, 7494, 4, 1437, 345, 16, 1819, 117, 936, 19, 1055, 122, 111, 960, 16, 11, 1707, 4, 1437, 22995, 2327, 39, 8413, 4, 1437, 38, 109, 45, 679, 47, 95, 362, 14, 418, 1666, 1437, 1437, 1437, 1437, 2156, 25, 114, 51, 956, 42, 418, 116, 2, 2, 13841, 429, 33, 1554, 5186, 303, 5, 1637, 15750, 17487, 1890, 27740, 868, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 100, 64, 3581, 13, 10, 186, 4, 1437, 1554, 5186, 181, 19747, 10, 19489, 9, 1637, 15750, 15, 39, 7494, 4, 1437, 345, 16, 1819, 117, 936, 19, 1055, 122, 111, 960, 16, 11, 1707, 4, 1437, 22995, 2327, 39, 8413, 4, 1437, 38, 109, 45, 679, 47, 95, 362, 14, 418, 1666, 1437, 1437, 1437, 1437, 2156, 25, 114, 51, 956, 42, 418, 116, 2, 2, 13841, 429, 33, 1554, 5186, 303, 5, 1637, 15750, 17487, 9188, 46249, 1215, 10337, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], attention_mask=[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], token_type_ids=None, label=1)\n",
            "11/30/2020 10:57:22 - INFO - utils_multiple_choice -   Saving features into cached file ./data/cached_train_RobertaTokenizer_512_quail-reasoning\n",
            "11/30/2020 10:58:51 - INFO - filelock -   Lock 140668232594152 released on ./data/cached_train_RobertaTokenizer_512_quail-reasoning.lock\n",
            "11/30/2020 10:58:51 - INFO - filelock -   Lock 140667963441840 acquired on ./data/cached_dev_RobertaTokenizer_512_quail-reasoning.lock\n",
            "11/30/2020 10:58:51 - INFO - utils_multiple_choice -   Creating features from dataset file at ./data\n",
            "LOOKING AT ./data dev\n",
            "11/30/2020 10:58:51 - INFO - utils_multiple_choice -   Training examples: 2164\n",
            "convert examples to features: 0it [00:00, ?it/s]11/30/2020 10:58:51 - INFO - utils_multiple_choice -   Writing example 0 of 2164\n",
            "convert examples to features: 999it [00:16, 59.58it/s]11/30/2020 10:59:08 - INFO - utils_multiple_choice -   Writing example 1000 of 2164\n",
            "convert examples to features: 1999it [00:34, 55.50it/s]11/30/2020 10:59:26 - INFO - utils_multiple_choice -   Writing example 2000 of 2164\n",
            "convert examples to features: 2164it [00:40, 53.94it/s]\n",
            "11/30/2020 10:59:31 - INFO - utils_multiple_choice -   *** Example ***\n",
            "11/30/2020 10:59:31 - INFO - utils_multiple_choice -   feature: InputFeatures(example_id='f141_0', input_ids=[[0, 347, 10708, 3996, 5, 38048, 313, 1305, 39, 4334, 8588, 88, 5, 9742, 1400, 2932, 319, 8, 2999, 198, 7, 5, 526, 6, 583, 5, 124, 2797, 9, 5, 745, 4, 345, 58, 2710, 9, 490, 20063, 11, 5, 760, 6, 98, 79, 11464, 5, 2173, 21, 89, 13, 402, 97, 87, 10, 3298, 9, 8053, 8, 10, 1029, 1071, 4, 50118, 250, 23141, 24572, 10879, 62, 69, 7983, 12, 7771, 9211, 8, 79, 1481, 35158, 4, 264, 11224, 69, 5856, 561, 18412, 7, 5368, 103, 2859, 4, 20, 4117, 12, 3530, 10317, 4371, 69, 1730, 8, 32606, 6, 53, 69, 17507, 21, 11074, 160, 4, 50118, 2515, 875, 159, 5, 4385, 346, 25, 79, 36110, 198, 7, 5, 526, 9, 5, 3214, 1155, 4, 91, 581, 33, 10, 380, 885, 625, 9, 1055, 6, 79, 802, 4, 50118, 38544, 5078, 329, 368, 56, 95, 4425, 66, 9, 5, 512, 6, 77, 79, 26, 6, 22, 41541, 512, 6, 13834, 72, 50118, 113, 42903, 6, 2446, 72, 50118, 113, 100, 437, 25575, 4, 370, 300, 10, 4045, 13495, 3422, 1917, 50118, 894, 851, 69, 5, 683, 81, 4, 1405, 909, 2549, 18699, 10, 1256, 6, 664, 12, 3690, 652, 4, 20, 614, 12, 8267, 3089, 11556, 314, 410, 7, 5, 13670, 6, 6254, 9646, 69, 42529, 4, 264, 21, 674, 6958, 6, 53, 5, 239, 19728, 10317, 10944, 69, 7, 59, 195, 108, 398, 845, 20, 251, 5856, 58, 182, 2579, 4, 50118, 38544, 56, 393, 341, 10, 36289, 4, 91, 1017, 460, 802, 9, 24, 25, 34633, 2577, 4, 20, 1114, 9, 519, 2099, 19, 10, 693, 54, 1017, 57, 19, 2213, 9, 604, 222, 45, 2868, 7, 123, 4, 50118, 1708, 42, 399, 75, 2045, 101, 10, 6097, 9337, 254, 4, 264, 2551, 350, 2382, 5579, 26949, 8309, 4, 125, 9, 768, 6, 79, 938, 75, 4, 91, 1467, 79, 56, 7, 28, 95, 25, 2972, 30451, 25, 5, 1079, 9, 106, 4, 3180, 5579, 1594, 37, 5844, 75, 57, 11, 5, 1692, 9, 402, 505, 37, 429, 33, 57, 55, 87, 2882, 7, 907, 99, 79, 21, 2183, 4, 50118, 113, 2847, 6, 99, 109, 47, 224, 116, 7348, 7, 120, 24, 15, 1917, 264, 20185, 10195, 21491, 6608, 4, 50118, 894, 21, 6889, 14, 79, 56, 70, 69, 9927, 6, 8, 14, 51, 1415, 1104, 4, 50118, 113, 6179, 64, 38, 11942, 1917, 91, 44060, 23, 69, 8, 39422, 196, 4, 2, 2, 6179, 251, 21, 25575, 667, 7, 10195, 15431, 6045, 116, 35177, 1215, 8009, 1571, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 347, 10708, 3996, 5, 38048, 313, 1305, 39, 4334, 8588, 88, 5, 9742, 1400, 2932, 319, 8, 2999, 198, 7, 5, 526, 6, 583, 5, 124, 2797, 9, 5, 745, 4, 345, 58, 2710, 9, 490, 20063, 11, 5, 760, 6, 98, 79, 11464, 5, 2173, 21, 89, 13, 402, 97, 87, 10, 3298, 9, 8053, 8, 10, 1029, 1071, 4, 50118, 250, 23141, 24572, 10879, 62, 69, 7983, 12, 7771, 9211, 8, 79, 1481, 35158, 4, 264, 11224, 69, 5856, 561, 18412, 7, 5368, 103, 2859, 4, 20, 4117, 12, 3530, 10317, 4371, 69, 1730, 8, 32606, 6, 53, 69, 17507, 21, 11074, 160, 4, 50118, 2515, 875, 159, 5, 4385, 346, 25, 79, 36110, 198, 7, 5, 526, 9, 5, 3214, 1155, 4, 91, 581, 33, 10, 380, 885, 625, 9, 1055, 6, 79, 802, 4, 50118, 38544, 5078, 329, 368, 56, 95, 4425, 66, 9, 5, 512, 6, 77, 79, 26, 6, 22, 41541, 512, 6, 13834, 72, 50118, 113, 42903, 6, 2446, 72, 50118, 113, 100, 437, 25575, 4, 370, 300, 10, 4045, 13495, 3422, 1917, 50118, 894, 851, 69, 5, 683, 81, 4, 1405, 909, 2549, 18699, 10, 1256, 6, 664, 12, 3690, 652, 4, 20, 614, 12, 8267, 3089, 11556, 314, 410, 7, 5, 13670, 6, 6254, 9646, 69, 42529, 4, 264, 21, 674, 6958, 6, 53, 5, 239, 19728, 10317, 10944, 69, 7, 59, 195, 108, 398, 845, 20, 251, 5856, 58, 182, 2579, 4, 50118, 38544, 56, 393, 341, 10, 36289, 4, 91, 1017, 460, 802, 9, 24, 25, 34633, 2577, 4, 20, 1114, 9, 519, 2099, 19, 10, 693, 54, 1017, 57, 19, 2213, 9, 604, 222, 45, 2868, 7, 123, 4, 50118, 1708, 42, 399, 75, 2045, 101, 10, 6097, 9337, 254, 4, 264, 2551, 350, 2382, 5579, 26949, 8309, 4, 125, 9, 768, 6, 79, 938, 75, 4, 91, 1467, 79, 56, 7, 28, 95, 25, 2972, 30451, 25, 5, 1079, 9, 106, 4, 3180, 5579, 1594, 37, 5844, 75, 57, 11, 5, 1692, 9, 402, 505, 37, 429, 33, 57, 55, 87, 2882, 7, 907, 99, 79, 21, 2183, 4, 50118, 113, 2847, 6, 99, 109, 47, 224, 116, 7348, 7, 120, 24, 15, 1917, 264, 20185, 10195, 21491, 6608, 4, 50118, 894, 21, 6889, 14, 79, 56, 70, 69, 9927, 6, 8, 14, 51, 1415, 1104, 4, 50118, 113, 6179, 64, 38, 11942, 1917, 91, 44060, 23, 69, 8, 39422, 196, 4, 2, 2, 6179, 251, 21, 25575, 667, 7, 10195, 15431, 6045, 116, 8316, 687, 6948, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 347, 10708, 3996, 5, 38048, 313, 1305, 39, 4334, 8588, 88, 5, 9742, 1400, 2932, 319, 8, 2999, 198, 7, 5, 526, 6, 583, 5, 124, 2797, 9, 5, 745, 4, 345, 58, 2710, 9, 490, 20063, 11, 5, 760, 6, 98, 79, 11464, 5, 2173, 21, 89, 13, 402, 97, 87, 10, 3298, 9, 8053, 8, 10, 1029, 1071, 4, 50118, 250, 23141, 24572, 10879, 62, 69, 7983, 12, 7771, 9211, 8, 79, 1481, 35158, 4, 264, 11224, 69, 5856, 561, 18412, 7, 5368, 103, 2859, 4, 20, 4117, 12, 3530, 10317, 4371, 69, 1730, 8, 32606, 6, 53, 69, 17507, 21, 11074, 160, 4, 50118, 2515, 875, 159, 5, 4385, 346, 25, 79, 36110, 198, 7, 5, 526, 9, 5, 3214, 1155, 4, 91, 581, 33, 10, 380, 885, 625, 9, 1055, 6, 79, 802, 4, 50118, 38544, 5078, 329, 368, 56, 95, 4425, 66, 9, 5, 512, 6, 77, 79, 26, 6, 22, 41541, 512, 6, 13834, 72, 50118, 113, 42903, 6, 2446, 72, 50118, 113, 100, 437, 25575, 4, 370, 300, 10, 4045, 13495, 3422, 1917, 50118, 894, 851, 69, 5, 683, 81, 4, 1405, 909, 2549, 18699, 10, 1256, 6, 664, 12, 3690, 652, 4, 20, 614, 12, 8267, 3089, 11556, 314, 410, 7, 5, 13670, 6, 6254, 9646, 69, 42529, 4, 264, 21, 674, 6958, 6, 53, 5, 239, 19728, 10317, 10944, 69, 7, 59, 195, 108, 398, 845, 20, 251, 5856, 58, 182, 2579, 4, 50118, 38544, 56, 393, 341, 10, 36289, 4, 91, 1017, 460, 802, 9, 24, 25, 34633, 2577, 4, 20, 1114, 9, 519, 2099, 19, 10, 693, 54, 1017, 57, 19, 2213, 9, 604, 222, 45, 2868, 7, 123, 4, 50118, 1708, 42, 399, 75, 2045, 101, 10, 6097, 9337, 254, 4, 264, 2551, 350, 2382, 5579, 26949, 8309, 4, 125, 9, 768, 6, 79, 938, 75, 4, 91, 1467, 79, 56, 7, 28, 95, 25, 2972, 30451, 25, 5, 1079, 9, 106, 4, 3180, 5579, 1594, 37, 5844, 75, 57, 11, 5, 1692, 9, 402, 505, 37, 429, 33, 57, 55, 87, 2882, 7, 907, 99, 79, 21, 2183, 4, 50118, 113, 2847, 6, 99, 109, 47, 224, 116, 7348, 7, 120, 24, 15, 1917, 264, 20185, 10195, 21491, 6608, 4, 50118, 894, 21, 6889, 14, 79, 56, 70, 69, 9927, 6, 8, 14, 51, 1415, 1104, 4, 50118, 113, 6179, 64, 38, 11942, 1917, 91, 44060, 23, 69, 8, 39422, 196, 4, 2, 2, 6179, 251, 21, 25575, 667, 7, 10195, 15431, 6045, 116, 11373, 1215, 41218, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 347, 10708, 3996, 5, 38048, 313, 1305, 39, 4334, 8588, 88, 5, 9742, 1400, 2932, 319, 8, 2999, 198, 7, 5, 526, 6, 583, 5, 124, 2797, 9, 5, 745, 4, 345, 58, 2710, 9, 490, 20063, 11, 5, 760, 6, 98, 79, 11464, 5, 2173, 21, 89, 13, 402, 97, 87, 10, 3298, 9, 8053, 8, 10, 1029, 1071, 4, 50118, 250, 23141, 24572, 10879, 62, 69, 7983, 12, 7771, 9211, 8, 79, 1481, 35158, 4, 264, 11224, 69, 5856, 561, 18412, 7, 5368, 103, 2859, 4, 20, 4117, 12, 3530, 10317, 4371, 69, 1730, 8, 32606, 6, 53, 69, 17507, 21, 11074, 160, 4, 50118, 2515, 875, 159, 5, 4385, 346, 25, 79, 36110, 198, 7, 5, 526, 9, 5, 3214, 1155, 4, 91, 581, 33, 10, 380, 885, 625, 9, 1055, 6, 79, 802, 4, 50118, 38544, 5078, 329, 368, 56, 95, 4425, 66, 9, 5, 512, 6, 77, 79, 26, 6, 22, 41541, 512, 6, 13834, 72, 50118, 113, 42903, 6, 2446, 72, 50118, 113, 100, 437, 25575, 4, 370, 300, 10, 4045, 13495, 3422, 1917, 50118, 894, 851, 69, 5, 683, 81, 4, 1405, 909, 2549, 18699, 10, 1256, 6, 664, 12, 3690, 652, 4, 20, 614, 12, 8267, 3089, 11556, 314, 410, 7, 5, 13670, 6, 6254, 9646, 69, 42529, 4, 264, 21, 674, 6958, 6, 53, 5, 239, 19728, 10317, 10944, 69, 7, 59, 195, 108, 398, 845, 20, 251, 5856, 58, 182, 2579, 4, 50118, 38544, 56, 393, 341, 10, 36289, 4, 91, 1017, 460, 802, 9, 24, 25, 34633, 2577, 4, 20, 1114, 9, 519, 2099, 19, 10, 693, 54, 1017, 57, 19, 2213, 9, 604, 222, 45, 2868, 7, 123, 4, 50118, 1708, 42, 399, 75, 2045, 101, 10, 6097, 9337, 254, 4, 264, 2551, 350, 2382, 5579, 26949, 8309, 4, 125, 9, 768, 6, 79, 938, 75, 4, 91, 1467, 79, 56, 7, 28, 95, 25, 2972, 30451, 25, 5, 1079, 9, 106, 4, 3180, 5579, 1594, 37, 5844, 75, 57, 11, 5, 1692, 9, 402, 505, 37, 429, 33, 57, 55, 87, 2882, 7, 907, 99, 79, 21, 2183, 4, 50118, 113, 2847, 6, 99, 109, 47, 224, 116, 7348, 7, 120, 24, 15, 1917, 264, 20185, 10195, 21491, 6608, 4, 50118, 894, 21, 6889, 14, 79, 56, 70, 69, 9927, 6, 8, 14, 51, 1415, 1104, 4, 50118, 113, 6179, 64, 38, 11942, 1917, 91, 44060, 23, 69, 8, 39422, 196, 4, 2, 2, 6179, 251, 21, 25575, 667, 7, 10195, 15431, 6045, 116, 4052, 39022, 1215, 4897, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 347, 10708, 3996, 5, 38048, 313, 1305, 39, 4334, 8588, 88, 5, 9742, 1400, 2932, 319, 8, 2999, 198, 7, 5, 526, 6, 583, 5, 124, 2797, 9, 5, 745, 4, 345, 58, 2710, 9, 490, 20063, 11, 5, 760, 6, 98, 79, 11464, 5, 2173, 21, 89, 13, 402, 97, 87, 10, 3298, 9, 8053, 8, 10, 1029, 1071, 4, 50118, 250, 23141, 24572, 10879, 62, 69, 7983, 12, 7771, 9211, 8, 79, 1481, 35158, 4, 264, 11224, 69, 5856, 561, 18412, 7, 5368, 103, 2859, 4, 20, 4117, 12, 3530, 10317, 4371, 69, 1730, 8, 32606, 6, 53, 69, 17507, 21, 11074, 160, 4, 50118, 2515, 875, 159, 5, 4385, 346, 25, 79, 36110, 198, 7, 5, 526, 9, 5, 3214, 1155, 4, 91, 581, 33, 10, 380, 885, 625, 9, 1055, 6, 79, 802, 4, 50118, 38544, 5078, 329, 368, 56, 95, 4425, 66, 9, 5, 512, 6, 77, 79, 26, 6, 22, 41541, 512, 6, 13834, 72, 50118, 113, 42903, 6, 2446, 72, 50118, 113, 100, 437, 25575, 4, 370, 300, 10, 4045, 13495, 3422, 1917, 50118, 894, 851, 69, 5, 683, 81, 4, 1405, 909, 2549, 18699, 10, 1256, 6, 664, 12, 3690, 652, 4, 20, 614, 12, 8267, 3089, 11556, 314, 410, 7, 5, 13670, 6, 6254, 9646, 69, 42529, 4, 264, 21, 674, 6958, 6, 53, 5, 239, 19728, 10317, 10944, 69, 7, 59, 195, 108, 398, 845, 20, 251, 5856, 58, 182, 2579, 4, 50118, 38544, 56, 393, 341, 10, 36289, 4, 91, 1017, 460, 802, 9, 24, 25, 34633, 2577, 4, 20, 1114, 9, 519, 2099, 19, 10, 693, 54, 1017, 57, 19, 2213, 9, 604, 222, 45, 2868, 7, 123, 4, 50118, 1708, 42, 399, 75, 2045, 101, 10, 6097, 9337, 254, 4, 264, 2551, 350, 2382, 5579, 26949, 8309, 4, 125, 9, 768, 6, 79, 938, 75, 4, 91, 1467, 79, 56, 7, 28, 95, 25, 2972, 30451, 25, 5, 1079, 9, 106, 4, 3180, 5579, 1594, 37, 5844, 75, 57, 11, 5, 1692, 9, 402, 505, 37, 429, 33, 57, 55, 87, 2882, 7, 907, 99, 79, 21, 2183, 4, 50118, 113, 2847, 6, 99, 109, 47, 224, 116, 7348, 7, 120, 24, 15, 1917, 264, 20185, 10195, 21491, 6608, 4, 50118, 894, 21, 6889, 14, 79, 56, 70, 69, 9927, 6, 8, 14, 51, 1415, 1104, 4, 50118, 113, 6179, 64, 38, 11942, 1917, 91, 44060, 23, 69, 8, 39422, 196, 4, 2, 2, 6179, 251, 21, 25575, 667, 7, 10195, 15431, 6045, 116, 18454, 5564, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 347, 10708, 3996, 5, 38048, 313, 1305, 39, 4334, 8588, 88, 5, 9742, 1400, 2932, 319, 8, 2999, 198, 7, 5, 526, 6, 583, 5, 124, 2797, 9, 5, 745, 4, 345, 58, 2710, 9, 490, 20063, 11, 5, 760, 6, 98, 79, 11464, 5, 2173, 21, 89, 13, 402, 97, 87, 10, 3298, 9, 8053, 8, 10, 1029, 1071, 4, 50118, 250, 23141, 24572, 10879, 62, 69, 7983, 12, 7771, 9211, 8, 79, 1481, 35158, 4, 264, 11224, 69, 5856, 561, 18412, 7, 5368, 103, 2859, 4, 20, 4117, 12, 3530, 10317, 4371, 69, 1730, 8, 32606, 6, 53, 69, 17507, 21, 11074, 160, 4, 50118, 2515, 875, 159, 5, 4385, 346, 25, 79, 36110, 198, 7, 5, 526, 9, 5, 3214, 1155, 4, 91, 581, 33, 10, 380, 885, 625, 9, 1055, 6, 79, 802, 4, 50118, 38544, 5078, 329, 368, 56, 95, 4425, 66, 9, 5, 512, 6, 77, 79, 26, 6, 22, 41541, 512, 6, 13834, 72, 50118, 113, 42903, 6, 2446, 72, 50118, 113, 100, 437, 25575, 4, 370, 300, 10, 4045, 13495, 3422, 1917, 50118, 894, 851, 69, 5, 683, 81, 4, 1405, 909, 2549, 18699, 10, 1256, 6, 664, 12, 3690, 652, 4, 20, 614, 12, 8267, 3089, 11556, 314, 410, 7, 5, 13670, 6, 6254, 9646, 69, 42529, 4, 264, 21, 674, 6958, 6, 53, 5, 239, 19728, 10317, 10944, 69, 7, 59, 195, 108, 398, 845, 20, 251, 5856, 58, 182, 2579, 4, 50118, 38544, 56, 393, 341, 10, 36289, 4, 91, 1017, 460, 802, 9, 24, 25, 34633, 2577, 4, 20, 1114, 9, 519, 2099, 19, 10, 693, 54, 1017, 57, 19, 2213, 9, 604, 222, 45, 2868, 7, 123, 4, 50118, 1708, 42, 399, 75, 2045, 101, 10, 6097, 9337, 254, 4, 264, 2551, 350, 2382, 5579, 26949, 8309, 4, 125, 9, 768, 6, 79, 938, 75, 4, 91, 1467, 79, 56, 7, 28, 95, 25, 2972, 30451, 25, 5, 1079, 9, 106, 4, 3180, 5579, 1594, 37, 5844, 75, 57, 11, 5, 1692, 9, 402, 505, 37, 429, 33, 57, 55, 87, 2882, 7, 907, 99, 79, 21, 2183, 4, 50118, 113, 2847, 6, 99, 109, 47, 224, 116, 7348, 7, 120, 24, 15, 1917, 264, 20185, 10195, 21491, 6608, 4, 50118, 894, 21, 6889, 14, 79, 56, 70, 69, 9927, 6, 8, 14, 51, 1415, 1104, 4, 50118, 113, 6179, 64, 38, 11942, 1917, 91, 44060, 23, 69, 8, 39422, 196, 4, 2, 2, 6179, 251, 21, 25575, 667, 7, 10195, 15431, 6045, 116, 45731, 1215, 26947, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 347, 10708, 3996, 5, 38048, 313, 1305, 39, 4334, 8588, 88, 5, 9742, 1400, 2932, 319, 8, 2999, 198, 7, 5, 526, 6, 583, 5, 124, 2797, 9, 5, 745, 4, 345, 58, 2710, 9, 490, 20063, 11, 5, 760, 6, 98, 79, 11464, 5, 2173, 21, 89, 13, 402, 97, 87, 10, 3298, 9, 8053, 8, 10, 1029, 1071, 4, 50118, 250, 23141, 24572, 10879, 62, 69, 7983, 12, 7771, 9211, 8, 79, 1481, 35158, 4, 264, 11224, 69, 5856, 561, 18412, 7, 5368, 103, 2859, 4, 20, 4117, 12, 3530, 10317, 4371, 69, 1730, 8, 32606, 6, 53, 69, 17507, 21, 11074, 160, 4, 50118, 2515, 875, 159, 5, 4385, 346, 25, 79, 36110, 198, 7, 5, 526, 9, 5, 3214, 1155, 4, 91, 581, 33, 10, 380, 885, 625, 9, 1055, 6, 79, 802, 4, 50118, 38544, 5078, 329, 368, 56, 95, 4425, 66, 9, 5, 512, 6, 77, 79, 26, 6, 22, 41541, 512, 6, 13834, 72, 50118, 113, 42903, 6, 2446, 72, 50118, 113, 100, 437, 25575, 4, 370, 300, 10, 4045, 13495, 3422, 1917, 50118, 894, 851, 69, 5, 683, 81, 4, 1405, 909, 2549, 18699, 10, 1256, 6, 664, 12, 3690, 652, 4, 20, 614, 12, 8267, 3089, 11556, 314, 410, 7, 5, 13670, 6, 6254, 9646, 69, 42529, 4, 264, 21, 674, 6958, 6, 53, 5, 239, 19728, 10317, 10944, 69, 7, 59, 195, 108, 398, 845, 20, 251, 5856, 58, 182, 2579, 4, 50118, 38544, 56, 393, 341, 10, 36289, 4, 91, 1017, 460, 802, 9, 24, 25, 34633, 2577, 4, 20, 1114, 9, 519, 2099, 19, 10, 693, 54, 1017, 57, 19, 2213, 9, 604, 222, 45, 2868, 7, 123, 4, 50118, 1708, 42, 399, 75, 2045, 101, 10, 6097, 9337, 254, 4, 264, 2551, 350, 2382, 5579, 26949, 8309, 4, 125, 9, 768, 6, 79, 938, 75, 4, 91, 1467, 79, 56, 7, 28, 95, 25, 2972, 30451, 25, 5, 1079, 9, 106, 4, 3180, 5579, 1594, 37, 5844, 75, 57, 11, 5, 1692, 9, 402, 505, 37, 429, 33, 57, 55, 87, 2882, 7, 907, 99, 79, 21, 2183, 4, 50118, 113, 2847, 6, 99, 109, 47, 224, 116, 7348, 7, 120, 24, 15, 1917, 264, 20185, 10195, 21491, 6608, 4, 50118, 894, 21, 6889, 14, 79, 56, 70, 69, 9927, 6, 8, 14, 51, 1415, 1104, 4, 50118, 113, 6179, 64, 38, 11942, 1917, 91, 44060, 23, 69, 8, 39422, 196, 4, 2, 2, 6179, 251, 21, 25575, 667, 7, 10195, 15431, 6045, 116, 46718, 1215, 47276, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 347, 10708, 3996, 5, 38048, 313, 1305, 39, 4334, 8588, 88, 5, 9742, 1400, 2932, 319, 8, 2999, 198, 7, 5, 526, 6, 583, 5, 124, 2797, 9, 5, 745, 4, 345, 58, 2710, 9, 490, 20063, 11, 5, 760, 6, 98, 79, 11464, 5, 2173, 21, 89, 13, 402, 97, 87, 10, 3298, 9, 8053, 8, 10, 1029, 1071, 4, 50118, 250, 23141, 24572, 10879, 62, 69, 7983, 12, 7771, 9211, 8, 79, 1481, 35158, 4, 264, 11224, 69, 5856, 561, 18412, 7, 5368, 103, 2859, 4, 20, 4117, 12, 3530, 10317, 4371, 69, 1730, 8, 32606, 6, 53, 69, 17507, 21, 11074, 160, 4, 50118, 2515, 875, 159, 5, 4385, 346, 25, 79, 36110, 198, 7, 5, 526, 9, 5, 3214, 1155, 4, 91, 581, 33, 10, 380, 885, 625, 9, 1055, 6, 79, 802, 4, 50118, 38544, 5078, 329, 368, 56, 95, 4425, 66, 9, 5, 512, 6, 77, 79, 26, 6, 22, 41541, 512, 6, 13834, 72, 50118, 113, 42903, 6, 2446, 72, 50118, 113, 100, 437, 25575, 4, 370, 300, 10, 4045, 13495, 3422, 1917, 50118, 894, 851, 69, 5, 683, 81, 4, 1405, 909, 2549, 18699, 10, 1256, 6, 664, 12, 3690, 652, 4, 20, 614, 12, 8267, 3089, 11556, 314, 410, 7, 5, 13670, 6, 6254, 9646, 69, 42529, 4, 264, 21, 674, 6958, 6, 53, 5, 239, 19728, 10317, 10944, 69, 7, 59, 195, 108, 398, 845, 20, 251, 5856, 58, 182, 2579, 4, 50118, 38544, 56, 393, 341, 10, 36289, 4, 91, 1017, 460, 802, 9, 24, 25, 34633, 2577, 4, 20, 1114, 9, 519, 2099, 19, 10, 693, 54, 1017, 57, 19, 2213, 9, 604, 222, 45, 2868, 7, 123, 4, 50118, 1708, 42, 399, 75, 2045, 101, 10, 6097, 9337, 254, 4, 264, 2551, 350, 2382, 5579, 26949, 8309, 4, 125, 9, 768, 6, 79, 938, 75, 4, 91, 1467, 79, 56, 7, 28, 95, 25, 2972, 30451, 25, 5, 1079, 9, 106, 4, 3180, 5579, 1594, 37, 5844, 75, 57, 11, 5, 1692, 9, 402, 505, 37, 429, 33, 57, 55, 87, 2882, 7, 907, 99, 79, 21, 2183, 4, 50118, 113, 2847, 6, 99, 109, 47, 224, 116, 7348, 7, 120, 24, 15, 1917, 264, 20185, 10195, 21491, 6608, 4, 50118, 894, 21, 6889, 14, 79, 56, 70, 69, 9927, 6, 8, 14, 51, 1415, 1104, 4, 50118, 113, 6179, 64, 38, 11942, 1917, 91, 44060, 23, 69, 8, 39422, 196, 4, 2, 2, 6179, 251, 21, 25575, 667, 7, 10195, 15431, 6045, 116, 1890, 27740, 868, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 347, 10708, 3996, 5, 38048, 313, 1305, 39, 4334, 8588, 88, 5, 9742, 1400, 2932, 319, 8, 2999, 198, 7, 5, 526, 6, 583, 5, 124, 2797, 9, 5, 745, 4, 345, 58, 2710, 9, 490, 20063, 11, 5, 760, 6, 98, 79, 11464, 5, 2173, 21, 89, 13, 402, 97, 87, 10, 3298, 9, 8053, 8, 10, 1029, 1071, 4, 50118, 250, 23141, 24572, 10879, 62, 69, 7983, 12, 7771, 9211, 8, 79, 1481, 35158, 4, 264, 11224, 69, 5856, 561, 18412, 7, 5368, 103, 2859, 4, 20, 4117, 12, 3530, 10317, 4371, 69, 1730, 8, 32606, 6, 53, 69, 17507, 21, 11074, 160, 4, 50118, 2515, 875, 159, 5, 4385, 346, 25, 79, 36110, 198, 7, 5, 526, 9, 5, 3214, 1155, 4, 91, 581, 33, 10, 380, 885, 625, 9, 1055, 6, 79, 802, 4, 50118, 38544, 5078, 329, 368, 56, 95, 4425, 66, 9, 5, 512, 6, 77, 79, 26, 6, 22, 41541, 512, 6, 13834, 72, 50118, 113, 42903, 6, 2446, 72, 50118, 113, 100, 437, 25575, 4, 370, 300, 10, 4045, 13495, 3422, 1917, 50118, 894, 851, 69, 5, 683, 81, 4, 1405, 909, 2549, 18699, 10, 1256, 6, 664, 12, 3690, 652, 4, 20, 614, 12, 8267, 3089, 11556, 314, 410, 7, 5, 13670, 6, 6254, 9646, 69, 42529, 4, 264, 21, 674, 6958, 6, 53, 5, 239, 19728, 10317, 10944, 69, 7, 59, 195, 108, 398, 845, 20, 251, 5856, 58, 182, 2579, 4, 50118, 38544, 56, 393, 341, 10, 36289, 4, 91, 1017, 460, 802, 9, 24, 25, 34633, 2577, 4, 20, 1114, 9, 519, 2099, 19, 10, 693, 54, 1017, 57, 19, 2213, 9, 604, 222, 45, 2868, 7, 123, 4, 50118, 1708, 42, 399, 75, 2045, 101, 10, 6097, 9337, 254, 4, 264, 2551, 350, 2382, 5579, 26949, 8309, 4, 125, 9, 768, 6, 79, 938, 75, 4, 91, 1467, 79, 56, 7, 28, 95, 25, 2972, 30451, 25, 5, 1079, 9, 106, 4, 3180, 5579, 1594, 37, 5844, 75, 57, 11, 5, 1692, 9, 402, 505, 37, 429, 33, 57, 55, 87, 2882, 7, 907, 99, 79, 21, 2183, 4, 50118, 113, 2847, 6, 99, 109, 47, 224, 116, 7348, 7, 120, 24, 15, 1917, 264, 20185, 10195, 21491, 6608, 4, 50118, 894, 21, 6889, 14, 79, 56, 70, 69, 9927, 6, 8, 14, 51, 1415, 1104, 4, 50118, 113, 6179, 64, 38, 11942, 1917, 91, 44060, 23, 69, 8, 39422, 196, 4, 2, 2, 6179, 251, 21, 25575, 667, 7, 10195, 15431, 6045, 116, 9188, 46249, 1215, 10337, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], attention_mask=[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], token_type_ids=None, label=2)\n",
            "11/30/2020 10:59:31 - INFO - utils_multiple_choice -   *** Example ***\n",
            "11/30/2020 10:59:31 - INFO - utils_multiple_choice -   feature: InputFeatures(example_id='f141_1', input_ids=[[0, 347, 10708, 3996, 5, 38048, 313, 1305, 39, 4334, 8588, 88, 5, 9742, 1400, 2932, 319, 8, 2999, 198, 7, 5, 526, 6, 583, 5, 124, 2797, 9, 5, 745, 4, 345, 58, 2710, 9, 490, 20063, 11, 5, 760, 6, 98, 79, 11464, 5, 2173, 21, 89, 13, 402, 97, 87, 10, 3298, 9, 8053, 8, 10, 1029, 1071, 4, 50118, 250, 23141, 24572, 10879, 62, 69, 7983, 12, 7771, 9211, 8, 79, 1481, 35158, 4, 264, 11224, 69, 5856, 561, 18412, 7, 5368, 103, 2859, 4, 20, 4117, 12, 3530, 10317, 4371, 69, 1730, 8, 32606, 6, 53, 69, 17507, 21, 11074, 160, 4, 50118, 2515, 875, 159, 5, 4385, 346, 25, 79, 36110, 198, 7, 5, 526, 9, 5, 3214, 1155, 4, 91, 581, 33, 10, 380, 885, 625, 9, 1055, 6, 79, 802, 4, 50118, 38544, 5078, 329, 368, 56, 95, 4425, 66, 9, 5, 512, 6, 77, 79, 26, 6, 22, 41541, 512, 6, 13834, 72, 50118, 113, 42903, 6, 2446, 72, 50118, 113, 100, 437, 25575, 4, 370, 300, 10, 4045, 13495, 3422, 1917, 50118, 894, 851, 69, 5, 683, 81, 4, 1405, 909, 2549, 18699, 10, 1256, 6, 664, 12, 3690, 652, 4, 20, 614, 12, 8267, 3089, 11556, 314, 410, 7, 5, 13670, 6, 6254, 9646, 69, 42529, 4, 264, 21, 674, 6958, 6, 53, 5, 239, 19728, 10317, 10944, 69, 7, 59, 195, 108, 398, 845, 20, 251, 5856, 58, 182, 2579, 4, 50118, 38544, 56, 393, 341, 10, 36289, 4, 91, 1017, 460, 802, 9, 24, 25, 34633, 2577, 4, 20, 1114, 9, 519, 2099, 19, 10, 693, 54, 1017, 57, 19, 2213, 9, 604, 222, 45, 2868, 7, 123, 4, 50118, 1708, 42, 399, 75, 2045, 101, 10, 6097, 9337, 254, 4, 264, 2551, 350, 2382, 5579, 26949, 8309, 4, 125, 9, 768, 6, 79, 938, 75, 4, 91, 1467, 79, 56, 7, 28, 95, 25, 2972, 30451, 25, 5, 1079, 9, 106, 4, 3180, 5579, 1594, 37, 5844, 75, 57, 11, 5, 1692, 9, 402, 505, 37, 429, 33, 57, 55, 87, 2882, 7, 907, 99, 79, 21, 2183, 4, 50118, 113, 2847, 6, 99, 109, 47, 224, 116, 7348, 7, 120, 24, 15, 1917, 264, 20185, 10195, 21491, 6608, 4, 50118, 894, 21, 6889, 14, 79, 56, 70, 69, 9927, 6, 8, 14, 51, 1415, 1104, 4, 50118, 113, 6179, 64, 38, 11942, 1917, 91, 44060, 23, 69, 8, 39422, 196, 4, 2, 2, 2264, 16, 1153, 1528, 59, 6045, 4, 35177, 1215, 8009, 1571, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 347, 10708, 3996, 5, 38048, 313, 1305, 39, 4334, 8588, 88, 5, 9742, 1400, 2932, 319, 8, 2999, 198, 7, 5, 526, 6, 583, 5, 124, 2797, 9, 5, 745, 4, 345, 58, 2710, 9, 490, 20063, 11, 5, 760, 6, 98, 79, 11464, 5, 2173, 21, 89, 13, 402, 97, 87, 10, 3298, 9, 8053, 8, 10, 1029, 1071, 4, 50118, 250, 23141, 24572, 10879, 62, 69, 7983, 12, 7771, 9211, 8, 79, 1481, 35158, 4, 264, 11224, 69, 5856, 561, 18412, 7, 5368, 103, 2859, 4, 20, 4117, 12, 3530, 10317, 4371, 69, 1730, 8, 32606, 6, 53, 69, 17507, 21, 11074, 160, 4, 50118, 2515, 875, 159, 5, 4385, 346, 25, 79, 36110, 198, 7, 5, 526, 9, 5, 3214, 1155, 4, 91, 581, 33, 10, 380, 885, 625, 9, 1055, 6, 79, 802, 4, 50118, 38544, 5078, 329, 368, 56, 95, 4425, 66, 9, 5, 512, 6, 77, 79, 26, 6, 22, 41541, 512, 6, 13834, 72, 50118, 113, 42903, 6, 2446, 72, 50118, 113, 100, 437, 25575, 4, 370, 300, 10, 4045, 13495, 3422, 1917, 50118, 894, 851, 69, 5, 683, 81, 4, 1405, 909, 2549, 18699, 10, 1256, 6, 664, 12, 3690, 652, 4, 20, 614, 12, 8267, 3089, 11556, 314, 410, 7, 5, 13670, 6, 6254, 9646, 69, 42529, 4, 264, 21, 674, 6958, 6, 53, 5, 239, 19728, 10317, 10944, 69, 7, 59, 195, 108, 398, 845, 20, 251, 5856, 58, 182, 2579, 4, 50118, 38544, 56, 393, 341, 10, 36289, 4, 91, 1017, 460, 802, 9, 24, 25, 34633, 2577, 4, 20, 1114, 9, 519, 2099, 19, 10, 693, 54, 1017, 57, 19, 2213, 9, 604, 222, 45, 2868, 7, 123, 4, 50118, 1708, 42, 399, 75, 2045, 101, 10, 6097, 9337, 254, 4, 264, 2551, 350, 2382, 5579, 26949, 8309, 4, 125, 9, 768, 6, 79, 938, 75, 4, 91, 1467, 79, 56, 7, 28, 95, 25, 2972, 30451, 25, 5, 1079, 9, 106, 4, 3180, 5579, 1594, 37, 5844, 75, 57, 11, 5, 1692, 9, 402, 505, 37, 429, 33, 57, 55, 87, 2882, 7, 907, 99, 79, 21, 2183, 4, 50118, 113, 2847, 6, 99, 109, 47, 224, 116, 7348, 7, 120, 24, 15, 1917, 264, 20185, 10195, 21491, 6608, 4, 50118, 894, 21, 6889, 14, 79, 56, 70, 69, 9927, 6, 8, 14, 51, 1415, 1104, 4, 50118, 113, 6179, 64, 38, 11942, 1917, 91, 44060, 23, 69, 8, 39422, 196, 4, 2, 2, 2264, 16, 1153, 1528, 59, 6045, 4, 8316, 687, 6948, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 347, 10708, 3996, 5, 38048, 313, 1305, 39, 4334, 8588, 88, 5, 9742, 1400, 2932, 319, 8, 2999, 198, 7, 5, 526, 6, 583, 5, 124, 2797, 9, 5, 745, 4, 345, 58, 2710, 9, 490, 20063, 11, 5, 760, 6, 98, 79, 11464, 5, 2173, 21, 89, 13, 402, 97, 87, 10, 3298, 9, 8053, 8, 10, 1029, 1071, 4, 50118, 250, 23141, 24572, 10879, 62, 69, 7983, 12, 7771, 9211, 8, 79, 1481, 35158, 4, 264, 11224, 69, 5856, 561, 18412, 7, 5368, 103, 2859, 4, 20, 4117, 12, 3530, 10317, 4371, 69, 1730, 8, 32606, 6, 53, 69, 17507, 21, 11074, 160, 4, 50118, 2515, 875, 159, 5, 4385, 346, 25, 79, 36110, 198, 7, 5, 526, 9, 5, 3214, 1155, 4, 91, 581, 33, 10, 380, 885, 625, 9, 1055, 6, 79, 802, 4, 50118, 38544, 5078, 329, 368, 56, 95, 4425, 66, 9, 5, 512, 6, 77, 79, 26, 6, 22, 41541, 512, 6, 13834, 72, 50118, 113, 42903, 6, 2446, 72, 50118, 113, 100, 437, 25575, 4, 370, 300, 10, 4045, 13495, 3422, 1917, 50118, 894, 851, 69, 5, 683, 81, 4, 1405, 909, 2549, 18699, 10, 1256, 6, 664, 12, 3690, 652, 4, 20, 614, 12, 8267, 3089, 11556, 314, 410, 7, 5, 13670, 6, 6254, 9646, 69, 42529, 4, 264, 21, 674, 6958, 6, 53, 5, 239, 19728, 10317, 10944, 69, 7, 59, 195, 108, 398, 845, 20, 251, 5856, 58, 182, 2579, 4, 50118, 38544, 56, 393, 341, 10, 36289, 4, 91, 1017, 460, 802, 9, 24, 25, 34633, 2577, 4, 20, 1114, 9, 519, 2099, 19, 10, 693, 54, 1017, 57, 19, 2213, 9, 604, 222, 45, 2868, 7, 123, 4, 50118, 1708, 42, 399, 75, 2045, 101, 10, 6097, 9337, 254, 4, 264, 2551, 350, 2382, 5579, 26949, 8309, 4, 125, 9, 768, 6, 79, 938, 75, 4, 91, 1467, 79, 56, 7, 28, 95, 25, 2972, 30451, 25, 5, 1079, 9, 106, 4, 3180, 5579, 1594, 37, 5844, 75, 57, 11, 5, 1692, 9, 402, 505, 37, 429, 33, 57, 55, 87, 2882, 7, 907, 99, 79, 21, 2183, 4, 50118, 113, 2847, 6, 99, 109, 47, 224, 116, 7348, 7, 120, 24, 15, 1917, 264, 20185, 10195, 21491, 6608, 4, 50118, 894, 21, 6889, 14, 79, 56, 70, 69, 9927, 6, 8, 14, 51, 1415, 1104, 4, 50118, 113, 6179, 64, 38, 11942, 1917, 91, 44060, 23, 69, 8, 39422, 196, 4, 2, 2, 2264, 16, 1153, 1528, 59, 6045, 4, 11373, 1215, 41218, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 347, 10708, 3996, 5, 38048, 313, 1305, 39, 4334, 8588, 88, 5, 9742, 1400, 2932, 319, 8, 2999, 198, 7, 5, 526, 6, 583, 5, 124, 2797, 9, 5, 745, 4, 345, 58, 2710, 9, 490, 20063, 11, 5, 760, 6, 98, 79, 11464, 5, 2173, 21, 89, 13, 402, 97, 87, 10, 3298, 9, 8053, 8, 10, 1029, 1071, 4, 50118, 250, 23141, 24572, 10879, 62, 69, 7983, 12, 7771, 9211, 8, 79, 1481, 35158, 4, 264, 11224, 69, 5856, 561, 18412, 7, 5368, 103, 2859, 4, 20, 4117, 12, 3530, 10317, 4371, 69, 1730, 8, 32606, 6, 53, 69, 17507, 21, 11074, 160, 4, 50118, 2515, 875, 159, 5, 4385, 346, 25, 79, 36110, 198, 7, 5, 526, 9, 5, 3214, 1155, 4, 91, 581, 33, 10, 380, 885, 625, 9, 1055, 6, 79, 802, 4, 50118, 38544, 5078, 329, 368, 56, 95, 4425, 66, 9, 5, 512, 6, 77, 79, 26, 6, 22, 41541, 512, 6, 13834, 72, 50118, 113, 42903, 6, 2446, 72, 50118, 113, 100, 437, 25575, 4, 370, 300, 10, 4045, 13495, 3422, 1917, 50118, 894, 851, 69, 5, 683, 81, 4, 1405, 909, 2549, 18699, 10, 1256, 6, 664, 12, 3690, 652, 4, 20, 614, 12, 8267, 3089, 11556, 314, 410, 7, 5, 13670, 6, 6254, 9646, 69, 42529, 4, 264, 21, 674, 6958, 6, 53, 5, 239, 19728, 10317, 10944, 69, 7, 59, 195, 108, 398, 845, 20, 251, 5856, 58, 182, 2579, 4, 50118, 38544, 56, 393, 341, 10, 36289, 4, 91, 1017, 460, 802, 9, 24, 25, 34633, 2577, 4, 20, 1114, 9, 519, 2099, 19, 10, 693, 54, 1017, 57, 19, 2213, 9, 604, 222, 45, 2868, 7, 123, 4, 50118, 1708, 42, 399, 75, 2045, 101, 10, 6097, 9337, 254, 4, 264, 2551, 350, 2382, 5579, 26949, 8309, 4, 125, 9, 768, 6, 79, 938, 75, 4, 91, 1467, 79, 56, 7, 28, 95, 25, 2972, 30451, 25, 5, 1079, 9, 106, 4, 3180, 5579, 1594, 37, 5844, 75, 57, 11, 5, 1692, 9, 402, 505, 37, 429, 33, 57, 55, 87, 2882, 7, 907, 99, 79, 21, 2183, 4, 50118, 113, 2847, 6, 99, 109, 47, 224, 116, 7348, 7, 120, 24, 15, 1917, 264, 20185, 10195, 21491, 6608, 4, 50118, 894, 21, 6889, 14, 79, 56, 70, 69, 9927, 6, 8, 14, 51, 1415, 1104, 4, 50118, 113, 6179, 64, 38, 11942, 1917, 91, 44060, 23, 69, 8, 39422, 196, 4, 2, 2, 2264, 16, 1153, 1528, 59, 6045, 4, 4052, 39022, 1215, 4897, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 347, 10708, 3996, 5, 38048, 313, 1305, 39, 4334, 8588, 88, 5, 9742, 1400, 2932, 319, 8, 2999, 198, 7, 5, 526, 6, 583, 5, 124, 2797, 9, 5, 745, 4, 345, 58, 2710, 9, 490, 20063, 11, 5, 760, 6, 98, 79, 11464, 5, 2173, 21, 89, 13, 402, 97, 87, 10, 3298, 9, 8053, 8, 10, 1029, 1071, 4, 50118, 250, 23141, 24572, 10879, 62, 69, 7983, 12, 7771, 9211, 8, 79, 1481, 35158, 4, 264, 11224, 69, 5856, 561, 18412, 7, 5368, 103, 2859, 4, 20, 4117, 12, 3530, 10317, 4371, 69, 1730, 8, 32606, 6, 53, 69, 17507, 21, 11074, 160, 4, 50118, 2515, 875, 159, 5, 4385, 346, 25, 79, 36110, 198, 7, 5, 526, 9, 5, 3214, 1155, 4, 91, 581, 33, 10, 380, 885, 625, 9, 1055, 6, 79, 802, 4, 50118, 38544, 5078, 329, 368, 56, 95, 4425, 66, 9, 5, 512, 6, 77, 79, 26, 6, 22, 41541, 512, 6, 13834, 72, 50118, 113, 42903, 6, 2446, 72, 50118, 113, 100, 437, 25575, 4, 370, 300, 10, 4045, 13495, 3422, 1917, 50118, 894, 851, 69, 5, 683, 81, 4, 1405, 909, 2549, 18699, 10, 1256, 6, 664, 12, 3690, 652, 4, 20, 614, 12, 8267, 3089, 11556, 314, 410, 7, 5, 13670, 6, 6254, 9646, 69, 42529, 4, 264, 21, 674, 6958, 6, 53, 5, 239, 19728, 10317, 10944, 69, 7, 59, 195, 108, 398, 845, 20, 251, 5856, 58, 182, 2579, 4, 50118, 38544, 56, 393, 341, 10, 36289, 4, 91, 1017, 460, 802, 9, 24, 25, 34633, 2577, 4, 20, 1114, 9, 519, 2099, 19, 10, 693, 54, 1017, 57, 19, 2213, 9, 604, 222, 45, 2868, 7, 123, 4, 50118, 1708, 42, 399, 75, 2045, 101, 10, 6097, 9337, 254, 4, 264, 2551, 350, 2382, 5579, 26949, 8309, 4, 125, 9, 768, 6, 79, 938, 75, 4, 91, 1467, 79, 56, 7, 28, 95, 25, 2972, 30451, 25, 5, 1079, 9, 106, 4, 3180, 5579, 1594, 37, 5844, 75, 57, 11, 5, 1692, 9, 402, 505, 37, 429, 33, 57, 55, 87, 2882, 7, 907, 99, 79, 21, 2183, 4, 50118, 113, 2847, 6, 99, 109, 47, 224, 116, 7348, 7, 120, 24, 15, 1917, 264, 20185, 10195, 21491, 6608, 4, 50118, 894, 21, 6889, 14, 79, 56, 70, 69, 9927, 6, 8, 14, 51, 1415, 1104, 4, 50118, 113, 6179, 64, 38, 11942, 1917, 91, 44060, 23, 69, 8, 39422, 196, 4, 2, 2, 2264, 16, 1153, 1528, 59, 6045, 4, 18454, 5564, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 347, 10708, 3996, 5, 38048, 313, 1305, 39, 4334, 8588, 88, 5, 9742, 1400, 2932, 319, 8, 2999, 198, 7, 5, 526, 6, 583, 5, 124, 2797, 9, 5, 745, 4, 345, 58, 2710, 9, 490, 20063, 11, 5, 760, 6, 98, 79, 11464, 5, 2173, 21, 89, 13, 402, 97, 87, 10, 3298, 9, 8053, 8, 10, 1029, 1071, 4, 50118, 250, 23141, 24572, 10879, 62, 69, 7983, 12, 7771, 9211, 8, 79, 1481, 35158, 4, 264, 11224, 69, 5856, 561, 18412, 7, 5368, 103, 2859, 4, 20, 4117, 12, 3530, 10317, 4371, 69, 1730, 8, 32606, 6, 53, 69, 17507, 21, 11074, 160, 4, 50118, 2515, 875, 159, 5, 4385, 346, 25, 79, 36110, 198, 7, 5, 526, 9, 5, 3214, 1155, 4, 91, 581, 33, 10, 380, 885, 625, 9, 1055, 6, 79, 802, 4, 50118, 38544, 5078, 329, 368, 56, 95, 4425, 66, 9, 5, 512, 6, 77, 79, 26, 6, 22, 41541, 512, 6, 13834, 72, 50118, 113, 42903, 6, 2446, 72, 50118, 113, 100, 437, 25575, 4, 370, 300, 10, 4045, 13495, 3422, 1917, 50118, 894, 851, 69, 5, 683, 81, 4, 1405, 909, 2549, 18699, 10, 1256, 6, 664, 12, 3690, 652, 4, 20, 614, 12, 8267, 3089, 11556, 314, 410, 7, 5, 13670, 6, 6254, 9646, 69, 42529, 4, 264, 21, 674, 6958, 6, 53, 5, 239, 19728, 10317, 10944, 69, 7, 59, 195, 108, 398, 845, 20, 251, 5856, 58, 182, 2579, 4, 50118, 38544, 56, 393, 341, 10, 36289, 4, 91, 1017, 460, 802, 9, 24, 25, 34633, 2577, 4, 20, 1114, 9, 519, 2099, 19, 10, 693, 54, 1017, 57, 19, 2213, 9, 604, 222, 45, 2868, 7, 123, 4, 50118, 1708, 42, 399, 75, 2045, 101, 10, 6097, 9337, 254, 4, 264, 2551, 350, 2382, 5579, 26949, 8309, 4, 125, 9, 768, 6, 79, 938, 75, 4, 91, 1467, 79, 56, 7, 28, 95, 25, 2972, 30451, 25, 5, 1079, 9, 106, 4, 3180, 5579, 1594, 37, 5844, 75, 57, 11, 5, 1692, 9, 402, 505, 37, 429, 33, 57, 55, 87, 2882, 7, 907, 99, 79, 21, 2183, 4, 50118, 113, 2847, 6, 99, 109, 47, 224, 116, 7348, 7, 120, 24, 15, 1917, 264, 20185, 10195, 21491, 6608, 4, 50118, 894, 21, 6889, 14, 79, 56, 70, 69, 9927, 6, 8, 14, 51, 1415, 1104, 4, 50118, 113, 6179, 64, 38, 11942, 1917, 91, 44060, 23, 69, 8, 39422, 196, 4, 2, 2, 2264, 16, 1153, 1528, 59, 6045, 4, 45731, 1215, 26947, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 347, 10708, 3996, 5, 38048, 313, 1305, 39, 4334, 8588, 88, 5, 9742, 1400, 2932, 319, 8, 2999, 198, 7, 5, 526, 6, 583, 5, 124, 2797, 9, 5, 745, 4, 345, 58, 2710, 9, 490, 20063, 11, 5, 760, 6, 98, 79, 11464, 5, 2173, 21, 89, 13, 402, 97, 87, 10, 3298, 9, 8053, 8, 10, 1029, 1071, 4, 50118, 250, 23141, 24572, 10879, 62, 69, 7983, 12, 7771, 9211, 8, 79, 1481, 35158, 4, 264, 11224, 69, 5856, 561, 18412, 7, 5368, 103, 2859, 4, 20, 4117, 12, 3530, 10317, 4371, 69, 1730, 8, 32606, 6, 53, 69, 17507, 21, 11074, 160, 4, 50118, 2515, 875, 159, 5, 4385, 346, 25, 79, 36110, 198, 7, 5, 526, 9, 5, 3214, 1155, 4, 91, 581, 33, 10, 380, 885, 625, 9, 1055, 6, 79, 802, 4, 50118, 38544, 5078, 329, 368, 56, 95, 4425, 66, 9, 5, 512, 6, 77, 79, 26, 6, 22, 41541, 512, 6, 13834, 72, 50118, 113, 42903, 6, 2446, 72, 50118, 113, 100, 437, 25575, 4, 370, 300, 10, 4045, 13495, 3422, 1917, 50118, 894, 851, 69, 5, 683, 81, 4, 1405, 909, 2549, 18699, 10, 1256, 6, 664, 12, 3690, 652, 4, 20, 614, 12, 8267, 3089, 11556, 314, 410, 7, 5, 13670, 6, 6254, 9646, 69, 42529, 4, 264, 21, 674, 6958, 6, 53, 5, 239, 19728, 10317, 10944, 69, 7, 59, 195, 108, 398, 845, 20, 251, 5856, 58, 182, 2579, 4, 50118, 38544, 56, 393, 341, 10, 36289, 4, 91, 1017, 460, 802, 9, 24, 25, 34633, 2577, 4, 20, 1114, 9, 519, 2099, 19, 10, 693, 54, 1017, 57, 19, 2213, 9, 604, 222, 45, 2868, 7, 123, 4, 50118, 1708, 42, 399, 75, 2045, 101, 10, 6097, 9337, 254, 4, 264, 2551, 350, 2382, 5579, 26949, 8309, 4, 125, 9, 768, 6, 79, 938, 75, 4, 91, 1467, 79, 56, 7, 28, 95, 25, 2972, 30451, 25, 5, 1079, 9, 106, 4, 3180, 5579, 1594, 37, 5844, 75, 57, 11, 5, 1692, 9, 402, 505, 37, 429, 33, 57, 55, 87, 2882, 7, 907, 99, 79, 21, 2183, 4, 50118, 113, 2847, 6, 99, 109, 47, 224, 116, 7348, 7, 120, 24, 15, 1917, 264, 20185, 10195, 21491, 6608, 4, 50118, 894, 21, 6889, 14, 79, 56, 70, 69, 9927, 6, 8, 14, 51, 1415, 1104, 4, 50118, 113, 6179, 64, 38, 11942, 1917, 91, 44060, 23, 69, 8, 39422, 196, 4, 2, 2, 2264, 16, 1153, 1528, 59, 6045, 4, 46718, 1215, 47276, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 347, 10708, 3996, 5, 38048, 313, 1305, 39, 4334, 8588, 88, 5, 9742, 1400, 2932, 319, 8, 2999, 198, 7, 5, 526, 6, 583, 5, 124, 2797, 9, 5, 745, 4, 345, 58, 2710, 9, 490, 20063, 11, 5, 760, 6, 98, 79, 11464, 5, 2173, 21, 89, 13, 402, 97, 87, 10, 3298, 9, 8053, 8, 10, 1029, 1071, 4, 50118, 250, 23141, 24572, 10879, 62, 69, 7983, 12, 7771, 9211, 8, 79, 1481, 35158, 4, 264, 11224, 69, 5856, 561, 18412, 7, 5368, 103, 2859, 4, 20, 4117, 12, 3530, 10317, 4371, 69, 1730, 8, 32606, 6, 53, 69, 17507, 21, 11074, 160, 4, 50118, 2515, 875, 159, 5, 4385, 346, 25, 79, 36110, 198, 7, 5, 526, 9, 5, 3214, 1155, 4, 91, 581, 33, 10, 380, 885, 625, 9, 1055, 6, 79, 802, 4, 50118, 38544, 5078, 329, 368, 56, 95, 4425, 66, 9, 5, 512, 6, 77, 79, 26, 6, 22, 41541, 512, 6, 13834, 72, 50118, 113, 42903, 6, 2446, 72, 50118, 113, 100, 437, 25575, 4, 370, 300, 10, 4045, 13495, 3422, 1917, 50118, 894, 851, 69, 5, 683, 81, 4, 1405, 909, 2549, 18699, 10, 1256, 6, 664, 12, 3690, 652, 4, 20, 614, 12, 8267, 3089, 11556, 314, 410, 7, 5, 13670, 6, 6254, 9646, 69, 42529, 4, 264, 21, 674, 6958, 6, 53, 5, 239, 19728, 10317, 10944, 69, 7, 59, 195, 108, 398, 845, 20, 251, 5856, 58, 182, 2579, 4, 50118, 38544, 56, 393, 341, 10, 36289, 4, 91, 1017, 460, 802, 9, 24, 25, 34633, 2577, 4, 20, 1114, 9, 519, 2099, 19, 10, 693, 54, 1017, 57, 19, 2213, 9, 604, 222, 45, 2868, 7, 123, 4, 50118, 1708, 42, 399, 75, 2045, 101, 10, 6097, 9337, 254, 4, 264, 2551, 350, 2382, 5579, 26949, 8309, 4, 125, 9, 768, 6, 79, 938, 75, 4, 91, 1467, 79, 56, 7, 28, 95, 25, 2972, 30451, 25, 5, 1079, 9, 106, 4, 3180, 5579, 1594, 37, 5844, 75, 57, 11, 5, 1692, 9, 402, 505, 37, 429, 33, 57, 55, 87, 2882, 7, 907, 99, 79, 21, 2183, 4, 50118, 113, 2847, 6, 99, 109, 47, 224, 116, 7348, 7, 120, 24, 15, 1917, 264, 20185, 10195, 21491, 6608, 4, 50118, 894, 21, 6889, 14, 79, 56, 70, 69, 9927, 6, 8, 14, 51, 1415, 1104, 4, 50118, 113, 6179, 64, 38, 11942, 1917, 91, 44060, 23, 69, 8, 39422, 196, 4, 2, 2, 2264, 16, 1153, 1528, 59, 6045, 4, 1890, 27740, 868, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 347, 10708, 3996, 5, 38048, 313, 1305, 39, 4334, 8588, 88, 5, 9742, 1400, 2932, 319, 8, 2999, 198, 7, 5, 526, 6, 583, 5, 124, 2797, 9, 5, 745, 4, 345, 58, 2710, 9, 490, 20063, 11, 5, 760, 6, 98, 79, 11464, 5, 2173, 21, 89, 13, 402, 97, 87, 10, 3298, 9, 8053, 8, 10, 1029, 1071, 4, 50118, 250, 23141, 24572, 10879, 62, 69, 7983, 12, 7771, 9211, 8, 79, 1481, 35158, 4, 264, 11224, 69, 5856, 561, 18412, 7, 5368, 103, 2859, 4, 20, 4117, 12, 3530, 10317, 4371, 69, 1730, 8, 32606, 6, 53, 69, 17507, 21, 11074, 160, 4, 50118, 2515, 875, 159, 5, 4385, 346, 25, 79, 36110, 198, 7, 5, 526, 9, 5, 3214, 1155, 4, 91, 581, 33, 10, 380, 885, 625, 9, 1055, 6, 79, 802, 4, 50118, 38544, 5078, 329, 368, 56, 95, 4425, 66, 9, 5, 512, 6, 77, 79, 26, 6, 22, 41541, 512, 6, 13834, 72, 50118, 113, 42903, 6, 2446, 72, 50118, 113, 100, 437, 25575, 4, 370, 300, 10, 4045, 13495, 3422, 1917, 50118, 894, 851, 69, 5, 683, 81, 4, 1405, 909, 2549, 18699, 10, 1256, 6, 664, 12, 3690, 652, 4, 20, 614, 12, 8267, 3089, 11556, 314, 410, 7, 5, 13670, 6, 6254, 9646, 69, 42529, 4, 264, 21, 674, 6958, 6, 53, 5, 239, 19728, 10317, 10944, 69, 7, 59, 195, 108, 398, 845, 20, 251, 5856, 58, 182, 2579, 4, 50118, 38544, 56, 393, 341, 10, 36289, 4, 91, 1017, 460, 802, 9, 24, 25, 34633, 2577, 4, 20, 1114, 9, 519, 2099, 19, 10, 693, 54, 1017, 57, 19, 2213, 9, 604, 222, 45, 2868, 7, 123, 4, 50118, 1708, 42, 399, 75, 2045, 101, 10, 6097, 9337, 254, 4, 264, 2551, 350, 2382, 5579, 26949, 8309, 4, 125, 9, 768, 6, 79, 938, 75, 4, 91, 1467, 79, 56, 7, 28, 95, 25, 2972, 30451, 25, 5, 1079, 9, 106, 4, 3180, 5579, 1594, 37, 5844, 75, 57, 11, 5, 1692, 9, 402, 505, 37, 429, 33, 57, 55, 87, 2882, 7, 907, 99, 79, 21, 2183, 4, 50118, 113, 2847, 6, 99, 109, 47, 224, 116, 7348, 7, 120, 24, 15, 1917, 264, 20185, 10195, 21491, 6608, 4, 50118, 894, 21, 6889, 14, 79, 56, 70, 69, 9927, 6, 8, 14, 51, 1415, 1104, 4, 50118, 113, 6179, 64, 38, 11942, 1917, 91, 44060, 23, 69, 8, 39422, 196, 4, 2, 2, 2264, 16, 1153, 1528, 59, 6045, 4, 9188, 46249, 1215, 10337, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], attention_mask=[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], token_type_ids=None, label=6)\n",
            "11/30/2020 10:59:31 - INFO - utils_multiple_choice -   Saving features into cached file ./data/cached_dev_RobertaTokenizer_512_quail-reasoning\n",
            "11/30/2020 10:59:37 - INFO - filelock -   Lock 140667963441840 released on ./data/cached_dev_RobertaTokenizer_512_quail-reasoning.lock\n",
            "roberta-base-reasoning_classification\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mngdodd\u001b[0m (use `wandb login --relogin` to force relogin)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.11\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mroberta-base-reasoning_classification\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ngdodd/huggingface\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ngdodd/huggingface/runs/2lt2lenb\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /content/wandb/run-20201130_105943-2lt2lenb\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n",
            "\n",
            "  1%|          | 25/2562 [02:48<4:46:11,  6.77s/it]\n",
            "                                                   \n",
            "  3%|▎         | 75/2562 [08:27<4:39:39,  6.75s/it]{'loss': 1.0238946533203126, 'learning_rate': 9.707259953161594e-06, 'epoch': 0.05852242579356409}\n",
            "  4%|▍         | 100/2562 [11:16<4:38:24,  6.78s/it]{'loss': 0.8554293823242187, 'learning_rate': 9.60967993754879e-06, 'epoch': 0.07802990105808545}\n",
            "                                                    \n",
            "                                                    {'loss': 0.734732666015625, 'learning_rate': 9.414519906323187e-06, 'epoch': 0.11704485158712818}\n",
            "  7%|▋         | 175/2562 [19:44<4:28:36,  6.75s/it]\n",
            "  8%|▊         | 200/2562 [22:33<4:27:26,  6.79s/it]\n",
            "  9%|▉         | 225/2562 [25:22<4:23:51,  6.77s/it]\n",
            "{'loss': 0.5236859130859375, 'learning_rate': 9.024199843871976e-06, 'epoch': 0.19507475264521365}\n",
            " 11%|█         | 275/2562 [31:01<4:17:26,  6.75s/it]{'loss': 0.432039794921875, 'learning_rate': 8.926619828259172e-06, 'epoch': 0.21458222790973502}\n",
            " 12%|█▏        | 300/2562 [33:50<4:16:16,  6.80s/it]\n",
            "{'loss': 0.3970263671875, 'learning_rate': 8.731459797033569e-06, 'epoch': 0.2535971784387777}\n",
            " 14%|█▎        | 350/2562 [39:29<4:09:05,  6.76s/it]{'loss': 0.3471826171875, 'learning_rate': 8.633879781420765e-06, 'epoch': 0.2731046537032991}\n",
            " 15%|█▍        | 375/2562 [42:19<4:06:40,  6.77s/it]\n",
            " 16%|█▌        | 400/2562 [45:08<4:04:48,  6.79s/it]{'loss': 0.3919873046875, 'learning_rate': 8.438719750195162e-06, 'epoch': 0.3121196042323418}\n",
            "                                                    {'loss': 0.294041748046875, 'learning_rate': 8.341139734582358e-06, 'epoch': 0.3316270794968632}\n",
            " 18%|█▊        | 450/2562 [50:47<3:58:09,  6.77s/it]{'loss': 0.249417724609375, 'learning_rate': 8.243559718969556e-06, 'epoch': 0.35113455476138455}\n",
            "{'loss': 0.311846923828125, 'learning_rate': 8.145979703356753e-06, 'epoch': 0.3706420300259059}\n",
            "{'loss': 0.300277099609375, 'learning_rate': 8.048399687743951e-06, 'epoch': 0.3901495052904273}\n",
            " 20%|██        | 525/2562 [59:21<3:49:52,  6.77s/it]\n",
            "                                                      {'loss': 0.232099609375, 'learning_rate': 7.853239656518346e-06, 'epoch': 0.42916445581947005}\n",
            "{'loss': 0.2969287109375, 'learning_rate': 7.755659640905544e-06, 'epoch': 0.4486719310839914}\n",
            "                                                      \n",
            " 24%|██▍       | 625/2562 [1:10:38<3:38:44,  6.78s/it]\n",
            "{'loss': 0.282421875, 'learning_rate': 7.4629195940671365e-06, 'epoch': 0.5071943568775554}\n",
            " 26%|██▋       | 675/2562 [1:16:17<3:32:31,  6.76s/it]{'loss': 0.253455810546875, 'learning_rate': 7.365339578454334e-06, 'epoch': 0.5267018321420769}\n",
            " 27%|██▋       | 700/2562 [1:19:06<3:30:55,  6.80s/it]{'loss': 0.21859375, 'learning_rate': 7.267759562841531e-06, 'epoch': 0.5462093074065982}\n",
            "                                                      {'loss': 0.2418408203125, 'learning_rate': 7.1701795472287285e-06, 'epoch': 0.5657167826711196}\n",
            " 29%|██▉       | 750/2562 [1:24:45<3:24:25,  6.77s/it]\n",
            "                                                      \n",
            " 31%|███       | 800/2562 [1:30:24<3:19:34,  6.80s/it]\n",
            " 32%|███▏      | 825/2562 [1:33:13<3:16:11,  6.78s/it]\n",
            " 33%|███▎      | 850/2562 [1:36:02<3:13:03,  6.77s/it]\n",
            " 34%|███▍      | 875/2562 [1:38:51<3:09:54,  6.75s/it]{'loss': 0.216903076171875, 'learning_rate': 6.5846994535519125e-06, 'epoch': 0.6827616342582478}\n",
            "                                                      {'loss': 0.269217529296875, 'learning_rate': 6.487119437939111e-06, 'epoch': 0.7022691095227691}\n",
            "                                                      {'loss': 0.2264892578125, 'learning_rate': 6.389539422326309e-06, 'epoch': 0.7217765847872905}\n",
            " 37%|███▋      | 950/2562 [1:47:20<3:01:53,  6.77s/it]{'loss': 0.24922607421875, 'learning_rate': 6.291959406713506e-06, 'epoch': 0.7412840600518118}\n",
            " 38%|███▊      | 975/2562 [1:50:09<2:58:48,  6.76s/it]{'loss': 0.217198486328125, 'learning_rate': 6.1943793911007036e-06, 'epoch': 0.7607915353163333}\n",
            "{'loss': 0.249293212890625, 'learning_rate': 6.096799375487901e-06, 'epoch': 0.7802990105808546}\n",
            "                                                       {'loss': 0.224539794921875, 'learning_rate': 5.999219359875098e-06, 'epoch': 0.799806485845376}\n",
            "{'loss': 0.25058349609375, 'learning_rate': 5.9016393442622956e-06, 'epoch': 0.8193139611098973}\n",
            "                                                       {'loss': 0.233472900390625, 'learning_rate': 5.804059328649493e-06, 'epoch': 0.8388214363744186}\n",
            " 43%|████▎     | 1100/2562 [2:04:21<2:45:28,  6.79s/it]\n",
            " 44%|████▍     | 1125/2562 [2:07:10<2:42:13,  6.77s/it]\n",
            " 45%|████▍     | 1150/2562 [2:10:00<2:39:08,  6.76s/it]\n",
            "{'loss': 0.1880908203125, 'learning_rate': 5.413739266198283e-06, 'epoch': 0.9168513374325041}\n",
            "{'loss': 0.1899462890625, 'learning_rate': 5.316159250585481e-06, 'epoch': 0.9363588126970255}\n",
            " 48%|████▊     | 1225/2562 [2:18:28<2:30:41,  6.76s/it]\n",
            "                                                       \n",
            " 50%|████▉     | 1275/2562 [2:24:06<2:24:52,  6.75s/it]\n",
            "                                                       \n",
            "                                                       {'loss': 0.22655517578125, 'learning_rate': 4.828259172521468e-06, 'epoch': 1.0343331564655576}\n",
            " 53%|█████▎    | 1350/2562 [2:32:38<2:16:35,  6.76s/it]\n",
            "{'loss': 0.1942041015625, 'learning_rate': 4.6330991412958634e-06, 'epoch': 1.0733481069946003}\n",
            "                                                       {'loss': 0.2213671875, 'learning_rate': 4.535519125683061e-06, 'epoch': 1.0928555822591217}\n",
            "                                                       {'loss': 0.1968994140625, 'learning_rate': 4.437939110070258e-06, 'epoch': 1.112363057523643}\n",
            " 57%|█████▋    | 1450/2562 [2:43:55<2:05:28,  6.77s/it]\n",
            "{'loss': 0.20377685546875, 'learning_rate': 4.242779078844654e-06, 'epoch': 1.1513780080526859}\n",
            "{'loss': 0.16338134765625, 'learning_rate': 4.145199063231851e-06, 'epoch': 1.170885483317207}\n",
            "                                                       \n",
            "                                                       {'loss': 0.24445068359375, 'learning_rate': 3.950039032006246e-06, 'epoch': 1.2099004338462498}\n",
            "{'loss': 0.22853759765625, 'learning_rate': 3.852459016393443e-06, 'epoch': 1.2294079091107712}\n",
            " 62%|██████▏   | 1600/2562 [3:00:57<1:48:48,  6.79s/it]\n",
            "                                                       {'loss': 0.19667236328125, 'learning_rate': 3.657298985167838e-06, 'epoch': 1.268422859639814}\n",
            " 64%|██████▍   | 1650/2562 [3:06:35<1:42:52,  6.77s/it]\n",
            " 65%|██████▌   | 1675/2562 [3:09:24<1:39:50,  6.75s/it]\n",
            " 66%|██████▋   | 1700/2562 [3:12:14<1:37:36,  6.79s/it]{'loss': 0.24988037109375, 'learning_rate': 3.3645589383294304e-06, 'epoch': 1.326945285433378}\n",
            " 67%|██████▋   | 1725/2562 [3:15:03<1:34:27,  6.77s/it]{'loss': 0.17580078125, 'learning_rate': 3.2669789227166278e-06, 'epoch': 1.3464527606978995}\n",
            "                                                       \n",
            "{'loss': 0.2032666015625, 'learning_rate': 3.071818891491023e-06, 'epoch': 1.3854677112269422}\n",
            " 70%|███████   | 1800/2562 [3:23:31<1:26:10,  6.79s/it]{'loss': 0.20969970703125, 'learning_rate': 2.97423887587822e-06, 'epoch': 1.4049751864914635}\n",
            " 71%|███████   | 1825/2562 [3:26:20<1:23:20,  6.78s/it]\n",
            " 72%|███████▏  | 1850/2562 [3:29:10<1:20:10,  6.76s/it]\n",
            " 73%|███████▎  | 1875/2562 [3:31:59<1:17:19,  6.75s/it]{'loss': 0.1754052734375, 'learning_rate': 2.681498829039813e-06, 'epoch': 1.4634976122850276}\n",
            " 74%|███████▍  | 1900/2562 [3:34:48<1:14:57,  6.79s/it]\n",
            "                                                       \n",
            " 76%|███████▌  | 1950/2562 [3:40:27<1:09:06,  6.77s/it]{'loss': 0.178349609375, 'learning_rate': 2.388758782201405e-06, 'epoch': 1.5220200380785918}\n",
            "{'loss': 0.20972412109375, 'learning_rate': 2.291178766588603e-06, 'epoch': 1.5415275133431132}\n",
            "                                                       \n",
            " 79%|███████▉  | 2025/2562 [3:49:01<1:00:46,  6.79s/it]\n",
            " 80%|████████  | 2050/2562 [3:51:50<57:46,  6.77s/it]\n",
            " 81%|████████  | 2075/2562 [3:54:40<54:56,  6.77s/it]\n",
            "{'loss': 0.19096923828125, 'learning_rate': 1.8032786885245903e-06, 'epoch': 1.63906488966572}\n",
            " 83%|████████▎ | 2125/2562 [4:00:20<49:33,  6.80s/it]{'loss': 0.17572998046875, 'learning_rate': 1.7056986729117879e-06, 'epoch': 1.6585723649302413}\n",
            "                                                     {'loss': 0.18812744140625, 'learning_rate': 1.6081186572989854e-06, 'epoch': 1.6780798401947625}\n",
            " 85%|████████▍ | 2175/2562 [4:05:59<43:44,  6.78s/it]{'loss': 0.1998486328125, 'learning_rate': 1.5105386416861827e-06, 'epoch': 1.697587315459284}\n",
            " 86%|████████▌ | 2200/2562 [4:08:49<40:59,  6.79s/it]\n",
            " 87%|████████▋ | 2225/2562 [4:11:38<38:07,  6.79s/it]\n",
            "{'loss': 0.1230029296875, 'learning_rate': 1.2177985948477752e-06, 'epoch': 1.7561097412528481}\n",
            "                                                     \n",
            "                                                     \n",
            " 91%|█████████ | 2325/2562 [4:22:57<26:49,  6.79s/it]{'loss': 0.2384130859375, 'learning_rate': 9.250585480093678e-07, 'epoch': 1.8146321670464123}\n",
            " 92%|█████████▏| 2350/2562 [4:25:47<23:56,  6.78s/it]\n",
            " 93%|█████████▎| 2375/2562 [4:28:36<21:05,  6.77s/it]{'loss': 0.17011962890625, 'learning_rate': 7.298985167837628e-07, 'epoch': 1.8536471175754548}\n",
            " 94%|█████████▎| 2400/2562 [4:31:26<18:21,  6.80s/it]{'loss': 0.20362060546875, 'learning_rate': 6.323185011709602e-07, 'epoch': 1.8731545928399762}\n",
            " 95%|█████████▍| 2425/2562 [4:34:16<15:31,  6.80s/it]{'loss': 0.19162109375, 'learning_rate': 5.347384855581578e-07, 'epoch': 1.8926620681044977}\n",
            " 96%|█████████▌| 2450/2562 [4:37:06<12:39,  6.78s/it]\n",
            "                                                     {'loss': 0.15906005859375, 'learning_rate': 3.3957845433255274e-07, 'epoch': 1.9316770186335404}\n",
            " 98%|█████████▊| 2500/2562 [4:42:45<07:02,  6.82s/it]{'loss': 0.198203125, 'learning_rate': 2.4199843871975023e-07, 'epoch': 1.9511844938980616}\n",
            " 99%|█████████▊| 2525/2562 [4:45:41<04:11,  6.79s/it]{'loss': 0.232919921875, 'learning_rate': 1.4441842310694772e-07, 'epoch': 1.970691969162583}\n",
            "100%|█████████▉| 2550/2562 [4:48:30<01:21,  6.79s/it]\n",
            "100%|██████████| 2562/2562 [4:49:52<00:00,  6.79s/it]\n",
            "100%|██████████| 2562/2562 [4:49:52<00:00,  6.79s/it]\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/trainer.py:1174: FutureWarning: This method is deprecated, use `Trainer.is_world_process_zero()` instead.\n",
            "  warnings.warn(\"This method is deprecated, use `Trainer.is_world_process_zero()` instead.\", FutureWarning)\n",
            "11/30/2020 15:49:38 - INFO - __main__ -   *** Evaluate ***\n",
            "100%|█████████▉| 2163/2164 [03:13<00:00, 11.15it/s]11/30/2020 15:52:52 - INFO - __main__ -   \n",
            "\n",
            "\n",
            "\n",
            "***** Quail_Dev_Eval Results *****\n",
            "11/30/2020 15:52:52 - INFO - __main__ -     eval_loss = 0.582772433757782\n",
            "11/30/2020 15:52:52 - INFO - __main__ -     eval_acc = 0.83271719038817\n",
            "11/30/2020 15:52:52 - INFO - filelock -   Lock 140667922615544 acquired on ./data/cached_dev_RobertaTokenizer_512_quail-reasoning.lock\n",
            "11/30/2020 15:52:52 - INFO - utils_multiple_choice -   Creating features from dataset file at ./data\n",
            "LOOKING AT ./data dev\n",
            "11/30/2020 15:52:52 - INFO - utils_multiple_choice -   Training examples: 3312\n",
            "\n",
            "convert examples to features: 0it [00:00, ?it/s]\u001b[A11/30/2020 15:52:52 - INFO - utils_multiple_choice -   Writing example 0 of 3312\n",
            "\n",
            "convert examples to features: 9it [00:00, 88.91it/s]\u001b[A\n",
            "convert examples to features: 16it [00:00, 78.70it/s]\u001b[A\n",
            "convert examples to features: 23it [00:00, 73.27it/s]\u001b[A\n",
            "convert examples to features: 33it [00:00, 76.54it/s]\u001b[A\n",
            "convert examples to features: 43it [00:00, 81.76it/s]\u001b[A\n",
            "convert examples to features: 51it [00:00, 79.46it/s]\u001b[A\n",
            "convert examples to features: 60it [00:00, 80.61it/s]\u001b[A\n",
            "convert examples to features: 71it [00:00, 85.42it/s]\u001b[A\n",
            "convert examples to features: 80it [00:00, 82.37it/s]\u001b[A\n",
            "convert examples to features: 91it [00:01, 85.65it/s]\u001b[A\n",
            "convert examples to features: 100it [00:01, 76.21it/s]\u001b[A\n",
            "convert examples to features: 110it [00:01, 79.48it/s]\u001b[A\n",
            "convert examples to features: 119it [00:01, 76.37it/s]\u001b[A\n",
            "convert examples to features: 127it [00:01, 74.98it/s]\u001b[A\n",
            "convert examples to features: 135it [00:01, 75.20it/s]\u001b[A\n",
            "convert examples to features: 143it [00:01, 76.56it/s]\u001b[A\n",
            "convert examples to features: 152it [00:01, 79.22it/s]\u001b[A\n",
            "convert examples to features: 161it [00:02, 80.37it/s]\u001b[A\n",
            "convert examples to features: 170it [00:02, 79.56it/s]\u001b[A\n",
            "convert examples to features: 178it [00:02, 76.66it/s]\u001b[A\n",
            "convert examples to features: 186it [00:02, 76.12it/s]\u001b[A\n",
            "convert examples to features: 194it [00:02, 73.52it/s]\u001b[A\n",
            "convert examples to features: 202it [00:02, 70.52it/s]\u001b[A\n",
            "convert examples to features: 210it [00:02, 68.83it/s]\u001b[A\n",
            "convert examples to features: 218it [00:02, 69.31it/s]\u001b[A\n",
            "convert examples to features: 225it [00:02, 68.72it/s]\u001b[A\n",
            "convert examples to features: 233it [00:03, 71.67it/s]\u001b[A\n",
            "convert examples to features: 241it [00:03, 72.94it/s]\u001b[A\n",
            "convert examples to features: 249it [00:03, 68.95it/s]\u001b[A\n",
            "convert examples to features: 258it [00:03, 73.55it/s]\u001b[A\n",
            "convert examples to features: 266it [00:03, 74.12it/s]\u001b[A\n",
            "convert examples to features: 274it [00:03, 69.38it/s]\u001b[A\n",
            "convert examples to features: 282it [00:03, 71.14it/s]\u001b[A\n",
            "convert examples to features: 290it [00:03, 73.38it/s]\u001b[A\n",
            "convert examples to features: 298it [00:03, 67.25it/s]\u001b[A\n",
            "convert examples to features: 307it [00:04, 71.64it/s]\u001b[A\n",
            "convert examples to features: 317it [00:04, 75.40it/s]\u001b[A\n",
            "convert examples to features: 325it [00:04, 72.83it/s]\u001b[A\n",
            "convert examples to features: 334it [00:04, 74.75it/s]\u001b[A\n",
            "convert examples to features: 342it [00:04, 70.59it/s]\u001b[A\n",
            "convert examples to features: 350it [00:04, 72.42it/s]\u001b[A\n",
            "convert examples to features: 358it [00:04, 70.34it/s]\u001b[A\n",
            "convert examples to features: 367it [00:04, 74.41it/s]\u001b[A\n",
            "convert examples to features: 377it [00:04, 78.80it/s]\u001b[A\n",
            "convert examples to features: 386it [00:05, 75.12it/s]\u001b[A\n",
            "convert examples to features: 394it [00:05, 70.39it/s]\u001b[A\n",
            "convert examples to features: 402it [00:05, 67.17it/s]\u001b[A\n",
            "convert examples to features: 409it [00:05, 67.28it/s]\u001b[A\n",
            "convert examples to features: 419it [00:05, 71.92it/s]\u001b[A\n",
            "convert examples to features: 427it [00:05, 70.49it/s]\u001b[A\n",
            "convert examples to features: 435it [00:05, 69.47it/s]\u001b[A\n",
            "convert examples to features: 443it [00:05, 67.83it/s]\u001b[A\n",
            "convert examples to features: 452it [00:06, 70.44it/s]\u001b[A\n",
            "convert examples to features: 462it [00:06, 75.47it/s]\u001b[A\n",
            "convert examples to features: 470it [00:06, 74.44it/s]\u001b[A\n",
            "convert examples to features: 480it [00:06, 80.40it/s]\u001b[A\n",
            "convert examples to features: 489it [00:06, 74.51it/s]\u001b[A\n",
            "convert examples to features: 497it [00:06, 70.23it/s]\u001b[A\n",
            "convert examples to features: 505it [00:06, 66.17it/s]\u001b[A\n",
            "convert examples to features: 515it [00:06, 71.43it/s]\u001b[A\n",
            "convert examples to features: 524it [00:07, 73.80it/s]\u001b[A\n",
            "convert examples to features: 532it [00:07, 66.84it/s]\u001b[A\n",
            "convert examples to features: 540it [00:07, 69.90it/s]\u001b[A\n",
            "convert examples to features: 548it [00:07, 67.41it/s]\u001b[A\n",
            "convert examples to features: 557it [00:07, 72.36it/s]\u001b[A\n",
            "convert examples to features: 565it [00:07, 72.95it/s]\u001b[A\n",
            "convert examples to features: 573it [00:07, 70.71it/s]\u001b[A\n",
            "convert examples to features: 581it [00:07, 68.77it/s]\u001b[A\n",
            "convert examples to features: 589it [00:07, 70.29it/s]\u001b[A\n",
            "convert examples to features: 597it [00:08, 67.71it/s]\u001b[A\n",
            "convert examples to features: 605it [00:08, 70.03it/s]\u001b[A\n",
            "convert examples to features: 613it [00:08, 71.47it/s]\u001b[A\n",
            "convert examples to features: 624it [00:08, 77.27it/s]\u001b[A\n",
            "convert examples to features: 632it [00:08, 70.18it/s]\u001b[A\n",
            "convert examples to features: 640it [00:08, 71.91it/s]\u001b[A\n",
            "convert examples to features: 648it [00:08, 70.18it/s]\u001b[A\n",
            "convert examples to features: 657it [00:08, 72.29it/s]\u001b[A\n",
            "convert examples to features: 665it [00:09, 72.03it/s]\u001b[A\n",
            "convert examples to features: 673it [00:09, 73.68it/s]\u001b[A\n",
            "convert examples to features: 681it [00:09, 71.02it/s]\u001b[A\n",
            "convert examples to features: 689it [00:09, 68.00it/s]\u001b[A\n",
            "convert examples to features: 698it [00:09, 72.04it/s]\u001b[A\n",
            "convert examples to features: 706it [00:09, 67.66it/s]\u001b[A\n",
            "convert examples to features: 713it [00:09, 68.34it/s]\u001b[A\n",
            "convert examples to features: 722it [00:09, 73.44it/s]\u001b[A\n",
            "convert examples to features: 730it [00:09, 67.76it/s]\u001b[A\n",
            "convert examples to features: 740it [00:10, 72.21it/s]\u001b[A\n",
            "convert examples to features: 749it [00:10, 76.24it/s]\u001b[A\n",
            "convert examples to features: 757it [00:10, 70.62it/s]\u001b[A\n",
            "convert examples to features: 765it [00:10, 69.13it/s]\u001b[A\n",
            "convert examples to features: 773it [00:10, 67.42it/s]\u001b[A\n",
            "convert examples to features: 780it [00:10, 63.02it/s]\u001b[A\n",
            "convert examples to features: 790it [00:10, 68.78it/s]\u001b[A\n",
            "convert examples to features: 798it [00:10, 71.36it/s]\u001b[A\n",
            "convert examples to features: 806it [00:11, 71.34it/s]\u001b[A\n",
            "convert examples to features: 814it [00:11, 70.05it/s]\u001b[A\n",
            "convert examples to features: 822it [00:11, 72.56it/s]\u001b[A\n",
            "convert examples to features: 830it [00:11, 67.88it/s]\u001b[A\n",
            "convert examples to features: 837it [00:11, 64.58it/s]\u001b[A\n",
            "convert examples to features: 845it [00:11, 66.62it/s]\u001b[A\n",
            "convert examples to features: 853it [00:11, 67.09it/s]\u001b[A\n",
            "convert examples to features: 864it [00:11, 74.25it/s]\u001b[A\n",
            "convert examples to features: 873it [00:11, 74.83it/s]\u001b[A\n",
            "convert examples to features: 881it [00:12, 72.75it/s]\u001b[A\n",
            "convert examples to features: 890it [00:12, 76.71it/s]\u001b[A\n",
            "convert examples to features: 898it [00:12, 73.62it/s]\u001b[A\n",
            "convert examples to features: 906it [00:12, 72.38it/s]\u001b[A\n",
            "convert examples to features: 914it [00:12, 72.15it/s]\u001b[A\n",
            "convert examples to features: 922it [00:12, 74.32it/s]\u001b[A\n",
            "convert examples to features: 930it [00:12, 69.52it/s]\u001b[A\n",
            "convert examples to features: 940it [00:12, 73.90it/s]\u001b[A\n",
            "convert examples to features: 948it [00:12, 74.85it/s]\u001b[A\n",
            "convert examples to features: 957it [00:13, 74.68it/s]\u001b[A\n",
            "convert examples to features: 965it [00:13, 73.48it/s]\u001b[A\n",
            "convert examples to features: 973it [00:13, 73.25it/s]\u001b[A\n",
            "convert examples to features: 981it [00:13, 73.51it/s]\u001b[A\n",
            "convert examples to features: 989it [00:13, 72.60it/s]\u001b[A\n",
            "convert examples to features: 997it [00:13, 68.38it/s]\u001b[A11/30/2020 15:53:06 - INFO - utils_multiple_choice -   Writing example 1000 of 3312\n",
            "\n",
            "convert examples to features: 1005it [00:13, 69.77it/s]\u001b[A\n",
            "convert examples to features: 1013it [00:13, 72.06it/s]\u001b[A\n",
            "convert examples to features: 1021it [00:14, 70.11it/s]\u001b[A\n",
            "convert examples to features: 1029it [00:14, 69.12it/s]\u001b[A\n",
            "convert examples to features: 1036it [00:14, 67.46it/s]\u001b[A\n",
            "convert examples to features: 1043it [00:14, 64.93it/s]\u001b[A\n",
            "convert examples to features: 1050it [00:14, 64.99it/s]\u001b[A\n",
            "convert examples to features: 1059it [00:14, 68.85it/s]\u001b[A\n",
            "convert examples to features: 1069it [00:14, 74.04it/s]\u001b[A\n",
            "convert examples to features: 1077it [00:14, 70.58it/s]\u001b[A\n",
            "convert examples to features: 1085it [00:14, 70.15it/s]\u001b[A\n",
            "convert examples to features: 1093it [00:15, 67.15it/s]\u001b[A\n",
            "convert examples to features: 1100it [00:15, 67.23it/s]\u001b[A\n",
            "convert examples to features: 1109it [00:15, 71.38it/s]\u001b[A\n",
            "convert examples to features: 1119it [00:15, 75.97it/s]\u001b[A\n",
            "convert examples to features: 1132it [00:15, 84.45it/s]\u001b[A\n",
            "convert examples to features: 1141it [00:15, 79.28it/s]\u001b[A\n",
            "convert examples to features: 1150it [00:15, 76.59it/s]\u001b[A\n",
            "convert examples to features: 1158it [00:15, 74.97it/s]\u001b[A\n",
            "100%|██████████| 2164/2164 [03:30<00:00, 11.15it/s]\n",
            "convert examples to features: 1178it [00:16, 79.33it/s]\u001b[A\n",
            "convert examples to features: 1187it [00:16, 74.39it/s]\u001b[A\n",
            "convert examples to features: 1196it [00:16, 78.19it/s]\u001b[A\n",
            "convert examples to features: 1205it [00:16, 78.38it/s]\u001b[A\n",
            "convert examples to features: 1215it [00:16, 80.55it/s]\u001b[A\n",
            "convert examples to features: 1224it [00:16, 78.13it/s]\u001b[A\n",
            "convert examples to features: 1232it [00:16, 70.08it/s]\u001b[A\n",
            "convert examples to features: 1240it [00:16, 70.00it/s]\u001b[A\n",
            "convert examples to features: 1248it [00:17, 72.58it/s]\u001b[A\n",
            "convert examples to features: 1256it [00:17, 69.80it/s]\u001b[A\n",
            "convert examples to features: 1264it [00:17, 68.27it/s]\u001b[A\n",
            "convert examples to features: 1275it [00:17, 74.98it/s]\u001b[A\n",
            "convert examples to features: 1283it [00:17, 70.92it/s]\u001b[A\n",
            "convert examples to features: 1293it [00:17, 76.04it/s]\u001b[A\n",
            "convert examples to features: 1301it [00:17, 73.45it/s]\u001b[A\n",
            "convert examples to features: 1309it [00:17, 73.81it/s]\u001b[A\n",
            "convert examples to features: 1319it [00:17, 79.86it/s]\u001b[A\n",
            "convert examples to features: 1328it [00:18, 77.89it/s]\u001b[A\n",
            "convert examples to features: 1339it [00:18, 84.62it/s]\u001b[A\n",
            "convert examples to features: 1348it [00:18, 79.96it/s]\u001b[A\n",
            "convert examples to features: 1360it [00:18, 87.98it/s]\u001b[A\n",
            "convert examples to features: 1370it [00:18, 89.85it/s]\u001b[A\n",
            "convert examples to features: 1380it [00:18, 83.31it/s]\u001b[A\n",
            "convert examples to features: 1389it [00:18, 79.91it/s]\u001b[A\n",
            "convert examples to features: 1398it [00:18, 75.49it/s]\u001b[A\n",
            "convert examples to features: 1406it [00:19, 73.18it/s]\u001b[A\n",
            "convert examples to features: 1415it [00:19, 74.70it/s]\u001b[A\n",
            "convert examples to features: 1423it [00:19, 70.87it/s]\u001b[A\n",
            "convert examples to features: 1432it [00:19, 74.90it/s]\u001b[A\n",
            "convert examples to features: 1440it [00:19, 71.12it/s]\u001b[A\n",
            "convert examples to features: 1450it [00:19, 77.10it/s]\u001b[A\n",
            "convert examples to features: 1459it [00:19, 79.27it/s]\u001b[A\n",
            "convert examples to features: 1468it [00:19, 72.45it/s]\u001b[A\n",
            "convert examples to features: 1476it [00:19, 73.84it/s]\u001b[A\n",
            "convert examples to features: 1484it [00:20, 71.76it/s]\u001b[A\n",
            "convert examples to features: 1492it [00:20, 72.60it/s]\u001b[A\n",
            "convert examples to features: 1500it [00:20, 64.40it/s]\u001b[A\n",
            "convert examples to features: 1507it [00:20, 65.46it/s]\u001b[A\n",
            "convert examples to features: 1515it [00:20, 67.89it/s]\u001b[A\n",
            "convert examples to features: 1523it [00:20, 68.64it/s]\u001b[A\n",
            "convert examples to features: 1532it [00:20, 72.19it/s]\u001b[A\n",
            "convert examples to features: 1542it [00:20, 76.82it/s]\u001b[A\n",
            "convert examples to features: 1550it [00:21, 77.47it/s]\u001b[A\n",
            "convert examples to features: 1558it [00:21, 75.30it/s]\u001b[A\n",
            "convert examples to features: 1566it [00:21, 70.41it/s]\u001b[A\n",
            "convert examples to features: 1577it [00:21, 77.94it/s]\u001b[A\n",
            "convert examples to features: 1586it [00:21, 76.85it/s]\u001b[A\n",
            "convert examples to features: 1594it [00:21, 70.06it/s]\u001b[A\n",
            "convert examples to features: 1602it [00:21, 72.23it/s]\u001b[A\n",
            "convert examples to features: 1611it [00:21, 74.07it/s]\u001b[A\n",
            "convert examples to features: 1620it [00:21, 77.21it/s]\u001b[A\n",
            "convert examples to features: 1630it [00:22, 80.12it/s]\u001b[A\n",
            "convert examples to features: 1639it [00:22, 79.38it/s]\u001b[A\n",
            "convert examples to features: 1648it [00:22, 82.04it/s]\u001b[A\n",
            "convert examples to features: 1657it [00:22, 75.28it/s]\u001b[A\n",
            "convert examples to features: 1666it [00:22, 78.65it/s]\u001b[A\n",
            "convert examples to features: 1675it [00:22, 72.41it/s]\u001b[A\n",
            "convert examples to features: 1684it [00:22, 75.68it/s]\u001b[A\n",
            "convert examples to features: 1692it [00:22, 76.85it/s]\u001b[A\n",
            "convert examples to features: 1702it [00:22, 82.21it/s]\u001b[A\n",
            "convert examples to features: 1711it [00:23, 76.73it/s]\u001b[A\n",
            "convert examples to features: 1719it [00:23, 76.92it/s]\u001b[A\n",
            "convert examples to features: 1730it [00:23, 82.69it/s]\u001b[A\n",
            "convert examples to features: 1739it [00:23, 83.49it/s]\u001b[A\n",
            "convert examples to features: 1748it [00:23, 80.76it/s]\u001b[A\n",
            "convert examples to features: 1757it [00:23, 82.92it/s]\u001b[A\n",
            "convert examples to features: 1766it [00:23, 81.21it/s]\u001b[A\n",
            "convert examples to features: 1775it [00:23, 78.34it/s]\u001b[A\n",
            "convert examples to features: 1786it [00:23, 85.54it/s]\u001b[A\n",
            "convert examples to features: 1795it [00:24, 76.80it/s]\u001b[A\n",
            "convert examples to features: 1804it [00:24, 74.57it/s]\u001b[A\n",
            "convert examples to features: 1816it [00:24, 84.11it/s]\u001b[A\n",
            "convert examples to features: 1825it [00:24, 80.51it/s]\u001b[A\n",
            "convert examples to features: 1835it [00:24, 83.16it/s]\u001b[A\n",
            "convert examples to features: 1844it [00:24, 82.41it/s]\u001b[A\n",
            "convert examples to features: 1853it [00:24, 81.62it/s]\u001b[A\n",
            "convert examples to features: 1862it [00:24, 72.67it/s]\u001b[A\n",
            "convert examples to features: 1871it [00:25, 74.67it/s]\u001b[A\n",
            "convert examples to features: 1880it [00:25, 74.97it/s]\u001b[A\n",
            "convert examples to features: 1888it [00:25, 72.70it/s]\u001b[A\n",
            "convert examples to features: 1896it [00:25, 73.57it/s]\u001b[A\n",
            "convert examples to features: 1904it [00:25, 71.07it/s]\u001b[A\n",
            "convert examples to features: 1912it [00:25, 69.78it/s]\u001b[A\n",
            "convert examples to features: 1920it [00:25, 72.01it/s]\u001b[A\n",
            "convert examples to features: 1928it [00:25, 69.46it/s]\u001b[A\n",
            "convert examples to features: 1936it [00:26, 66.09it/s]\u001b[A\n",
            "convert examples to features: 1943it [00:26, 63.71it/s]\u001b[A\n",
            "convert examples to features: 1951it [00:26, 65.79it/s]\u001b[A\n",
            "convert examples to features: 1961it [00:26, 71.39it/s]\u001b[A\n",
            "convert examples to features: 1969it [00:26, 71.52it/s]\u001b[A\n",
            "convert examples to features: 1978it [00:26, 75.98it/s]\u001b[A\n",
            "convert examples to features: 1986it [00:26, 74.45it/s]\u001b[A\n",
            "convert examples to features: 1995it [00:26, 78.26it/s]\u001b[A11/30/2020 15:53:19 - INFO - utils_multiple_choice -   Writing example 2000 of 3312\n",
            "\n",
            "convert examples to features: 2003it [00:26, 76.35it/s]\u001b[A\n",
            "convert examples to features: 2012it [00:27, 79.72it/s]\u001b[A\n",
            "convert examples to features: 2021it [00:27, 77.18it/s]\u001b[A\n",
            "convert examples to features: 2030it [00:27, 78.43it/s]\u001b[A\n",
            "convert examples to features: 2039it [00:27, 80.04it/s]\u001b[A\n",
            "convert examples to features: 2048it [00:27, 77.62it/s]\u001b[A\n",
            "convert examples to features: 2057it [00:27, 80.19it/s]\u001b[A\n",
            "convert examples to features: 2066it [00:27, 75.95it/s]\u001b[A\n",
            "convert examples to features: 2074it [00:27, 73.61it/s]\u001b[A\n",
            "convert examples to features: 2082it [00:27, 73.22it/s]\u001b[A\n",
            "convert examples to features: 2090it [00:28, 71.31it/s]\u001b[A\n",
            "convert examples to features: 2098it [00:28, 67.01it/s]\u001b[A\n",
            "convert examples to features: 2105it [00:28, 66.37it/s]\u001b[A\n",
            "convert examples to features: 2112it [00:28, 65.57it/s]\u001b[A\n",
            "convert examples to features: 2119it [00:28, 66.48it/s]\u001b[A\n",
            "convert examples to features: 2126it [00:28, 64.59it/s]\u001b[A\n",
            "convert examples to features: 2135it [00:28, 68.21it/s]\u001b[A\n",
            "convert examples to features: 2143it [00:28, 70.69it/s]\u001b[A\n",
            "convert examples to features: 2151it [00:28, 68.78it/s]\u001b[A\n",
            "convert examples to features: 2159it [00:29, 69.58it/s]\u001b[A\n",
            "convert examples to features: 2167it [00:29, 66.22it/s]\u001b[A\n",
            "convert examples to features: 2175it [00:29, 68.97it/s]\u001b[A\n",
            "convert examples to features: 2183it [00:29, 70.03it/s]\u001b[A\n",
            "convert examples to features: 2191it [00:29, 71.38it/s]\u001b[A\n",
            "convert examples to features: 2200it [00:29, 75.69it/s]\u001b[A\n",
            "convert examples to features: 2208it [00:29, 74.62it/s]\u001b[A\n",
            "convert examples to features: 2216it [00:29, 76.09it/s]\u001b[A\n",
            "convert examples to features: 2224it [00:30, 68.82it/s]\u001b[A\n",
            "convert examples to features: 2232it [00:30, 68.07it/s]\u001b[A\n",
            "convert examples to features: 2241it [00:30, 71.28it/s]\u001b[A\n",
            "convert examples to features: 2249it [00:30, 71.35it/s]\u001b[A\n",
            "convert examples to features: 2257it [00:30, 70.28it/s]\u001b[A\n",
            "convert examples to features: 2265it [00:30, 69.12it/s]\u001b[A\n",
            "convert examples to features: 2272it [00:30, 66.56it/s]\u001b[A\n",
            "convert examples to features: 2279it [00:30, 64.19it/s]\u001b[A\n",
            "convert examples to features: 2287it [00:30, 67.94it/s]\u001b[A\n",
            "convert examples to features: 2296it [00:31, 70.46it/s]\u001b[A\n",
            "convert examples to features: 2304it [00:31, 68.93it/s]\u001b[A\n",
            "convert examples to features: 2311it [00:31, 65.88it/s]\u001b[A\n",
            "convert examples to features: 2318it [00:31, 64.14it/s]\u001b[A\n",
            "convert examples to features: 2326it [00:31, 68.19it/s]\u001b[A\n",
            "convert examples to features: 2335it [00:31, 73.13it/s]\u001b[A\n",
            "convert examples to features: 2344it [00:31, 76.20it/s]\u001b[A\n",
            "convert examples to features: 2354it [00:31, 79.40it/s]\u001b[A\n",
            "convert examples to features: 2363it [00:31, 75.68it/s]\u001b[A\n",
            "convert examples to features: 2371it [00:32, 71.29it/s]\u001b[A\n",
            "convert examples to features: 2382it [00:32, 78.62it/s]\u001b[A\n",
            "convert examples to features: 2391it [00:32, 78.99it/s]\u001b[A\n",
            "convert examples to features: 2404it [00:32, 87.14it/s]\u001b[A\n",
            "convert examples to features: 2414it [00:32, 87.56it/s]\u001b[A\n",
            "convert examples to features: 2424it [00:32, 82.11it/s]\u001b[A\n",
            "convert examples to features: 2433it [00:32, 75.30it/s]\u001b[A\n",
            "convert examples to features: 2441it [00:32, 75.04it/s]\u001b[A\n",
            "convert examples to features: 2449it [00:33, 74.00it/s]\u001b[A\n",
            "convert examples to features: 2459it [00:33, 77.15it/s]\u001b[A\n",
            "convert examples to features: 2467it [00:33, 72.23it/s]\u001b[A\n",
            "convert examples to features: 2476it [00:33, 72.91it/s]\u001b[A\n",
            "convert examples to features: 2485it [00:33, 73.75it/s]\u001b[A\n",
            "convert examples to features: 2494it [00:33, 77.88it/s]\u001b[A\n",
            "convert examples to features: 2503it [00:33, 79.22it/s]\u001b[A\n",
            "convert examples to features: 2512it [00:33, 78.95it/s]\u001b[A\n",
            "convert examples to features: 2524it [00:33, 84.79it/s]\u001b[A\n",
            "convert examples to features: 2534it [00:34, 85.28it/s]\u001b[A\n",
            "convert examples to features: 2543it [00:34, 82.97it/s]\u001b[A\n",
            "convert examples to features: 2552it [00:34, 79.12it/s]\u001b[A\n",
            "convert examples to features: 2561it [00:34, 77.86it/s]\u001b[A\n",
            "convert examples to features: 2569it [00:34, 75.32it/s]\u001b[A\n",
            "convert examples to features: 2577it [00:34, 69.51it/s]\u001b[A\n",
            "convert examples to features: 2585it [00:34, 66.13it/s]\u001b[A\n",
            "convert examples to features: 2593it [00:34, 69.03it/s]\u001b[A\n",
            "convert examples to features: 2601it [00:35, 70.08it/s]\u001b[A\n",
            "convert examples to features: 2610it [00:35, 72.48it/s]\u001b[A\n",
            "convert examples to features: 2618it [00:35, 70.46it/s]\u001b[A\n",
            "convert examples to features: 2630it [00:35, 77.83it/s]\u001b[A\n",
            "convert examples to features: 2639it [00:35, 74.33it/s]\u001b[A\n",
            "convert examples to features: 2647it [00:35, 71.65it/s]\u001b[A\n",
            "convert examples to features: 2656it [00:35, 75.84it/s]\u001b[A\n",
            "convert examples to features: 2665it [00:35, 76.82it/s]\u001b[A\n",
            "convert examples to features: 2673it [00:35, 75.68it/s]\u001b[A\n",
            "convert examples to features: 2681it [00:36, 73.84it/s]\u001b[A\n",
            "convert examples to features: 2689it [00:36, 74.02it/s]\u001b[A\n",
            "convert examples to features: 2699it [00:36, 77.38it/s]\u001b[A\n",
            "convert examples to features: 2707it [00:36, 74.27it/s]\u001b[A\n",
            "convert examples to features: 2715it [00:36, 75.32it/s]\u001b[A\n",
            "convert examples to features: 2723it [00:36, 73.64it/s]\u001b[A\n",
            "convert examples to features: 2731it [00:36, 72.39it/s]\u001b[A\n",
            "convert examples to features: 2739it [00:36, 73.14it/s]\u001b[A\n",
            "convert examples to features: 2747it [00:36, 72.53it/s]\u001b[A\n",
            "convert examples to features: 2755it [00:37, 71.19it/s]\u001b[A\n",
            "convert examples to features: 2764it [00:37, 75.53it/s]\u001b[A\n",
            "convert examples to features: 2772it [00:37, 70.26it/s]\u001b[A\n",
            "convert examples to features: 2781it [00:37, 73.14it/s]\u001b[A\n",
            "convert examples to features: 2789it [00:37, 69.75it/s]\u001b[A\n",
            "convert examples to features: 2797it [00:37, 70.38it/s]\u001b[A\n",
            "convert examples to features: 2805it [00:37, 71.83it/s]\u001b[A\n",
            "convert examples to features: 2814it [00:37, 74.16it/s]\u001b[A\n",
            "convert examples to features: 2822it [00:37, 72.10it/s]\u001b[A\n",
            "convert examples to features: 2831it [00:38, 74.21it/s]\u001b[A\n",
            "convert examples to features: 2839it [00:38, 73.96it/s]\u001b[A\n",
            "convert examples to features: 2847it [00:38, 73.24it/s]\u001b[A\n",
            "convert examples to features: 2856it [00:38, 77.32it/s]\u001b[A\n",
            "convert examples to features: 2865it [00:38, 77.69it/s]\u001b[A\n",
            "convert examples to features: 2873it [00:38, 76.99it/s]\u001b[A\n",
            "convert examples to features: 2881it [00:38, 71.99it/s]\u001b[A\n",
            "convert examples to features: 2889it [00:38, 69.81it/s]\u001b[A\n",
            "convert examples to features: 2897it [00:39, 67.68it/s]\u001b[A\n",
            "convert examples to features: 2904it [00:39, 67.18it/s]\u001b[A\n",
            "convert examples to features: 2912it [00:39, 67.83it/s]\u001b[A\n",
            "convert examples to features: 2919it [00:39, 66.43it/s]\u001b[A\n",
            "convert examples to features: 2926it [00:39, 65.88it/s]\u001b[A\n",
            "convert examples to features: 2934it [00:39, 67.27it/s]\u001b[A\n",
            "convert examples to features: 2941it [00:39, 64.29it/s]\u001b[A\n",
            "convert examples to features: 2948it [00:39, 64.84it/s]\u001b[A\n",
            "convert examples to features: 2955it [00:39, 65.81it/s]\u001b[A\n",
            "convert examples to features: 2963it [00:40, 68.09it/s]\u001b[A\n",
            "convert examples to features: 2970it [00:40, 67.33it/s]\u001b[A\n",
            "convert examples to features: 2979it [00:40, 72.49it/s]\u001b[A\n",
            "convert examples to features: 2987it [00:40, 67.11it/s]\u001b[A\n",
            "convert examples to features: 2994it [00:40, 65.77it/s]\u001b[A11/30/2020 15:53:33 - INFO - utils_multiple_choice -   Writing example 3000 of 3312\n",
            "\n",
            "convert examples to features: 3002it [00:40, 67.96it/s]\u001b[A\n",
            "convert examples to features: 3010it [00:40, 69.96it/s]\u001b[A\n",
            "convert examples to features: 3018it [00:40, 69.15it/s]\u001b[A\n",
            "convert examples to features: 3027it [00:40, 73.63it/s]\u001b[A\n",
            "convert examples to features: 3035it [00:41, 70.83it/s]\u001b[A\n",
            "convert examples to features: 3043it [00:41, 69.91it/s]\u001b[A\n",
            "convert examples to features: 3051it [00:41, 69.42it/s]\u001b[A\n",
            "convert examples to features: 3058it [00:41, 69.31it/s]\u001b[A\n",
            "convert examples to features: 3066it [00:41, 70.17it/s]\u001b[A\n",
            "convert examples to features: 3074it [00:41, 72.21it/s]\u001b[A\n",
            "convert examples to features: 3082it [00:41, 74.24it/s]\u001b[A\n",
            "convert examples to features: 3091it [00:41, 77.83it/s]\u001b[A\n",
            "convert examples to features: 3099it [00:41, 74.29it/s]\u001b[A\n",
            "convert examples to features: 3107it [00:42, 75.51it/s]\u001b[A\n",
            "convert examples to features: 3115it [00:42, 75.21it/s]\u001b[A\n",
            "convert examples to features: 3123it [00:42, 75.62it/s]\u001b[A\n",
            "convert examples to features: 3132it [00:42, 78.55it/s]\u001b[A\n",
            "convert examples to features: 3140it [00:42, 74.88it/s]\u001b[A\n",
            "convert examples to features: 3151it [00:42, 80.74it/s]\u001b[A\n",
            "convert examples to features: 3160it [00:42, 75.19it/s]\u001b[A\n",
            "convert examples to features: 3170it [00:42, 80.34it/s]\u001b[A\n",
            "convert examples to features: 3179it [00:42, 74.74it/s]\u001b[A\n",
            "convert examples to features: 3187it [00:43, 72.61it/s]\u001b[A\n",
            "convert examples to features: 3195it [00:43, 69.80it/s]\u001b[A\n",
            "convert examples to features: 3203it [00:43, 68.41it/s]\u001b[A\n",
            "convert examples to features: 3212it [00:43, 72.36it/s]\u001b[A\n",
            "convert examples to features: 3220it [00:43, 70.85it/s]\u001b[A\n",
            "convert examples to features: 3228it [00:43, 70.49it/s]\u001b[A\n",
            "convert examples to features: 3237it [00:43, 73.91it/s]\u001b[A\n",
            "convert examples to features: 3245it [00:43, 73.92it/s]\u001b[A\n",
            "convert examples to features: 3253it [00:43, 74.32it/s]\u001b[A\n",
            "convert examples to features: 3262it [00:44, 76.69it/s]\u001b[A\n",
            "convert examples to features: 3270it [00:44, 74.51it/s]\u001b[A\n",
            "convert examples to features: 3279it [00:44, 76.61it/s]\u001b[A\n",
            "convert examples to features: 3287it [00:44, 73.68it/s]\u001b[A\n",
            "convert examples to features: 3295it [00:44, 70.96it/s]\u001b[A\n",
            "convert examples to features: 3303it [00:44, 69.78it/s]\u001b[A\n",
            "convert examples to features: 3312it [00:44, 73.90it/s]\n",
            "11/30/2020 15:53:37 - INFO - utils_multiple_choice -   *** Example ***\n",
            "11/30/2020 15:53:37 - INFO - utils_multiple_choice -   feature: InputFeatures(example_id='u156_15', input_ids=[[0, 791, 5471, 1174, 100, 206, 42, 2263, 127, 1354, 4, 50118, 2387, 8733, 2138, 34, 460, 56, 41, 31232, 13, 5425, 10029, 578, 37790, 5556, 6, 326, 19112, 38215, 6, 380, 7, 37994, 784, 39700, 4, 370, 766, 24, 8, 37, 17, 27, 29, 1153, 7521, 24, 4, 96, 754, 6, 37, 202, 4618, 23, 41, 19265, 3477, 5159, 61, 16, 184, 7, 10, 739, 3143, 9, 167, 15785, 15916, 6, 8, 127, 793, 1441, 735, 36330, 4, 50118, 10787, 107, 536, 6, 38, 439, 7, 825, 127, 985, 147, 37, 202, 3033, 6, 160, 8, 15, 6, 25, 24, 21, 2789, 7, 39, 633, 87, 39, 92, 3537, 4, 38, 1102, 7, 213, 88, 39, 929, 8, 5324, 10, 1637, 25114, 8319, 2233, 59, 237, 50, 292, 4877, 3925, 4, 39273, 219, 25, 38, 524, 6, 38, 56, 7, 490, 24, 4, 50118, 243, 5558, 5, 7722, 1931, 366, 44869, 9, 10, 739, 42175, 5718, 8, 909, 326, 19112, 5571, 4, 44218, 219, 25, 14, 21, 6, 24, 399, 17, 27, 90, 15304, 6, 50, 190, 2755, 162, 203, 6, 25, 38, 1467, 127, 2138, 429, 489, 402, 101, 14, 11, 39, 929, 4, 50118, 21674, 41, 1946, 423, 6, 37, 373, 7, 224, 20760, 8, 2528, 38, 185, 10, 356, 23, 5, 1637, 2233, 11, 39, 929, 4, 38, 174, 123, 14, 38, 416, 56, 6, 53, 38, 2738, 24, 62, 456, 7, 185, 277, 356, 6, 150, 37, 174, 162, 59, 2494, 39, 4716, 7722, 24, 4, 50118, 2387, 80, 76, 793, 1354, 21, 39789, 10691, 59, 5, 13654, 9, 5, 1256, 2233, 6, 98, 38, 969, 24, 7, 69, 4, 50118, 12583, 39485, 5021, 4, 83, 5021, 98, 1099, 24, 197, 33, 57, 2292, 22697, 4, 50118, 2515, 362, 65, 356, 23, 24, 6, 1224, 1104, 8, 23472, 46754, 1329, 4, 38, 17, 27, 548, 393, 450, 951, 98, 19419, 4, 50118, 10643, 768, 38, 222, 99, 38, 115, 7, 20759, 69, 4, 38, 2002, 14, 24, 21, 5, 380, 34558, 44, 48, 279, 809, 17, 46, 8, 14, 24, 888, 3033, 23, 69, 542, 20639, 97, 790, 4, 50118, 1708, 6, 1717, 5471, 4, 479, 479, 100, 4443, 38, 938, 17, 27, 90, 269, 203, 9, 10, 23303, 8, 2969, 4252, 6, 142, 81, 5, 220, 891, 107, 38, 20711, 69, 19, 10, 9755, 10771, 29499, 6, 10, 821, 22383, 326, 19112, 5571, 8, 44, 48, 34868, 2462, 219, 10802, 62, 5, 3124, 4, 17, 46, 2, 2, 6179, 251, 34, 5, 2138, 56, 39, 633, 116, 35177, 1215, 8009, 1571, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 791, 5471, 1174, 100, 206, 42, 2263, 127, 1354, 4, 50118, 2387, 8733, 2138, 34, 460, 56, 41, 31232, 13, 5425, 10029, 578, 37790, 5556, 6, 326, 19112, 38215, 6, 380, 7, 37994, 784, 39700, 4, 370, 766, 24, 8, 37, 17, 27, 29, 1153, 7521, 24, 4, 96, 754, 6, 37, 202, 4618, 23, 41, 19265, 3477, 5159, 61, 16, 184, 7, 10, 739, 3143, 9, 167, 15785, 15916, 6, 8, 127, 793, 1441, 735, 36330, 4, 50118, 10787, 107, 536, 6, 38, 439, 7, 825, 127, 985, 147, 37, 202, 3033, 6, 160, 8, 15, 6, 25, 24, 21, 2789, 7, 39, 633, 87, 39, 92, 3537, 4, 38, 1102, 7, 213, 88, 39, 929, 8, 5324, 10, 1637, 25114, 8319, 2233, 59, 237, 50, 292, 4877, 3925, 4, 39273, 219, 25, 38, 524, 6, 38, 56, 7, 490, 24, 4, 50118, 243, 5558, 5, 7722, 1931, 366, 44869, 9, 10, 739, 42175, 5718, 8, 909, 326, 19112, 5571, 4, 44218, 219, 25, 14, 21, 6, 24, 399, 17, 27, 90, 15304, 6, 50, 190, 2755, 162, 203, 6, 25, 38, 1467, 127, 2138, 429, 489, 402, 101, 14, 11, 39, 929, 4, 50118, 21674, 41, 1946, 423, 6, 37, 373, 7, 224, 20760, 8, 2528, 38, 185, 10, 356, 23, 5, 1637, 2233, 11, 39, 929, 4, 38, 174, 123, 14, 38, 416, 56, 6, 53, 38, 2738, 24, 62, 456, 7, 185, 277, 356, 6, 150, 37, 174, 162, 59, 2494, 39, 4716, 7722, 24, 4, 50118, 2387, 80, 76, 793, 1354, 21, 39789, 10691, 59, 5, 13654, 9, 5, 1256, 2233, 6, 98, 38, 969, 24, 7, 69, 4, 50118, 12583, 39485, 5021, 4, 83, 5021, 98, 1099, 24, 197, 33, 57, 2292, 22697, 4, 50118, 2515, 362, 65, 356, 23, 24, 6, 1224, 1104, 8, 23472, 46754, 1329, 4, 38, 17, 27, 548, 393, 450, 951, 98, 19419, 4, 50118, 10643, 768, 38, 222, 99, 38, 115, 7, 20759, 69, 4, 38, 2002, 14, 24, 21, 5, 380, 34558, 44, 48, 279, 809, 17, 46, 8, 14, 24, 888, 3033, 23, 69, 542, 20639, 97, 790, 4, 50118, 1708, 6, 1717, 5471, 4, 479, 479, 100, 4443, 38, 938, 17, 27, 90, 269, 203, 9, 10, 23303, 8, 2969, 4252, 6, 142, 81, 5, 220, 891, 107, 38, 20711, 69, 19, 10, 9755, 10771, 29499, 6, 10, 821, 22383, 326, 19112, 5571, 8, 44, 48, 34868, 2462, 219, 10802, 62, 5, 3124, 4, 17, 46, 2, 2, 6179, 251, 34, 5, 2138, 56, 39, 633, 116, 8316, 687, 6948, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 791, 5471, 1174, 100, 206, 42, 2263, 127, 1354, 4, 50118, 2387, 8733, 2138, 34, 460, 56, 41, 31232, 13, 5425, 10029, 578, 37790, 5556, 6, 326, 19112, 38215, 6, 380, 7, 37994, 784, 39700, 4, 370, 766, 24, 8, 37, 17, 27, 29, 1153, 7521, 24, 4, 96, 754, 6, 37, 202, 4618, 23, 41, 19265, 3477, 5159, 61, 16, 184, 7, 10, 739, 3143, 9, 167, 15785, 15916, 6, 8, 127, 793, 1441, 735, 36330, 4, 50118, 10787, 107, 536, 6, 38, 439, 7, 825, 127, 985, 147, 37, 202, 3033, 6, 160, 8, 15, 6, 25, 24, 21, 2789, 7, 39, 633, 87, 39, 92, 3537, 4, 38, 1102, 7, 213, 88, 39, 929, 8, 5324, 10, 1637, 25114, 8319, 2233, 59, 237, 50, 292, 4877, 3925, 4, 39273, 219, 25, 38, 524, 6, 38, 56, 7, 490, 24, 4, 50118, 243, 5558, 5, 7722, 1931, 366, 44869, 9, 10, 739, 42175, 5718, 8, 909, 326, 19112, 5571, 4, 44218, 219, 25, 14, 21, 6, 24, 399, 17, 27, 90, 15304, 6, 50, 190, 2755, 162, 203, 6, 25, 38, 1467, 127, 2138, 429, 489, 402, 101, 14, 11, 39, 929, 4, 50118, 21674, 41, 1946, 423, 6, 37, 373, 7, 224, 20760, 8, 2528, 38, 185, 10, 356, 23, 5, 1637, 2233, 11, 39, 929, 4, 38, 174, 123, 14, 38, 416, 56, 6, 53, 38, 2738, 24, 62, 456, 7, 185, 277, 356, 6, 150, 37, 174, 162, 59, 2494, 39, 4716, 7722, 24, 4, 50118, 2387, 80, 76, 793, 1354, 21, 39789, 10691, 59, 5, 13654, 9, 5, 1256, 2233, 6, 98, 38, 969, 24, 7, 69, 4, 50118, 12583, 39485, 5021, 4, 83, 5021, 98, 1099, 24, 197, 33, 57, 2292, 22697, 4, 50118, 2515, 362, 65, 356, 23, 24, 6, 1224, 1104, 8, 23472, 46754, 1329, 4, 38, 17, 27, 548, 393, 450, 951, 98, 19419, 4, 50118, 10643, 768, 38, 222, 99, 38, 115, 7, 20759, 69, 4, 38, 2002, 14, 24, 21, 5, 380, 34558, 44, 48, 279, 809, 17, 46, 8, 14, 24, 888, 3033, 23, 69, 542, 20639, 97, 790, 4, 50118, 1708, 6, 1717, 5471, 4, 479, 479, 100, 4443, 38, 938, 17, 27, 90, 269, 203, 9, 10, 23303, 8, 2969, 4252, 6, 142, 81, 5, 220, 891, 107, 38, 20711, 69, 19, 10, 9755, 10771, 29499, 6, 10, 821, 22383, 326, 19112, 5571, 8, 44, 48, 34868, 2462, 219, 10802, 62, 5, 3124, 4, 17, 46, 2, 2, 6179, 251, 34, 5, 2138, 56, 39, 633, 116, 11373, 1215, 41218, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 791, 5471, 1174, 100, 206, 42, 2263, 127, 1354, 4, 50118, 2387, 8733, 2138, 34, 460, 56, 41, 31232, 13, 5425, 10029, 578, 37790, 5556, 6, 326, 19112, 38215, 6, 380, 7, 37994, 784, 39700, 4, 370, 766, 24, 8, 37, 17, 27, 29, 1153, 7521, 24, 4, 96, 754, 6, 37, 202, 4618, 23, 41, 19265, 3477, 5159, 61, 16, 184, 7, 10, 739, 3143, 9, 167, 15785, 15916, 6, 8, 127, 793, 1441, 735, 36330, 4, 50118, 10787, 107, 536, 6, 38, 439, 7, 825, 127, 985, 147, 37, 202, 3033, 6, 160, 8, 15, 6, 25, 24, 21, 2789, 7, 39, 633, 87, 39, 92, 3537, 4, 38, 1102, 7, 213, 88, 39, 929, 8, 5324, 10, 1637, 25114, 8319, 2233, 59, 237, 50, 292, 4877, 3925, 4, 39273, 219, 25, 38, 524, 6, 38, 56, 7, 490, 24, 4, 50118, 243, 5558, 5, 7722, 1931, 366, 44869, 9, 10, 739, 42175, 5718, 8, 909, 326, 19112, 5571, 4, 44218, 219, 25, 14, 21, 6, 24, 399, 17, 27, 90, 15304, 6, 50, 190, 2755, 162, 203, 6, 25, 38, 1467, 127, 2138, 429, 489, 402, 101, 14, 11, 39, 929, 4, 50118, 21674, 41, 1946, 423, 6, 37, 373, 7, 224, 20760, 8, 2528, 38, 185, 10, 356, 23, 5, 1637, 2233, 11, 39, 929, 4, 38, 174, 123, 14, 38, 416, 56, 6, 53, 38, 2738, 24, 62, 456, 7, 185, 277, 356, 6, 150, 37, 174, 162, 59, 2494, 39, 4716, 7722, 24, 4, 50118, 2387, 80, 76, 793, 1354, 21, 39789, 10691, 59, 5, 13654, 9, 5, 1256, 2233, 6, 98, 38, 969, 24, 7, 69, 4, 50118, 12583, 39485, 5021, 4, 83, 5021, 98, 1099, 24, 197, 33, 57, 2292, 22697, 4, 50118, 2515, 362, 65, 356, 23, 24, 6, 1224, 1104, 8, 23472, 46754, 1329, 4, 38, 17, 27, 548, 393, 450, 951, 98, 19419, 4, 50118, 10643, 768, 38, 222, 99, 38, 115, 7, 20759, 69, 4, 38, 2002, 14, 24, 21, 5, 380, 34558, 44, 48, 279, 809, 17, 46, 8, 14, 24, 888, 3033, 23, 69, 542, 20639, 97, 790, 4, 50118, 1708, 6, 1717, 5471, 4, 479, 479, 100, 4443, 38, 938, 17, 27, 90, 269, 203, 9, 10, 23303, 8, 2969, 4252, 6, 142, 81, 5, 220, 891, 107, 38, 20711, 69, 19, 10, 9755, 10771, 29499, 6, 10, 821, 22383, 326, 19112, 5571, 8, 44, 48, 34868, 2462, 219, 10802, 62, 5, 3124, 4, 17, 46, 2, 2, 6179, 251, 34, 5, 2138, 56, 39, 633, 116, 4052, 39022, 1215, 4897, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 791, 5471, 1174, 100, 206, 42, 2263, 127, 1354, 4, 50118, 2387, 8733, 2138, 34, 460, 56, 41, 31232, 13, 5425, 10029, 578, 37790, 5556, 6, 326, 19112, 38215, 6, 380, 7, 37994, 784, 39700, 4, 370, 766, 24, 8, 37, 17, 27, 29, 1153, 7521, 24, 4, 96, 754, 6, 37, 202, 4618, 23, 41, 19265, 3477, 5159, 61, 16, 184, 7, 10, 739, 3143, 9, 167, 15785, 15916, 6, 8, 127, 793, 1441, 735, 36330, 4, 50118, 10787, 107, 536, 6, 38, 439, 7, 825, 127, 985, 147, 37, 202, 3033, 6, 160, 8, 15, 6, 25, 24, 21, 2789, 7, 39, 633, 87, 39, 92, 3537, 4, 38, 1102, 7, 213, 88, 39, 929, 8, 5324, 10, 1637, 25114, 8319, 2233, 59, 237, 50, 292, 4877, 3925, 4, 39273, 219, 25, 38, 524, 6, 38, 56, 7, 490, 24, 4, 50118, 243, 5558, 5, 7722, 1931, 366, 44869, 9, 10, 739, 42175, 5718, 8, 909, 326, 19112, 5571, 4, 44218, 219, 25, 14, 21, 6, 24, 399, 17, 27, 90, 15304, 6, 50, 190, 2755, 162, 203, 6, 25, 38, 1467, 127, 2138, 429, 489, 402, 101, 14, 11, 39, 929, 4, 50118, 21674, 41, 1946, 423, 6, 37, 373, 7, 224, 20760, 8, 2528, 38, 185, 10, 356, 23, 5, 1637, 2233, 11, 39, 929, 4, 38, 174, 123, 14, 38, 416, 56, 6, 53, 38, 2738, 24, 62, 456, 7, 185, 277, 356, 6, 150, 37, 174, 162, 59, 2494, 39, 4716, 7722, 24, 4, 50118, 2387, 80, 76, 793, 1354, 21, 39789, 10691, 59, 5, 13654, 9, 5, 1256, 2233, 6, 98, 38, 969, 24, 7, 69, 4, 50118, 12583, 39485, 5021, 4, 83, 5021, 98, 1099, 24, 197, 33, 57, 2292, 22697, 4, 50118, 2515, 362, 65, 356, 23, 24, 6, 1224, 1104, 8, 23472, 46754, 1329, 4, 38, 17, 27, 548, 393, 450, 951, 98, 19419, 4, 50118, 10643, 768, 38, 222, 99, 38, 115, 7, 20759, 69, 4, 38, 2002, 14, 24, 21, 5, 380, 34558, 44, 48, 279, 809, 17, 46, 8, 14, 24, 888, 3033, 23, 69, 542, 20639, 97, 790, 4, 50118, 1708, 6, 1717, 5471, 4, 479, 479, 100, 4443, 38, 938, 17, 27, 90, 269, 203, 9, 10, 23303, 8, 2969, 4252, 6, 142, 81, 5, 220, 891, 107, 38, 20711, 69, 19, 10, 9755, 10771, 29499, 6, 10, 821, 22383, 326, 19112, 5571, 8, 44, 48, 34868, 2462, 219, 10802, 62, 5, 3124, 4, 17, 46, 2, 2, 6179, 251, 34, 5, 2138, 56, 39, 633, 116, 18454, 5564, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 791, 5471, 1174, 100, 206, 42, 2263, 127, 1354, 4, 50118, 2387, 8733, 2138, 34, 460, 56, 41, 31232, 13, 5425, 10029, 578, 37790, 5556, 6, 326, 19112, 38215, 6, 380, 7, 37994, 784, 39700, 4, 370, 766, 24, 8, 37, 17, 27, 29, 1153, 7521, 24, 4, 96, 754, 6, 37, 202, 4618, 23, 41, 19265, 3477, 5159, 61, 16, 184, 7, 10, 739, 3143, 9, 167, 15785, 15916, 6, 8, 127, 793, 1441, 735, 36330, 4, 50118, 10787, 107, 536, 6, 38, 439, 7, 825, 127, 985, 147, 37, 202, 3033, 6, 160, 8, 15, 6, 25, 24, 21, 2789, 7, 39, 633, 87, 39, 92, 3537, 4, 38, 1102, 7, 213, 88, 39, 929, 8, 5324, 10, 1637, 25114, 8319, 2233, 59, 237, 50, 292, 4877, 3925, 4, 39273, 219, 25, 38, 524, 6, 38, 56, 7, 490, 24, 4, 50118, 243, 5558, 5, 7722, 1931, 366, 44869, 9, 10, 739, 42175, 5718, 8, 909, 326, 19112, 5571, 4, 44218, 219, 25, 14, 21, 6, 24, 399, 17, 27, 90, 15304, 6, 50, 190, 2755, 162, 203, 6, 25, 38, 1467, 127, 2138, 429, 489, 402, 101, 14, 11, 39, 929, 4, 50118, 21674, 41, 1946, 423, 6, 37, 373, 7, 224, 20760, 8, 2528, 38, 185, 10, 356, 23, 5, 1637, 2233, 11, 39, 929, 4, 38, 174, 123, 14, 38, 416, 56, 6, 53, 38, 2738, 24, 62, 456, 7, 185, 277, 356, 6, 150, 37, 174, 162, 59, 2494, 39, 4716, 7722, 24, 4, 50118, 2387, 80, 76, 793, 1354, 21, 39789, 10691, 59, 5, 13654, 9, 5, 1256, 2233, 6, 98, 38, 969, 24, 7, 69, 4, 50118, 12583, 39485, 5021, 4, 83, 5021, 98, 1099, 24, 197, 33, 57, 2292, 22697, 4, 50118, 2515, 362, 65, 356, 23, 24, 6, 1224, 1104, 8, 23472, 46754, 1329, 4, 38, 17, 27, 548, 393, 450, 951, 98, 19419, 4, 50118, 10643, 768, 38, 222, 99, 38, 115, 7, 20759, 69, 4, 38, 2002, 14, 24, 21, 5, 380, 34558, 44, 48, 279, 809, 17, 46, 8, 14, 24, 888, 3033, 23, 69, 542, 20639, 97, 790, 4, 50118, 1708, 6, 1717, 5471, 4, 479, 479, 100, 4443, 38, 938, 17, 27, 90, 269, 203, 9, 10, 23303, 8, 2969, 4252, 6, 142, 81, 5, 220, 891, 107, 38, 20711, 69, 19, 10, 9755, 10771, 29499, 6, 10, 821, 22383, 326, 19112, 5571, 8, 44, 48, 34868, 2462, 219, 10802, 62, 5, 3124, 4, 17, 46, 2, 2, 6179, 251, 34, 5, 2138, 56, 39, 633, 116, 45731, 1215, 26947, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 791, 5471, 1174, 100, 206, 42, 2263, 127, 1354, 4, 50118, 2387, 8733, 2138, 34, 460, 56, 41, 31232, 13, 5425, 10029, 578, 37790, 5556, 6, 326, 19112, 38215, 6, 380, 7, 37994, 784, 39700, 4, 370, 766, 24, 8, 37, 17, 27, 29, 1153, 7521, 24, 4, 96, 754, 6, 37, 202, 4618, 23, 41, 19265, 3477, 5159, 61, 16, 184, 7, 10, 739, 3143, 9, 167, 15785, 15916, 6, 8, 127, 793, 1441, 735, 36330, 4, 50118, 10787, 107, 536, 6, 38, 439, 7, 825, 127, 985, 147, 37, 202, 3033, 6, 160, 8, 15, 6, 25, 24, 21, 2789, 7, 39, 633, 87, 39, 92, 3537, 4, 38, 1102, 7, 213, 88, 39, 929, 8, 5324, 10, 1637, 25114, 8319, 2233, 59, 237, 50, 292, 4877, 3925, 4, 39273, 219, 25, 38, 524, 6, 38, 56, 7, 490, 24, 4, 50118, 243, 5558, 5, 7722, 1931, 366, 44869, 9, 10, 739, 42175, 5718, 8, 909, 326, 19112, 5571, 4, 44218, 219, 25, 14, 21, 6, 24, 399, 17, 27, 90, 15304, 6, 50, 190, 2755, 162, 203, 6, 25, 38, 1467, 127, 2138, 429, 489, 402, 101, 14, 11, 39, 929, 4, 50118, 21674, 41, 1946, 423, 6, 37, 373, 7, 224, 20760, 8, 2528, 38, 185, 10, 356, 23, 5, 1637, 2233, 11, 39, 929, 4, 38, 174, 123, 14, 38, 416, 56, 6, 53, 38, 2738, 24, 62, 456, 7, 185, 277, 356, 6, 150, 37, 174, 162, 59, 2494, 39, 4716, 7722, 24, 4, 50118, 2387, 80, 76, 793, 1354, 21, 39789, 10691, 59, 5, 13654, 9, 5, 1256, 2233, 6, 98, 38, 969, 24, 7, 69, 4, 50118, 12583, 39485, 5021, 4, 83, 5021, 98, 1099, 24, 197, 33, 57, 2292, 22697, 4, 50118, 2515, 362, 65, 356, 23, 24, 6, 1224, 1104, 8, 23472, 46754, 1329, 4, 38, 17, 27, 548, 393, 450, 951, 98, 19419, 4, 50118, 10643, 768, 38, 222, 99, 38, 115, 7, 20759, 69, 4, 38, 2002, 14, 24, 21, 5, 380, 34558, 44, 48, 279, 809, 17, 46, 8, 14, 24, 888, 3033, 23, 69, 542, 20639, 97, 790, 4, 50118, 1708, 6, 1717, 5471, 4, 479, 479, 100, 4443, 38, 938, 17, 27, 90, 269, 203, 9, 10, 23303, 8, 2969, 4252, 6, 142, 81, 5, 220, 891, 107, 38, 20711, 69, 19, 10, 9755, 10771, 29499, 6, 10, 821, 22383, 326, 19112, 5571, 8, 44, 48, 34868, 2462, 219, 10802, 62, 5, 3124, 4, 17, 46, 2, 2, 6179, 251, 34, 5, 2138, 56, 39, 633, 116, 46718, 1215, 47276, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 791, 5471, 1174, 100, 206, 42, 2263, 127, 1354, 4, 50118, 2387, 8733, 2138, 34, 460, 56, 41, 31232, 13, 5425, 10029, 578, 37790, 5556, 6, 326, 19112, 38215, 6, 380, 7, 37994, 784, 39700, 4, 370, 766, 24, 8, 37, 17, 27, 29, 1153, 7521, 24, 4, 96, 754, 6, 37, 202, 4618, 23, 41, 19265, 3477, 5159, 61, 16, 184, 7, 10, 739, 3143, 9, 167, 15785, 15916, 6, 8, 127, 793, 1441, 735, 36330, 4, 50118, 10787, 107, 536, 6, 38, 439, 7, 825, 127, 985, 147, 37, 202, 3033, 6, 160, 8, 15, 6, 25, 24, 21, 2789, 7, 39, 633, 87, 39, 92, 3537, 4, 38, 1102, 7, 213, 88, 39, 929, 8, 5324, 10, 1637, 25114, 8319, 2233, 59, 237, 50, 292, 4877, 3925, 4, 39273, 219, 25, 38, 524, 6, 38, 56, 7, 490, 24, 4, 50118, 243, 5558, 5, 7722, 1931, 366, 44869, 9, 10, 739, 42175, 5718, 8, 909, 326, 19112, 5571, 4, 44218, 219, 25, 14, 21, 6, 24, 399, 17, 27, 90, 15304, 6, 50, 190, 2755, 162, 203, 6, 25, 38, 1467, 127, 2138, 429, 489, 402, 101, 14, 11, 39, 929, 4, 50118, 21674, 41, 1946, 423, 6, 37, 373, 7, 224, 20760, 8, 2528, 38, 185, 10, 356, 23, 5, 1637, 2233, 11, 39, 929, 4, 38, 174, 123, 14, 38, 416, 56, 6, 53, 38, 2738, 24, 62, 456, 7, 185, 277, 356, 6, 150, 37, 174, 162, 59, 2494, 39, 4716, 7722, 24, 4, 50118, 2387, 80, 76, 793, 1354, 21, 39789, 10691, 59, 5, 13654, 9, 5, 1256, 2233, 6, 98, 38, 969, 24, 7, 69, 4, 50118, 12583, 39485, 5021, 4, 83, 5021, 98, 1099, 24, 197, 33, 57, 2292, 22697, 4, 50118, 2515, 362, 65, 356, 23, 24, 6, 1224, 1104, 8, 23472, 46754, 1329, 4, 38, 17, 27, 548, 393, 450, 951, 98, 19419, 4, 50118, 10643, 768, 38, 222, 99, 38, 115, 7, 20759, 69, 4, 38, 2002, 14, 24, 21, 5, 380, 34558, 44, 48, 279, 809, 17, 46, 8, 14, 24, 888, 3033, 23, 69, 542, 20639, 97, 790, 4, 50118, 1708, 6, 1717, 5471, 4, 479, 479, 100, 4443, 38, 938, 17, 27, 90, 269, 203, 9, 10, 23303, 8, 2969, 4252, 6, 142, 81, 5, 220, 891, 107, 38, 20711, 69, 19, 10, 9755, 10771, 29499, 6, 10, 821, 22383, 326, 19112, 5571, 8, 44, 48, 34868, 2462, 219, 10802, 62, 5, 3124, 4, 17, 46, 2, 2, 6179, 251, 34, 5, 2138, 56, 39, 633, 116, 1890, 27740, 868, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 791, 5471, 1174, 100, 206, 42, 2263, 127, 1354, 4, 50118, 2387, 8733, 2138, 34, 460, 56, 41, 31232, 13, 5425, 10029, 578, 37790, 5556, 6, 326, 19112, 38215, 6, 380, 7, 37994, 784, 39700, 4, 370, 766, 24, 8, 37, 17, 27, 29, 1153, 7521, 24, 4, 96, 754, 6, 37, 202, 4618, 23, 41, 19265, 3477, 5159, 61, 16, 184, 7, 10, 739, 3143, 9, 167, 15785, 15916, 6, 8, 127, 793, 1441, 735, 36330, 4, 50118, 10787, 107, 536, 6, 38, 439, 7, 825, 127, 985, 147, 37, 202, 3033, 6, 160, 8, 15, 6, 25, 24, 21, 2789, 7, 39, 633, 87, 39, 92, 3537, 4, 38, 1102, 7, 213, 88, 39, 929, 8, 5324, 10, 1637, 25114, 8319, 2233, 59, 237, 50, 292, 4877, 3925, 4, 39273, 219, 25, 38, 524, 6, 38, 56, 7, 490, 24, 4, 50118, 243, 5558, 5, 7722, 1931, 366, 44869, 9, 10, 739, 42175, 5718, 8, 909, 326, 19112, 5571, 4, 44218, 219, 25, 14, 21, 6, 24, 399, 17, 27, 90, 15304, 6, 50, 190, 2755, 162, 203, 6, 25, 38, 1467, 127, 2138, 429, 489, 402, 101, 14, 11, 39, 929, 4, 50118, 21674, 41, 1946, 423, 6, 37, 373, 7, 224, 20760, 8, 2528, 38, 185, 10, 356, 23, 5, 1637, 2233, 11, 39, 929, 4, 38, 174, 123, 14, 38, 416, 56, 6, 53, 38, 2738, 24, 62, 456, 7, 185, 277, 356, 6, 150, 37, 174, 162, 59, 2494, 39, 4716, 7722, 24, 4, 50118, 2387, 80, 76, 793, 1354, 21, 39789, 10691, 59, 5, 13654, 9, 5, 1256, 2233, 6, 98, 38, 969, 24, 7, 69, 4, 50118, 12583, 39485, 5021, 4, 83, 5021, 98, 1099, 24, 197, 33, 57, 2292, 22697, 4, 50118, 2515, 362, 65, 356, 23, 24, 6, 1224, 1104, 8, 23472, 46754, 1329, 4, 38, 17, 27, 548, 393, 450, 951, 98, 19419, 4, 50118, 10643, 768, 38, 222, 99, 38, 115, 7, 20759, 69, 4, 38, 2002, 14, 24, 21, 5, 380, 34558, 44, 48, 279, 809, 17, 46, 8, 14, 24, 888, 3033, 23, 69, 542, 20639, 97, 790, 4, 50118, 1708, 6, 1717, 5471, 4, 479, 479, 100, 4443, 38, 938, 17, 27, 90, 269, 203, 9, 10, 23303, 8, 2969, 4252, 6, 142, 81, 5, 220, 891, 107, 38, 20711, 69, 19, 10, 9755, 10771, 29499, 6, 10, 821, 22383, 326, 19112, 5571, 8, 44, 48, 34868, 2462, 219, 10802, 62, 5, 3124, 4, 17, 46, 2, 2, 6179, 251, 34, 5, 2138, 56, 39, 633, 116, 9188, 46249, 1215, 10337, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], attention_mask=[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], token_type_ids=None, label=7)\n",
            "11/30/2020 15:53:37 - INFO - utils_multiple_choice -   *** Example ***\n",
            "11/30/2020 15:53:37 - INFO - utils_multiple_choice -   feature: InputFeatures(example_id='u141_15', input_ids=[[0, 100, 33, 57, 8, 202, 16, 11, 42, 1068, 11, 127, 284, 301, 4, 96, 1014, 6, 38, 1064, 11166, 4812, 8, 24, 362, 162, 209, 195, 107, 7, 671, 7, 2340, 301, 4, 96, 70, 209, 292, 107, 6, 38, 2220, 75, 56, 143, 23019, 3569, 50, 7654, 244, 31, 127, 1623, 4, 616, 38, 21, 11, 36021, 2400, 6, 37, 3776, 39, 301, 7, 5, 31848, 6, 11743, 8141, 66, 418, 13, 39, 36365, 101, 5651, 4, 38, 56, 7, 946, 80, 1315, 7, 582, 127, 1131, 4033, 187, 127, 474, 714, 399, 75, 1719, 5, 1042, 9, 127, 1416, 4, 38, 56, 7, 185, 80, 12, 1946, 6383, 227, 127, 1364, 298, 22833, 36, 33034, 6, 127, 320, 3504, 851, 162, 5537, 7, 304, 10, 28391, 5101, 3267, 11, 84, 3299, 18, 558, 13, 14, 43, 8, 127, 44, 48, 417, 4352, 97, 457, 17, 46, 7311, 59, 519, 7, 5555, 162, 7, 8, 31, 173, 25, 39, 512, 21, 341, 350, 747, 4, 286, 167, 6, 1207, 11, 5, 382, 6, 38, 619, 38, 240, 7, 3922, 103, 1254, 4, 96, 798, 6, 52, 218, 75, 2333, 33, 10, 2660, 284, 827, 1316, 6, 98, 38, 1705, 75, 304, 39, 418, 131, 38, 56, 7, 146, 109, 19, 99, 38, 2208, 4, 38, 553, 123, 13, 418, 6, 61, 38, 460, 18913, 31, 123, 3357, 24, 4595, 6, 129, 2330, 11, 70, 209, 107, 4, 91, 851, 162, 10, 410, 6797, 683, 129, 7, 2851, 32388, 162, 13, 1996, 5, 220, 183, 4, 91, 3179, 7, 15658, 162, 10, 38460, 6797, 13, 130, 360, 600, 37, 1467, 157, 615, 14, 114, 38, 399, 75, 120, 5, 6150, 38, 956, 6, 38, 115, 1323, 66, 11, 143, 317, 8, 143, 86, 4, 407, 122, 6, 38, 218, 75, 2416, 123, 5988, 8, 619, 182, 27810, 4, 318, 47, 1394, 162, 59, 141, 24, 2653, 7, 697, 101, 14, 6, 38, 581, 1137, 47, 14, 24, 18, 7360, 4, 1876, 82, 619, 26913, 77, 51, 32, 25177, 15, 4, 38, 129, 6675, 77, 38, 1166, 49, 1652, 4, 252, 218, 75, 216, 99, 26760, 16, 8, 99, 24, 839, 7, 33, 7, 697, 19, 10, 40048, 54, 189, 905, 47, 159, 143, 2289, 4, 2, 2, 12375, 34, 57, 11166, 4812, 116, 35177, 1215, 8009, 1571, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 100, 33, 57, 8, 202, 16, 11, 42, 1068, 11, 127, 284, 301, 4, 96, 1014, 6, 38, 1064, 11166, 4812, 8, 24, 362, 162, 209, 195, 107, 7, 671, 7, 2340, 301, 4, 96, 70, 209, 292, 107, 6, 38, 2220, 75, 56, 143, 23019, 3569, 50, 7654, 244, 31, 127, 1623, 4, 616, 38, 21, 11, 36021, 2400, 6, 37, 3776, 39, 301, 7, 5, 31848, 6, 11743, 8141, 66, 418, 13, 39, 36365, 101, 5651, 4, 38, 56, 7, 946, 80, 1315, 7, 582, 127, 1131, 4033, 187, 127, 474, 714, 399, 75, 1719, 5, 1042, 9, 127, 1416, 4, 38, 56, 7, 185, 80, 12, 1946, 6383, 227, 127, 1364, 298, 22833, 36, 33034, 6, 127, 320, 3504, 851, 162, 5537, 7, 304, 10, 28391, 5101, 3267, 11, 84, 3299, 18, 558, 13, 14, 43, 8, 127, 44, 48, 417, 4352, 97, 457, 17, 46, 7311, 59, 519, 7, 5555, 162, 7, 8, 31, 173, 25, 39, 512, 21, 341, 350, 747, 4, 286, 167, 6, 1207, 11, 5, 382, 6, 38, 619, 38, 240, 7, 3922, 103, 1254, 4, 96, 798, 6, 52, 218, 75, 2333, 33, 10, 2660, 284, 827, 1316, 6, 98, 38, 1705, 75, 304, 39, 418, 131, 38, 56, 7, 146, 109, 19, 99, 38, 2208, 4, 38, 553, 123, 13, 418, 6, 61, 38, 460, 18913, 31, 123, 3357, 24, 4595, 6, 129, 2330, 11, 70, 209, 107, 4, 91, 851, 162, 10, 410, 6797, 683, 129, 7, 2851, 32388, 162, 13, 1996, 5, 220, 183, 4, 91, 3179, 7, 15658, 162, 10, 38460, 6797, 13, 130, 360, 600, 37, 1467, 157, 615, 14, 114, 38, 399, 75, 120, 5, 6150, 38, 956, 6, 38, 115, 1323, 66, 11, 143, 317, 8, 143, 86, 4, 407, 122, 6, 38, 218, 75, 2416, 123, 5988, 8, 619, 182, 27810, 4, 318, 47, 1394, 162, 59, 141, 24, 2653, 7, 697, 101, 14, 6, 38, 581, 1137, 47, 14, 24, 18, 7360, 4, 1876, 82, 619, 26913, 77, 51, 32, 25177, 15, 4, 38, 129, 6675, 77, 38, 1166, 49, 1652, 4, 252, 218, 75, 216, 99, 26760, 16, 8, 99, 24, 839, 7, 33, 7, 697, 19, 10, 40048, 54, 189, 905, 47, 159, 143, 2289, 4, 2, 2, 12375, 34, 57, 11166, 4812, 116, 8316, 687, 6948, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 100, 33, 57, 8, 202, 16, 11, 42, 1068, 11, 127, 284, 301, 4, 96, 1014, 6, 38, 1064, 11166, 4812, 8, 24, 362, 162, 209, 195, 107, 7, 671, 7, 2340, 301, 4, 96, 70, 209, 292, 107, 6, 38, 2220, 75, 56, 143, 23019, 3569, 50, 7654, 244, 31, 127, 1623, 4, 616, 38, 21, 11, 36021, 2400, 6, 37, 3776, 39, 301, 7, 5, 31848, 6, 11743, 8141, 66, 418, 13, 39, 36365, 101, 5651, 4, 38, 56, 7, 946, 80, 1315, 7, 582, 127, 1131, 4033, 187, 127, 474, 714, 399, 75, 1719, 5, 1042, 9, 127, 1416, 4, 38, 56, 7, 185, 80, 12, 1946, 6383, 227, 127, 1364, 298, 22833, 36, 33034, 6, 127, 320, 3504, 851, 162, 5537, 7, 304, 10, 28391, 5101, 3267, 11, 84, 3299, 18, 558, 13, 14, 43, 8, 127, 44, 48, 417, 4352, 97, 457, 17, 46, 7311, 59, 519, 7, 5555, 162, 7, 8, 31, 173, 25, 39, 512, 21, 341, 350, 747, 4, 286, 167, 6, 1207, 11, 5, 382, 6, 38, 619, 38, 240, 7, 3922, 103, 1254, 4, 96, 798, 6, 52, 218, 75, 2333, 33, 10, 2660, 284, 827, 1316, 6, 98, 38, 1705, 75, 304, 39, 418, 131, 38, 56, 7, 146, 109, 19, 99, 38, 2208, 4, 38, 553, 123, 13, 418, 6, 61, 38, 460, 18913, 31, 123, 3357, 24, 4595, 6, 129, 2330, 11, 70, 209, 107, 4, 91, 851, 162, 10, 410, 6797, 683, 129, 7, 2851, 32388, 162, 13, 1996, 5, 220, 183, 4, 91, 3179, 7, 15658, 162, 10, 38460, 6797, 13, 130, 360, 600, 37, 1467, 157, 615, 14, 114, 38, 399, 75, 120, 5, 6150, 38, 956, 6, 38, 115, 1323, 66, 11, 143, 317, 8, 143, 86, 4, 407, 122, 6, 38, 218, 75, 2416, 123, 5988, 8, 619, 182, 27810, 4, 318, 47, 1394, 162, 59, 141, 24, 2653, 7, 697, 101, 14, 6, 38, 581, 1137, 47, 14, 24, 18, 7360, 4, 1876, 82, 619, 26913, 77, 51, 32, 25177, 15, 4, 38, 129, 6675, 77, 38, 1166, 49, 1652, 4, 252, 218, 75, 216, 99, 26760, 16, 8, 99, 24, 839, 7, 33, 7, 697, 19, 10, 40048, 54, 189, 905, 47, 159, 143, 2289, 4, 2, 2, 12375, 34, 57, 11166, 4812, 116, 11373, 1215, 41218, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 100, 33, 57, 8, 202, 16, 11, 42, 1068, 11, 127, 284, 301, 4, 96, 1014, 6, 38, 1064, 11166, 4812, 8, 24, 362, 162, 209, 195, 107, 7, 671, 7, 2340, 301, 4, 96, 70, 209, 292, 107, 6, 38, 2220, 75, 56, 143, 23019, 3569, 50, 7654, 244, 31, 127, 1623, 4, 616, 38, 21, 11, 36021, 2400, 6, 37, 3776, 39, 301, 7, 5, 31848, 6, 11743, 8141, 66, 418, 13, 39, 36365, 101, 5651, 4, 38, 56, 7, 946, 80, 1315, 7, 582, 127, 1131, 4033, 187, 127, 474, 714, 399, 75, 1719, 5, 1042, 9, 127, 1416, 4, 38, 56, 7, 185, 80, 12, 1946, 6383, 227, 127, 1364, 298, 22833, 36, 33034, 6, 127, 320, 3504, 851, 162, 5537, 7, 304, 10, 28391, 5101, 3267, 11, 84, 3299, 18, 558, 13, 14, 43, 8, 127, 44, 48, 417, 4352, 97, 457, 17, 46, 7311, 59, 519, 7, 5555, 162, 7, 8, 31, 173, 25, 39, 512, 21, 341, 350, 747, 4, 286, 167, 6, 1207, 11, 5, 382, 6, 38, 619, 38, 240, 7, 3922, 103, 1254, 4, 96, 798, 6, 52, 218, 75, 2333, 33, 10, 2660, 284, 827, 1316, 6, 98, 38, 1705, 75, 304, 39, 418, 131, 38, 56, 7, 146, 109, 19, 99, 38, 2208, 4, 38, 553, 123, 13, 418, 6, 61, 38, 460, 18913, 31, 123, 3357, 24, 4595, 6, 129, 2330, 11, 70, 209, 107, 4, 91, 851, 162, 10, 410, 6797, 683, 129, 7, 2851, 32388, 162, 13, 1996, 5, 220, 183, 4, 91, 3179, 7, 15658, 162, 10, 38460, 6797, 13, 130, 360, 600, 37, 1467, 157, 615, 14, 114, 38, 399, 75, 120, 5, 6150, 38, 956, 6, 38, 115, 1323, 66, 11, 143, 317, 8, 143, 86, 4, 407, 122, 6, 38, 218, 75, 2416, 123, 5988, 8, 619, 182, 27810, 4, 318, 47, 1394, 162, 59, 141, 24, 2653, 7, 697, 101, 14, 6, 38, 581, 1137, 47, 14, 24, 18, 7360, 4, 1876, 82, 619, 26913, 77, 51, 32, 25177, 15, 4, 38, 129, 6675, 77, 38, 1166, 49, 1652, 4, 252, 218, 75, 216, 99, 26760, 16, 8, 99, 24, 839, 7, 33, 7, 697, 19, 10, 40048, 54, 189, 905, 47, 159, 143, 2289, 4, 2, 2, 12375, 34, 57, 11166, 4812, 116, 4052, 39022, 1215, 4897, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 100, 33, 57, 8, 202, 16, 11, 42, 1068, 11, 127, 284, 301, 4, 96, 1014, 6, 38, 1064, 11166, 4812, 8, 24, 362, 162, 209, 195, 107, 7, 671, 7, 2340, 301, 4, 96, 70, 209, 292, 107, 6, 38, 2220, 75, 56, 143, 23019, 3569, 50, 7654, 244, 31, 127, 1623, 4, 616, 38, 21, 11, 36021, 2400, 6, 37, 3776, 39, 301, 7, 5, 31848, 6, 11743, 8141, 66, 418, 13, 39, 36365, 101, 5651, 4, 38, 56, 7, 946, 80, 1315, 7, 582, 127, 1131, 4033, 187, 127, 474, 714, 399, 75, 1719, 5, 1042, 9, 127, 1416, 4, 38, 56, 7, 185, 80, 12, 1946, 6383, 227, 127, 1364, 298, 22833, 36, 33034, 6, 127, 320, 3504, 851, 162, 5537, 7, 304, 10, 28391, 5101, 3267, 11, 84, 3299, 18, 558, 13, 14, 43, 8, 127, 44, 48, 417, 4352, 97, 457, 17, 46, 7311, 59, 519, 7, 5555, 162, 7, 8, 31, 173, 25, 39, 512, 21, 341, 350, 747, 4, 286, 167, 6, 1207, 11, 5, 382, 6, 38, 619, 38, 240, 7, 3922, 103, 1254, 4, 96, 798, 6, 52, 218, 75, 2333, 33, 10, 2660, 284, 827, 1316, 6, 98, 38, 1705, 75, 304, 39, 418, 131, 38, 56, 7, 146, 109, 19, 99, 38, 2208, 4, 38, 553, 123, 13, 418, 6, 61, 38, 460, 18913, 31, 123, 3357, 24, 4595, 6, 129, 2330, 11, 70, 209, 107, 4, 91, 851, 162, 10, 410, 6797, 683, 129, 7, 2851, 32388, 162, 13, 1996, 5, 220, 183, 4, 91, 3179, 7, 15658, 162, 10, 38460, 6797, 13, 130, 360, 600, 37, 1467, 157, 615, 14, 114, 38, 399, 75, 120, 5, 6150, 38, 956, 6, 38, 115, 1323, 66, 11, 143, 317, 8, 143, 86, 4, 407, 122, 6, 38, 218, 75, 2416, 123, 5988, 8, 619, 182, 27810, 4, 318, 47, 1394, 162, 59, 141, 24, 2653, 7, 697, 101, 14, 6, 38, 581, 1137, 47, 14, 24, 18, 7360, 4, 1876, 82, 619, 26913, 77, 51, 32, 25177, 15, 4, 38, 129, 6675, 77, 38, 1166, 49, 1652, 4, 252, 218, 75, 216, 99, 26760, 16, 8, 99, 24, 839, 7, 33, 7, 697, 19, 10, 40048, 54, 189, 905, 47, 159, 143, 2289, 4, 2, 2, 12375, 34, 57, 11166, 4812, 116, 18454, 5564, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 100, 33, 57, 8, 202, 16, 11, 42, 1068, 11, 127, 284, 301, 4, 96, 1014, 6, 38, 1064, 11166, 4812, 8, 24, 362, 162, 209, 195, 107, 7, 671, 7, 2340, 301, 4, 96, 70, 209, 292, 107, 6, 38, 2220, 75, 56, 143, 23019, 3569, 50, 7654, 244, 31, 127, 1623, 4, 616, 38, 21, 11, 36021, 2400, 6, 37, 3776, 39, 301, 7, 5, 31848, 6, 11743, 8141, 66, 418, 13, 39, 36365, 101, 5651, 4, 38, 56, 7, 946, 80, 1315, 7, 582, 127, 1131, 4033, 187, 127, 474, 714, 399, 75, 1719, 5, 1042, 9, 127, 1416, 4, 38, 56, 7, 185, 80, 12, 1946, 6383, 227, 127, 1364, 298, 22833, 36, 33034, 6, 127, 320, 3504, 851, 162, 5537, 7, 304, 10, 28391, 5101, 3267, 11, 84, 3299, 18, 558, 13, 14, 43, 8, 127, 44, 48, 417, 4352, 97, 457, 17, 46, 7311, 59, 519, 7, 5555, 162, 7, 8, 31, 173, 25, 39, 512, 21, 341, 350, 747, 4, 286, 167, 6, 1207, 11, 5, 382, 6, 38, 619, 38, 240, 7, 3922, 103, 1254, 4, 96, 798, 6, 52, 218, 75, 2333, 33, 10, 2660, 284, 827, 1316, 6, 98, 38, 1705, 75, 304, 39, 418, 131, 38, 56, 7, 146, 109, 19, 99, 38, 2208, 4, 38, 553, 123, 13, 418, 6, 61, 38, 460, 18913, 31, 123, 3357, 24, 4595, 6, 129, 2330, 11, 70, 209, 107, 4, 91, 851, 162, 10, 410, 6797, 683, 129, 7, 2851, 32388, 162, 13, 1996, 5, 220, 183, 4, 91, 3179, 7, 15658, 162, 10, 38460, 6797, 13, 130, 360, 600, 37, 1467, 157, 615, 14, 114, 38, 399, 75, 120, 5, 6150, 38, 956, 6, 38, 115, 1323, 66, 11, 143, 317, 8, 143, 86, 4, 407, 122, 6, 38, 218, 75, 2416, 123, 5988, 8, 619, 182, 27810, 4, 318, 47, 1394, 162, 59, 141, 24, 2653, 7, 697, 101, 14, 6, 38, 581, 1137, 47, 14, 24, 18, 7360, 4, 1876, 82, 619, 26913, 77, 51, 32, 25177, 15, 4, 38, 129, 6675, 77, 38, 1166, 49, 1652, 4, 252, 218, 75, 216, 99, 26760, 16, 8, 99, 24, 839, 7, 33, 7, 697, 19, 10, 40048, 54, 189, 905, 47, 159, 143, 2289, 4, 2, 2, 12375, 34, 57, 11166, 4812, 116, 45731, 1215, 26947, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 100, 33, 57, 8, 202, 16, 11, 42, 1068, 11, 127, 284, 301, 4, 96, 1014, 6, 38, 1064, 11166, 4812, 8, 24, 362, 162, 209, 195, 107, 7, 671, 7, 2340, 301, 4, 96, 70, 209, 292, 107, 6, 38, 2220, 75, 56, 143, 23019, 3569, 50, 7654, 244, 31, 127, 1623, 4, 616, 38, 21, 11, 36021, 2400, 6, 37, 3776, 39, 301, 7, 5, 31848, 6, 11743, 8141, 66, 418, 13, 39, 36365, 101, 5651, 4, 38, 56, 7, 946, 80, 1315, 7, 582, 127, 1131, 4033, 187, 127, 474, 714, 399, 75, 1719, 5, 1042, 9, 127, 1416, 4, 38, 56, 7, 185, 80, 12, 1946, 6383, 227, 127, 1364, 298, 22833, 36, 33034, 6, 127, 320, 3504, 851, 162, 5537, 7, 304, 10, 28391, 5101, 3267, 11, 84, 3299, 18, 558, 13, 14, 43, 8, 127, 44, 48, 417, 4352, 97, 457, 17, 46, 7311, 59, 519, 7, 5555, 162, 7, 8, 31, 173, 25, 39, 512, 21, 341, 350, 747, 4, 286, 167, 6, 1207, 11, 5, 382, 6, 38, 619, 38, 240, 7, 3922, 103, 1254, 4, 96, 798, 6, 52, 218, 75, 2333, 33, 10, 2660, 284, 827, 1316, 6, 98, 38, 1705, 75, 304, 39, 418, 131, 38, 56, 7, 146, 109, 19, 99, 38, 2208, 4, 38, 553, 123, 13, 418, 6, 61, 38, 460, 18913, 31, 123, 3357, 24, 4595, 6, 129, 2330, 11, 70, 209, 107, 4, 91, 851, 162, 10, 410, 6797, 683, 129, 7, 2851, 32388, 162, 13, 1996, 5, 220, 183, 4, 91, 3179, 7, 15658, 162, 10, 38460, 6797, 13, 130, 360, 600, 37, 1467, 157, 615, 14, 114, 38, 399, 75, 120, 5, 6150, 38, 956, 6, 38, 115, 1323, 66, 11, 143, 317, 8, 143, 86, 4, 407, 122, 6, 38, 218, 75, 2416, 123, 5988, 8, 619, 182, 27810, 4, 318, 47, 1394, 162, 59, 141, 24, 2653, 7, 697, 101, 14, 6, 38, 581, 1137, 47, 14, 24, 18, 7360, 4, 1876, 82, 619, 26913, 77, 51, 32, 25177, 15, 4, 38, 129, 6675, 77, 38, 1166, 49, 1652, 4, 252, 218, 75, 216, 99, 26760, 16, 8, 99, 24, 839, 7, 33, 7, 697, 19, 10, 40048, 54, 189, 905, 47, 159, 143, 2289, 4, 2, 2, 12375, 34, 57, 11166, 4812, 116, 46718, 1215, 47276, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 100, 33, 57, 8, 202, 16, 11, 42, 1068, 11, 127, 284, 301, 4, 96, 1014, 6, 38, 1064, 11166, 4812, 8, 24, 362, 162, 209, 195, 107, 7, 671, 7, 2340, 301, 4, 96, 70, 209, 292, 107, 6, 38, 2220, 75, 56, 143, 23019, 3569, 50, 7654, 244, 31, 127, 1623, 4, 616, 38, 21, 11, 36021, 2400, 6, 37, 3776, 39, 301, 7, 5, 31848, 6, 11743, 8141, 66, 418, 13, 39, 36365, 101, 5651, 4, 38, 56, 7, 946, 80, 1315, 7, 582, 127, 1131, 4033, 187, 127, 474, 714, 399, 75, 1719, 5, 1042, 9, 127, 1416, 4, 38, 56, 7, 185, 80, 12, 1946, 6383, 227, 127, 1364, 298, 22833, 36, 33034, 6, 127, 320, 3504, 851, 162, 5537, 7, 304, 10, 28391, 5101, 3267, 11, 84, 3299, 18, 558, 13, 14, 43, 8, 127, 44, 48, 417, 4352, 97, 457, 17, 46, 7311, 59, 519, 7, 5555, 162, 7, 8, 31, 173, 25, 39, 512, 21, 341, 350, 747, 4, 286, 167, 6, 1207, 11, 5, 382, 6, 38, 619, 38, 240, 7, 3922, 103, 1254, 4, 96, 798, 6, 52, 218, 75, 2333, 33, 10, 2660, 284, 827, 1316, 6, 98, 38, 1705, 75, 304, 39, 418, 131, 38, 56, 7, 146, 109, 19, 99, 38, 2208, 4, 38, 553, 123, 13, 418, 6, 61, 38, 460, 18913, 31, 123, 3357, 24, 4595, 6, 129, 2330, 11, 70, 209, 107, 4, 91, 851, 162, 10, 410, 6797, 683, 129, 7, 2851, 32388, 162, 13, 1996, 5, 220, 183, 4, 91, 3179, 7, 15658, 162, 10, 38460, 6797, 13, 130, 360, 600, 37, 1467, 157, 615, 14, 114, 38, 399, 75, 120, 5, 6150, 38, 956, 6, 38, 115, 1323, 66, 11, 143, 317, 8, 143, 86, 4, 407, 122, 6, 38, 218, 75, 2416, 123, 5988, 8, 619, 182, 27810, 4, 318, 47, 1394, 162, 59, 141, 24, 2653, 7, 697, 101, 14, 6, 38, 581, 1137, 47, 14, 24, 18, 7360, 4, 1876, 82, 619, 26913, 77, 51, 32, 25177, 15, 4, 38, 129, 6675, 77, 38, 1166, 49, 1652, 4, 252, 218, 75, 216, 99, 26760, 16, 8, 99, 24, 839, 7, 33, 7, 697, 19, 10, 40048, 54, 189, 905, 47, 159, 143, 2289, 4, 2, 2, 12375, 34, 57, 11166, 4812, 116, 1890, 27740, 868, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 100, 33, 57, 8, 202, 16, 11, 42, 1068, 11, 127, 284, 301, 4, 96, 1014, 6, 38, 1064, 11166, 4812, 8, 24, 362, 162, 209, 195, 107, 7, 671, 7, 2340, 301, 4, 96, 70, 209, 292, 107, 6, 38, 2220, 75, 56, 143, 23019, 3569, 50, 7654, 244, 31, 127, 1623, 4, 616, 38, 21, 11, 36021, 2400, 6, 37, 3776, 39, 301, 7, 5, 31848, 6, 11743, 8141, 66, 418, 13, 39, 36365, 101, 5651, 4, 38, 56, 7, 946, 80, 1315, 7, 582, 127, 1131, 4033, 187, 127, 474, 714, 399, 75, 1719, 5, 1042, 9, 127, 1416, 4, 38, 56, 7, 185, 80, 12, 1946, 6383, 227, 127, 1364, 298, 22833, 36, 33034, 6, 127, 320, 3504, 851, 162, 5537, 7, 304, 10, 28391, 5101, 3267, 11, 84, 3299, 18, 558, 13, 14, 43, 8, 127, 44, 48, 417, 4352, 97, 457, 17, 46, 7311, 59, 519, 7, 5555, 162, 7, 8, 31, 173, 25, 39, 512, 21, 341, 350, 747, 4, 286, 167, 6, 1207, 11, 5, 382, 6, 38, 619, 38, 240, 7, 3922, 103, 1254, 4, 96, 798, 6, 52, 218, 75, 2333, 33, 10, 2660, 284, 827, 1316, 6, 98, 38, 1705, 75, 304, 39, 418, 131, 38, 56, 7, 146, 109, 19, 99, 38, 2208, 4, 38, 553, 123, 13, 418, 6, 61, 38, 460, 18913, 31, 123, 3357, 24, 4595, 6, 129, 2330, 11, 70, 209, 107, 4, 91, 851, 162, 10, 410, 6797, 683, 129, 7, 2851, 32388, 162, 13, 1996, 5, 220, 183, 4, 91, 3179, 7, 15658, 162, 10, 38460, 6797, 13, 130, 360, 600, 37, 1467, 157, 615, 14, 114, 38, 399, 75, 120, 5, 6150, 38, 956, 6, 38, 115, 1323, 66, 11, 143, 317, 8, 143, 86, 4, 407, 122, 6, 38, 218, 75, 2416, 123, 5988, 8, 619, 182, 27810, 4, 318, 47, 1394, 162, 59, 141, 24, 2653, 7, 697, 101, 14, 6, 38, 581, 1137, 47, 14, 24, 18, 7360, 4, 1876, 82, 619, 26913, 77, 51, 32, 25177, 15, 4, 38, 129, 6675, 77, 38, 1166, 49, 1652, 4, 252, 218, 75, 216, 99, 26760, 16, 8, 99, 24, 839, 7, 33, 7, 697, 19, 10, 40048, 54, 189, 905, 47, 159, 143, 2289, 4, 2, 2, 12375, 34, 57, 11166, 4812, 116, 9188, 46249, 1215, 10337, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], attention_mask=[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], token_type_ids=None, label=0)\n",
            "11/30/2020 15:53:37 - INFO - utils_multiple_choice -   Saving features into cached file ./data/cached_dev_RobertaTokenizer_512_quail-reasoning\n",
            "11/30/2020 15:53:46 - INFO - filelock -   Lock 140667922615544 released on ./data/cached_dev_RobertaTokenizer_512_quail-reasoning.lock\n",
            "11/30/2020 15:53:46 - INFO - __main__ -   *** Evaluate ***\n",
            "5475it [09:02, 11.21it/s]11/30/2020 15:58:41 - INFO - __main__ -   \n",
            "\n",
            "\n",
            "\n",
            "***** Custom_Dev_Eval Results *****\n",
            "11/30/2020 15:58:41 - INFO - __main__ -     eval_loss = 0.3808412551879883\n",
            "11/30/2020 15:58:41 - INFO - __main__ -     eval_acc = 0.8907004830917874\n",
            "11/30/2020 15:58:41 - INFO - __main__ -   *** Evaluate ***\n",
            "37515it [56:26, 11.27it/s]11/30/2020 16:46:05 - INFO - __main__ -   \n",
            "\n",
            "\n",
            "\n",
            "***** Train_Eval Results *****\n",
            "11/30/2020 16:46:05 - INFO - __main__ -     eval_loss = 0.17099937796592712\n",
            "11/30/2020 16:46:05 - INFO - __main__ -     eval_acc = 0.949873591560286\n",
            "37515it [56:28, 11.07it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 994\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: /content/wandb/run-20201130_105943-2lt2lenb/logs/debug.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: /content/wandb/run-20201130_105943-2lt2lenb/logs/debug-internal.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                  _step 2562\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                               _runtime 20784\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                             _timestamp 1606754767\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                             train/loss 0.18832\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                    train/learning_rate 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            train/epoch 1.99956\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                       train/total_flos 220778874786742272\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/loss █▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/learning_rate ████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           train/epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      train/total_flos ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mroberta-base-reasoning_classification\u001b[0m: \u001b[34mhttps://wandb.ai/ngdodd/huggingface/runs/2lt2lenb\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "id": "l0Vi-TNoFaga",
        "outputId": "f97ba6f9-3b15-4d9f-ccac-4502d9a84f76"
      },
      "source": [
        "from google.colab import files\n",
        "#For the folder you have to zip it first and can only download later on\n",
        "!zip -r reasoning_classifier_results.zip quail_out\n",
        "#Download files\n",
        "files.download('reasoning_classifier_results.zip')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: quail_out/ (stored 0%)\n",
            "  adding: quail_out/roberta_base/ (stored 0%)\n",
            "  adding: quail_out/roberta_base/training_args.bin (deflated 44%)\n",
            "  adding: quail_out/roberta_base/checkpoint-1500/ (stored 0%)\n",
            "  adding: quail_out/roberta_base/checkpoint-1500/training_args.bin (deflated 44%)\n",
            "  adding: quail_out/roberta_base/checkpoint-1500/scheduler.pt (deflated 49%)\n",
            "  adding: quail_out/roberta_base/checkpoint-1500/trainer_state.json (deflated 76%)\n",
            "  adding: quail_out/roberta_base/checkpoint-1500/pytorch_model.bin (deflated 10%)\n",
            "  adding: quail_out/roberta_base/checkpoint-1500/config.json (deflated 56%)\n",
            "  adding: quail_out/roberta_base/checkpoint-1500/optimizer.pt (deflated 19%)\n",
            "  adding: quail_out/roberta_base/Train_Eval_metrics.json (deflated 15%)\n",
            "  adding: quail_out/roberta_base/checkpoint-2500/ (stored 0%)\n",
            "  adding: quail_out/roberta_base/checkpoint-2500/training_args.bin (deflated 44%)\n",
            "  adding: quail_out/roberta_base/checkpoint-2500/scheduler.pt (deflated 49%)\n",
            "  adding: quail_out/roberta_base/checkpoint-2500/trainer_state.json (deflated 77%)\n",
            "  adding: quail_out/roberta_base/checkpoint-2500/pytorch_model.bin (deflated 10%)\n",
            "  adding: quail_out/roberta_base/checkpoint-2500/config.json (deflated 56%)\n",
            "  adding: quail_out/roberta_base/checkpoint-2500/optimizer.pt (deflated 19%)\n",
            "  adding: quail_out/roberta_base/Quail_Dev_Eval_metrics.json (deflated 16%)\n",
            "  adding: quail_out/roberta_base/tokenizer_config.json (deflated 80%)\n",
            "  adding: quail_out/roberta_base/special_tokens_map.json (deflated 83%)\n",
            "  adding: quail_out/roberta_base/checkpoint-1000/ (stored 0%)\n",
            "  adding: quail_out/roberta_base/checkpoint-1000/training_args.bin (deflated 44%)\n",
            "  adding: quail_out/roberta_base/checkpoint-1000/scheduler.pt (deflated 49%)\n",
            "  adding: quail_out/roberta_base/checkpoint-1000/trainer_state.json (deflated 75%)\n",
            "  adding: quail_out/roberta_base/checkpoint-1000/pytorch_model.bin (deflated 10%)\n",
            "  adding: quail_out/roberta_base/checkpoint-1000/config.json (deflated 56%)\n",
            "  adding: quail_out/roberta_base/checkpoint-1000/optimizer.pt (deflated 19%)\n",
            "  adding: quail_out/roberta_base/Train_Eval_preds.json (deflated 85%)\n",
            "  adding: quail_out/roberta_base/pytorch_model.bin (deflated 10%)\n",
            "  adding: quail_out/roberta_base/config.json (deflated 56%)\n",
            "  adding: quail_out/roberta_base/checkpoint-2000/ (stored 0%)\n",
            "  adding: quail_out/roberta_base/checkpoint-2000/training_args.bin (deflated 44%)\n",
            "  adding: quail_out/roberta_base/checkpoint-2000/scheduler.pt (deflated 49%)\n",
            "  adding: quail_out/roberta_base/checkpoint-2000/trainer_state.json (deflated 77%)\n",
            "  adding: quail_out/roberta_base/checkpoint-2000/pytorch_model.bin (deflated 10%)\n",
            "  adding: quail_out/roberta_base/checkpoint-2000/config.json (deflated 56%)\n",
            "  adding: quail_out/roberta_base/checkpoint-2000/optimizer.pt (deflated 19%)\n",
            "  adding: quail_out/roberta_base/merges.txt (deflated 53%)\n",
            "  adding: quail_out/roberta_base/Custom_Dev_Eval_metrics.json (deflated 15%)\n",
            "  adding: quail_out/roberta_base/vocab.json (deflated 63%)\n",
            "  adding: quail_out/roberta_base/checkpoint-500/ (stored 0%)\n",
            "  adding: quail_out/roberta_base/checkpoint-500/training_args.bin (deflated 44%)\n",
            "  adding: quail_out/roberta_base/checkpoint-500/scheduler.pt (deflated 49%)\n",
            "  adding: quail_out/roberta_base/checkpoint-500/trainer_state.json (deflated 72%)\n",
            "  adding: quail_out/roberta_base/checkpoint-500/pytorch_model.bin (deflated 11%)\n",
            "  adding: quail_out/roberta_base/checkpoint-500/config.json (deflated 56%)\n",
            "  adding: quail_out/roberta_base/checkpoint-500/optimizer.pt (deflated 20%)\n",
            "  adding: quail_out/roberta_base/Quail_Dev_Eval_preds.json (deflated 83%)\n",
            "  adding: quail_out/roberta_base/Custom_Dev_Eval_preds.json (deflated 83%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_4088f7b1-3cf7-4fbd-bb7b-4bfe22a6e59a\", \"reasoning_classifier_results.zip\", 6708891875)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5tB78HaF_o3"
      },
      "source": [
        "Use the reasoning classifier output to annotate the QA dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vs2tVA95JKyp"
      },
      "source": [
        "!mkdir annotated_data\n",
        "!pip install datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "4f54db4d7daa4c02ac1002949c0e197b",
            "120c01c524bc489b9855fa4062d2ad4b",
            "bb6d8dd9caf846a9866d39edc5ef256d",
            "44b92f74e7b442d78dda15c3b5b5a2e5",
            "f07b3af984cf42619cd5daf3576d3109",
            "1c9974509970474a900e53067a9eb57c",
            "489c0d3327d34e76a4639d128684fd14",
            "eb0b9fa97f284aaaa42b4e9cbf4bc383"
          ]
        },
        "id": "y9VK_gzmF-u4",
        "outputId": "8199522e-4e3c-404e-b77a-b604c8a929c6"
      },
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "def load_dict(path):\n",
        "  with open(path, 'r', encoding='utf-8') as f:\n",
        "      return json.load(f)\n",
        "\n",
        "# Load the predictions from the trained upstream reasoning classifier on the various datasets\n",
        "custom_dev_preds = load_dict('./quail_out/roberta_base/Custom_Dev_Eval_preds.json')\n",
        "quail_dev_preds = load_dict('./quail_out/roberta_base/Quail_Dev_Eval_preds.json')\n",
        "custom_train_preds = load_dict('./quail_out/roberta_base/Train_Eval_preds.json')\n",
        "type_names = ['Character_identity', 'Causality', 'Event_duration', 'Subsequent_state','Factual', 'Belief_states', 'Entity_properties', 'Unanswerable', 'Temporal_order']\n",
        "\n",
        "# Annotate the synthetic training set\n",
        "synthetic_without_seq_with_quail_train = load_dataset('json', data_files='./data/synthetic_without_seq_with_quail_train.jsonl')['train']\n",
        "with open('./annotated_data/synthetic_without_seq_with_quail_with_reasoning_train.jsonl', 'w', encoding='utf-8') as w:\n",
        "    for entry in synthetic_without_seq_with_quail_train:\n",
        "        reasoning_type = type_names[custom_train_preds[entry['id']]]\n",
        "        entry['question'] = \"Question type: {}. {}\".format(reasoning_type.replace('_', ' '), entry['question'])\n",
        "        w.write(json.dumps(entry) + '\\n')\n",
        "\n",
        "# Annotate the synthetic dev set\n",
        "synthetic_without_seq_with_quail_dev = load_dataset('json', data_files='./data/synthetic_without_seq_with_quail_dev.jsonl')['train']\n",
        "with open('./annotated_data/synthetic_without_seq_with_quail_with_reasoning_dev.jsonl', 'w', encoding='utf-8') as w:\n",
        "    for entry in synthetic_without_seq_with_quail_dev:\n",
        "        reasoning_type = type_names[custom_dev_preds[entry['id']]]\n",
        "        entry['question'] = \"Question type: {}. {}\".format(reasoning_type.replace('_', ' '), entry['question'])\n",
        "        w.write(json.dumps(entry) + '\\n')\n",
        "\n",
        "# Annotate the quail dev set\n",
        "quail_dev = load_dataset('json', data_files='./data/dev.jsonl')['train']\n",
        "with open('./annotated_data/quail_with_reasoning_dev.jsonl', 'w', encoding='utf-8') as w:\n",
        "    for entry in quail_dev:\n",
        "        reasoning_type = type_names[quail_dev_preds[entry['id']]]\n",
        "        entry['question'] = \"Question type: {}. {}\".format(reasoning_type.replace('_', ' '), entry['question'])\n",
        "        w.write(json.dumps(entry) + '\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using custom data configuration default\n",
            "Reusing dataset json (/root/.cache/huggingface/datasets/json/default-75d56dec875ca6ab/0.0.0/70d89ed4db1394f028c651589fcab6d6b28dddcabbe39d3b21b4d41f9a708514)\n",
            "Using custom data configuration default\n",
            "Reusing dataset json (/root/.cache/huggingface/datasets/json/default-e6bf455afbabcf80/0.0.0/70d89ed4db1394f028c651589fcab6d6b28dddcabbe39d3b21b4d41f9a708514)\n",
            "Using custom data configuration default\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading and preparing dataset json/default-ef4fb0dccfb36032 (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/json/default-ef4fb0dccfb36032/0.0.0/70d89ed4db1394f028c651589fcab6d6b28dddcabbe39d3b21b4d41f9a708514...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4f54db4d7daa4c02ac1002949c0e197b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\rDataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-ef4fb0dccfb36032/0.0.0/70d89ed4db1394f028c651589fcab6d6b28dddcabbe39d3b21b4d41f9a708514. Subsequent calls will reuse this data.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_aDYzu5NpaH"
      },
      "source": [
        "Copy annotated data sets to default quail dev location to be used automatically during the run."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZYwlnaKOsNL"
      },
      "source": [
        "!cp ./annotated_data/quail_with_reasoning_dev.jsonl data/dev.jsonl\n",
        "!cp ./annotated_data/synthetic_without_seq_with_quail_with_reasoning_dev.jsonl ./data/synthetic_without_seq_with_quail_with_reasoning_dev.jsonl\n",
        "!cp ./annotated_data/synthetic_without_seq_with_quail_with_reasoning_train.jsonl ./data/synthetic_without_seq_with_quail_with_reasoning_train.jsonl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AjjbBJWPGFy"
      },
      "source": [
        "Train a new QA model with the annotated datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cA0Qv5n9Ntp9",
        "outputId": "057def75-16cc-421f-d569-24fee6cc9038"
      },
      "source": [
        "!python ./transformers/examples/multiple-choice/run_multiple_choice.py \\\n",
        "  --task_name quail \\\n",
        "  --model_name_or_path roberta-base \\\n",
        "  --do_train \\\n",
        "  --do_eval \\\n",
        "  --data_dir ./data \\\n",
        "  --learning_rate 1e-5 \\\n",
        "  --num_train_epochs 2 \\\n",
        "  --max_seq_length 512 \\\n",
        "  --output_dir quail_out/roberta_base \\\n",
        "  --per_device_eval_batch_size=2 \\\n",
        "  --per_device_train_batch_size=2 \\\n",
        "  --gradient_accumulation_steps 25 \\\n",
        "  --overwrite_output \\\n",
        "  --cache_dir colab_cache \\\n",
        "  --run_name roberta-base--with_upsteam_reasoning_classification \\\n",
        "  --logging_steps 25 \\\n",
        "  --quail_dev_key_path ./data/quail_dev_key.json \\\n",
        "  --custom_training_filename synthetic_without_seq_with_quail_with_reasoning_train.jsonl \\\n",
        "  --custom_eval_filename synthetic_without_seq_with_quail_with_reasoning_dev.jsonl \\\n",
        "  --custom_dev_key_path ./data/synthetic_with_quail_dev_key.json \\\n",
        "  --eval_on_training_set \\\n",
        "  --overwrite_cache"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-11-30 17:42:05.689503: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "11/30/2020 17:42:07 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "11/30/2020 17:42:07 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='quail_out/roberta_base', overwrite_output_dir=True, do_train=True, do_eval=True, do_predict=False, evaluate_during_training=False, evaluation_strategy=<EvaluationStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=2, per_device_eval_batch_size=2, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=25, eval_accumulation_steps=None, learning_rate=1e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=2.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Nov30_17-42-07_650e5d6ad2e4', logging_first_step=False, logging_steps=25, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=25, dataloader_num_workers=0, past_index=-1, run_name='roberta-base--with_upsteam_reasoning_classification', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None)\n",
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForMultipleChoice: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
            "- This IS expected if you are initializing RobertaForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForMultipleChoice were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "11/30/2020 17:42:13 - INFO - filelock -   Lock 140122282062344 acquired on ./data/cached_train_RobertaTokenizer_512_quail.lock\n",
            "11/30/2020 17:42:13 - INFO - utils_multiple_choice -   Creating features from dataset file at ./data\n",
            "LOOKING AT ./data train\n",
            "11/30/2020 17:42:14 - INFO - utils_multiple_choice -   Training examples: 32039\n",
            "convert examples to features: 0it [00:00, ?it/s]11/30/2020 17:42:14 - INFO - utils_multiple_choice -   Writing example 0 of 32039\n",
            "convert examples to features: 997it [00:05, 194.49it/s]11/30/2020 17:42:19 - INFO - utils_multiple_choice -   Writing example 1000 of 32039\n",
            "convert examples to features: 1996it [00:10, 227.03it/s]11/30/2020 17:42:24 - INFO - utils_multiple_choice -   Writing example 2000 of 32039\n",
            "convert examples to features: 2990it [00:14, 216.38it/s]11/30/2020 17:42:29 - INFO - utils_multiple_choice -   Writing example 3000 of 32039\n",
            "convert examples to features: 3976it [00:19, 232.40it/s]11/30/2020 17:42:34 - INFO - utils_multiple_choice -   Writing example 4000 of 32039\n",
            "convert examples to features: 4998it [00:23, 242.12it/s]11/30/2020 17:42:38 - INFO - utils_multiple_choice -   Writing example 5000 of 32039\n",
            "convert examples to features: 5983it [00:28, 215.93it/s]11/30/2020 17:42:43 - INFO - utils_multiple_choice -   Writing example 6000 of 32039\n",
            "convert examples to features: 6983it [00:32, 218.18it/s]11/30/2020 17:42:47 - INFO - utils_multiple_choice -   Writing example 7000 of 32039\n",
            "convert examples to features: 7987it [00:37, 219.41it/s]11/30/2020 17:42:52 - INFO - utils_multiple_choice -   Writing example 8000 of 32039\n",
            "convert examples to features: 8977it [00:41, 235.22it/s]11/30/2020 17:42:56 - INFO - utils_multiple_choice -   Writing example 9000 of 32039\n",
            "convert examples to features: 9990it [00:46, 230.69it/s]11/30/2020 17:43:01 - INFO - utils_multiple_choice -   Writing example 10000 of 32039\n",
            "convert examples to features: 10999it [00:51, 220.92it/s]11/30/2020 17:43:05 - INFO - utils_multiple_choice -   Writing example 11000 of 32039\n",
            "convert examples to features: 11997it [00:55, 223.20it/s]11/30/2020 17:43:10 - INFO - utils_multiple_choice -   Writing example 12000 of 32039\n",
            "convert examples to features: 12982it [01:00, 230.48it/s]11/30/2020 17:43:14 - INFO - utils_multiple_choice -   Writing example 13000 of 32039\n",
            "convert examples to features: 13983it [01:05, 177.42it/s]11/30/2020 17:43:19 - INFO - utils_multiple_choice -   Writing example 14000 of 32039\n",
            "convert examples to features: 14986it [01:09, 222.55it/s]11/30/2020 17:43:24 - INFO - utils_multiple_choice -   Writing example 15000 of 32039\n",
            "convert examples to features: 15992it [01:14, 222.07it/s]11/30/2020 17:43:28 - INFO - utils_multiple_choice -   Writing example 16000 of 32039\n",
            "convert examples to features: 16985it [01:18, 228.61it/s]11/30/2020 17:43:33 - INFO - utils_multiple_choice -   Writing example 17000 of 32039\n",
            "convert examples to features: 17992it [01:23, 209.51it/s]11/30/2020 17:43:37 - INFO - utils_multiple_choice -   Writing example 18000 of 32039\n",
            "convert examples to features: 18987it [01:27, 221.44it/s]11/30/2020 17:43:42 - INFO - utils_multiple_choice -   Writing example 19000 of 32039\n",
            "convert examples to features: 20000it [01:32, 217.56it/s]11/30/2020 17:43:47 - INFO - utils_multiple_choice -   Writing example 20000 of 32039\n",
            "convert examples to features: 20991it [01:36, 219.83it/s]11/30/2020 17:43:51 - INFO - utils_multiple_choice -   Writing example 21000 of 32039\n",
            "convert examples to features: 21975it [01:41, 206.84it/s]11/30/2020 17:43:56 - INFO - utils_multiple_choice -   Writing example 22000 of 32039\n",
            "convert examples to features: 22979it [01:46, 202.15it/s]11/30/2020 17:44:00 - INFO - utils_multiple_choice -   Writing example 23000 of 32039\n",
            "convert examples to features: 23980it [01:50, 209.06it/s]11/30/2020 17:44:05 - INFO - utils_multiple_choice -   Writing example 24000 of 32039\n",
            "convert examples to features: 24996it [01:55, 227.63it/s]11/30/2020 17:44:09 - INFO - utils_multiple_choice -   Writing example 25000 of 32039\n",
            "convert examples to features: 25989it [01:59, 212.15it/s]11/30/2020 17:44:14 - INFO - utils_multiple_choice -   Writing example 26000 of 32039\n",
            "convert examples to features: 26979it [02:04, 214.63it/s]11/30/2020 17:44:18 - INFO - utils_multiple_choice -   Writing example 27000 of 32039\n",
            "convert examples to features: 27981it [02:09, 218.06it/s]11/30/2020 17:44:24 - INFO - utils_multiple_choice -   Writing example 28000 of 32039\n",
            "convert examples to features: 28984it [02:14, 231.27it/s]11/30/2020 17:44:28 - INFO - utils_multiple_choice -   Writing example 29000 of 32039\n",
            "convert examples to features: 29996it [02:18, 232.10it/s]11/30/2020 17:44:33 - INFO - utils_multiple_choice -   Writing example 30000 of 32039\n",
            "convert examples to features: 30995it [02:22, 227.82it/s]11/30/2020 17:44:37 - INFO - utils_multiple_choice -   Writing example 31000 of 32039\n",
            "convert examples to features: 31989it [02:27, 208.68it/s]11/30/2020 17:44:42 - INFO - utils_multiple_choice -   Writing example 32000 of 32039\n",
            "convert examples to features: 32039it [02:27, 217.12it/s]\n",
            "11/30/2020 17:44:42 - INFO - utils_multiple_choice -   *** Example ***\n",
            "11/30/2020 17:44:42 - INFO - utils_multiple_choice -   feature: InputFeatures(example_id='custom_9617', input_ids=[[0, 170, 95, 56, 123, 42836, 30, 10, 400, 13174, 8, 14, 817, 201, 619, 357, 4, 345, 16, 10, 778, 14, 37, 189, 45, 6008, 53, 38, 216, 127, 910, 7010, 8, 37, 16, 10, 7251, 4, 38, 216, 52, 40, 1137, 47, 14, 37, 16, 567, 124, 4, 3401, 10745, 13, 123, 8, 3392, 47, 182, 203, 4, 2, 2, 45641, 1907, 35, 8316, 687, 6948, 4, 653, 189, 28, 10, 27099, 754, 59, 1774, 17487, 91, 16, 10, 182, 2245, 664, 313, 479, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 170, 95, 56, 123, 42836, 30, 10, 400, 13174, 8, 14, 817, 201, 619, 357, 4, 345, 16, 10, 778, 14, 37, 189, 45, 6008, 53, 38, 216, 127, 910, 7010, 8, 37, 16, 10, 7251, 4, 38, 216, 52, 40, 1137, 47, 14, 37, 16, 567, 124, 4, 3401, 10745, 13, 123, 8, 3392, 47, 182, 203, 4, 2, 2, 45641, 1907, 35, 8316, 687, 6948, 4, 653, 189, 28, 10, 27099, 754, 59, 1774, 17487, 91, 16, 10, 2038, 7251, 479, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 170, 95, 56, 123, 42836, 30, 10, 400, 13174, 8, 14, 817, 201, 619, 357, 4, 345, 16, 10, 778, 14, 37, 189, 45, 6008, 53, 38, 216, 127, 910, 7010, 8, 37, 16, 10, 7251, 4, 38, 216, 52, 40, 1137, 47, 14, 37, 16, 567, 124, 4, 3401, 10745, 13, 123, 8, 3392, 47, 182, 203, 4, 2, 2, 45641, 1907, 35, 8316, 687, 6948, 4, 653, 189, 28, 10, 27099, 754, 59, 1774, 17487, 91, 34, 10, 301, 111, 5608, 2199, 479, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 170, 95, 56, 123, 42836, 30, 10, 400, 13174, 8, 14, 817, 201, 619, 357, 4, 345, 16, 10, 778, 14, 37, 189, 45, 6008, 53, 38, 216, 127, 910, 7010, 8, 37, 16, 10, 7251, 4, 38, 216, 52, 40, 1137, 47, 14, 37, 16, 567, 124, 4, 3401, 10745, 13, 123, 8, 3392, 47, 182, 203, 4, 2, 2, 45641, 1907, 35, 8316, 687, 6948, 4, 653, 189, 28, 10, 27099, 754, 59, 1774, 17487, 45, 615, 335, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], attention_mask=[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], token_type_ids=None, label=2)\n",
            "11/30/2020 17:44:42 - INFO - utils_multiple_choice -   *** Example ***\n",
            "11/30/2020 17:44:42 - INFO - utils_multiple_choice -   feature: InputFeatures(example_id='custom_4690', input_ids=[[0, 100, 64, 3581, 13, 10, 186, 4, 1437, 1554, 5186, 181, 19747, 10, 19489, 9, 1637, 15750, 15, 39, 7494, 4, 1437, 345, 16, 1819, 117, 936, 19, 1055, 122, 111, 960, 16, 11, 1707, 4, 1437, 22995, 2327, 39, 8413, 4, 1437, 38, 109, 45, 679, 47, 95, 362, 14, 418, 1666, 1437, 1437, 1437, 1437, 2156, 25, 114, 51, 956, 42, 418, 116, 2, 2, 45641, 1907, 35, 8316, 687, 6948, 4, 4820, 429, 33, 1554, 5186, 303, 5, 1637, 15750, 17487, 45, 615, 335, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 100, 64, 3581, 13, 10, 186, 4, 1437, 1554, 5186, 181, 19747, 10, 19489, 9, 1637, 15750, 15, 39, 7494, 4, 1437, 345, 16, 1819, 117, 936, 19, 1055, 122, 111, 960, 16, 11, 1707, 4, 1437, 22995, 2327, 39, 8413, 4, 1437, 38, 109, 45, 679, 47, 95, 362, 14, 418, 1666, 1437, 1437, 1437, 1437, 2156, 25, 114, 51, 956, 42, 418, 116, 2, 2, 45641, 1907, 35, 8316, 687, 6948, 4, 4820, 429, 33, 1554, 5186, 303, 5, 1637, 15750, 17487, 91, 429, 33, 13266, 951, 15, 5, 921, 479, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 100, 64, 3581, 13, 10, 186, 4, 1437, 1554, 5186, 181, 19747, 10, 19489, 9, 1637, 15750, 15, 39, 7494, 4, 1437, 345, 16, 1819, 117, 936, 19, 1055, 122, 111, 960, 16, 11, 1707, 4, 1437, 22995, 2327, 39, 8413, 4, 1437, 38, 109, 45, 679, 47, 95, 362, 14, 418, 1666, 1437, 1437, 1437, 1437, 2156, 25, 114, 51, 956, 42, 418, 116, 2, 2, 45641, 1907, 35, 8316, 687, 6948, 4, 4820, 429, 33, 1554, 5186, 303, 5, 1637, 15750, 17487, 91, 429, 33, 1146, 106, 19, 123, 70, 552, 479, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 100, 64, 3581, 13, 10, 186, 4, 1437, 1554, 5186, 181, 19747, 10, 19489, 9, 1637, 15750, 15, 39, 7494, 4, 1437, 345, 16, 1819, 117, 936, 19, 1055, 122, 111, 960, 16, 11, 1707, 4, 1437, 22995, 2327, 39, 8413, 4, 1437, 38, 109, 45, 679, 47, 95, 362, 14, 418, 1666, 1437, 1437, 1437, 1437, 2156, 25, 114, 51, 956, 42, 418, 116, 2, 2, 45641, 1907, 35, 8316, 687, 6948, 4, 4820, 429, 33, 1554, 5186, 303, 5, 1637, 15750, 17487, 91, 429, 33, 303, 15, 10, 921, 8, 2738, 106, 62, 479, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], attention_mask=[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], token_type_ids=None, label=3)\n",
            "11/30/2020 17:44:42 - INFO - utils_multiple_choice -   Saving features into cached file ./data/cached_train_RobertaTokenizer_512_quail\n",
            "11/30/2020 17:45:23 - INFO - filelock -   Lock 140122282062344 released on ./data/cached_train_RobertaTokenizer_512_quail.lock\n",
            "11/30/2020 17:45:23 - INFO - filelock -   Lock 140122281963648 acquired on ./data/cached_dev_RobertaTokenizer_512_quail.lock\n",
            "11/30/2020 17:45:23 - INFO - utils_multiple_choice -   Creating features from dataset file at ./data\n",
            "LOOKING AT ./data dev\n",
            "11/30/2020 17:45:23 - INFO - utils_multiple_choice -   Training examples: 2164\n",
            "convert examples to features: 0it [00:00, ?it/s]11/30/2020 17:45:23 - INFO - utils_multiple_choice -   Writing example 0 of 2164\n",
            "convert examples to features: 995it [00:07, 136.94it/s]11/30/2020 17:45:31 - INFO - utils_multiple_choice -   Writing example 1000 of 2164\n",
            "convert examples to features: 1992it [00:15, 121.58it/s]11/30/2020 17:45:39 - INFO - utils_multiple_choice -   Writing example 2000 of 2164\n",
            "convert examples to features: 2164it [00:17, 126.46it/s]\n",
            "11/30/2020 17:45:41 - INFO - utils_multiple_choice -   *** Example ***\n",
            "11/30/2020 17:45:41 - INFO - utils_multiple_choice -   feature: InputFeatures(example_id='f141_0', input_ids=[[0, 347, 10708, 3996, 5, 38048, 313, 1305, 39, 4334, 8588, 88, 5, 9742, 1400, 2932, 319, 8, 2999, 198, 7, 5, 526, 6, 583, 5, 124, 2797, 9, 5, 745, 4, 345, 58, 2710, 9, 490, 20063, 11, 5, 760, 6, 98, 79, 11464, 5, 2173, 21, 89, 13, 402, 97, 87, 10, 3298, 9, 8053, 8, 10, 1029, 1071, 4, 50118, 250, 23141, 24572, 10879, 62, 69, 7983, 12, 7771, 9211, 8, 79, 1481, 35158, 4, 264, 11224, 69, 5856, 561, 18412, 7, 5368, 103, 2859, 4, 20, 4117, 12, 3530, 10317, 4371, 69, 1730, 8, 32606, 6, 53, 69, 17507, 21, 11074, 160, 4, 50118, 2515, 875, 159, 5, 4385, 346, 25, 79, 36110, 198, 7, 5, 526, 9, 5, 3214, 1155, 4, 91, 581, 33, 10, 380, 885, 625, 9, 1055, 6, 79, 802, 4, 50118, 38544, 5078, 329, 368, 56, 95, 4425, 66, 9, 5, 512, 6, 77, 79, 26, 6, 22, 41541, 512, 6, 13834, 72, 50118, 113, 42903, 6, 2446, 72, 50118, 113, 100, 437, 25575, 4, 370, 300, 10, 4045, 13495, 3422, 1917, 50118, 894, 851, 69, 5, 683, 81, 4, 1405, 909, 2549, 18699, 10, 1256, 6, 664, 12, 3690, 652, 4, 20, 614, 12, 8267, 3089, 11556, 314, 410, 7, 5, 13670, 6, 6254, 9646, 69, 42529, 4, 264, 21, 674, 6958, 6, 53, 5, 239, 19728, 10317, 10944, 69, 7, 59, 195, 108, 398, 845, 20, 251, 5856, 58, 182, 2579, 4, 50118, 38544, 56, 393, 341, 10, 36289, 4, 91, 1017, 460, 802, 9, 24, 25, 34633, 2577, 4, 20, 1114, 9, 519, 2099, 19, 10, 693, 54, 1017, 57, 19, 2213, 9, 604, 222, 45, 2868, 7, 123, 4, 50118, 1708, 42, 399, 75, 2045, 101, 10, 6097, 9337, 254, 4, 264, 2551, 350, 2382, 5579, 26949, 8309, 4, 125, 9, 768, 6, 79, 938, 75, 4, 91, 1467, 79, 56, 7, 28, 95, 25, 2972, 30451, 25, 5, 1079, 9, 106, 4, 3180, 5579, 1594, 37, 5844, 75, 57, 11, 5, 1692, 9, 402, 505, 37, 429, 33, 57, 55, 87, 2882, 7, 907, 99, 79, 21, 2183, 4, 50118, 113, 2847, 6, 99, 109, 47, 224, 116, 7348, 7, 120, 24, 15, 1917, 264, 20185, 10195, 21491, 6608, 4, 50118, 894, 21, 6889, 14, 79, 56, 70, 69, 9927, 6, 8, 14, 51, 1415, 1104, 4, 50118, 113, 6179, 64, 38, 11942, 1917, 91, 44060, 23, 69, 8, 39422, 196, 4, 2, 2, 45641, 1907, 35, 11373, 13428, 4, 1336, 251, 21, 25575, 667, 7, 10195, 15431, 6045, 116, 59, 158, 728, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 347, 10708, 3996, 5, 38048, 313, 1305, 39, 4334, 8588, 88, 5, 9742, 1400, 2932, 319, 8, 2999, 198, 7, 5, 526, 6, 583, 5, 124, 2797, 9, 5, 745, 4, 345, 58, 2710, 9, 490, 20063, 11, 5, 760, 6, 98, 79, 11464, 5, 2173, 21, 89, 13, 402, 97, 87, 10, 3298, 9, 8053, 8, 10, 1029, 1071, 4, 50118, 250, 23141, 24572, 10879, 62, 69, 7983, 12, 7771, 9211, 8, 79, 1481, 35158, 4, 264, 11224, 69, 5856, 561, 18412, 7, 5368, 103, 2859, 4, 20, 4117, 12, 3530, 10317, 4371, 69, 1730, 8, 32606, 6, 53, 69, 17507, 21, 11074, 160, 4, 50118, 2515, 875, 159, 5, 4385, 346, 25, 79, 36110, 198, 7, 5, 526, 9, 5, 3214, 1155, 4, 91, 581, 33, 10, 380, 885, 625, 9, 1055, 6, 79, 802, 4, 50118, 38544, 5078, 329, 368, 56, 95, 4425, 66, 9, 5, 512, 6, 77, 79, 26, 6, 22, 41541, 512, 6, 13834, 72, 50118, 113, 42903, 6, 2446, 72, 50118, 113, 100, 437, 25575, 4, 370, 300, 10, 4045, 13495, 3422, 1917, 50118, 894, 851, 69, 5, 683, 81, 4, 1405, 909, 2549, 18699, 10, 1256, 6, 664, 12, 3690, 652, 4, 20, 614, 12, 8267, 3089, 11556, 314, 410, 7, 5, 13670, 6, 6254, 9646, 69, 42529, 4, 264, 21, 674, 6958, 6, 53, 5, 239, 19728, 10317, 10944, 69, 7, 59, 195, 108, 398, 845, 20, 251, 5856, 58, 182, 2579, 4, 50118, 38544, 56, 393, 341, 10, 36289, 4, 91, 1017, 460, 802, 9, 24, 25, 34633, 2577, 4, 20, 1114, 9, 519, 2099, 19, 10, 693, 54, 1017, 57, 19, 2213, 9, 604, 222, 45, 2868, 7, 123, 4, 50118, 1708, 42, 399, 75, 2045, 101, 10, 6097, 9337, 254, 4, 264, 2551, 350, 2382, 5579, 26949, 8309, 4, 125, 9, 768, 6, 79, 938, 75, 4, 91, 1467, 79, 56, 7, 28, 95, 25, 2972, 30451, 25, 5, 1079, 9, 106, 4, 3180, 5579, 1594, 37, 5844, 75, 57, 11, 5, 1692, 9, 402, 505, 37, 429, 33, 57, 55, 87, 2882, 7, 907, 99, 79, 21, 2183, 4, 50118, 113, 2847, 6, 99, 109, 47, 224, 116, 7348, 7, 120, 24, 15, 1917, 264, 20185, 10195, 21491, 6608, 4, 50118, 894, 21, 6889, 14, 79, 56, 70, 69, 9927, 6, 8, 14, 51, 1415, 1104, 4, 50118, 113, 6179, 64, 38, 11942, 1917, 91, 44060, 23, 69, 8, 39422, 196, 4, 2, 2, 45641, 1907, 35, 11373, 13428, 4, 1336, 251, 21, 25575, 667, 7, 10195, 15431, 6045, 116, 59, 132, 722, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 347, 10708, 3996, 5, 38048, 313, 1305, 39, 4334, 8588, 88, 5, 9742, 1400, 2932, 319, 8, 2999, 198, 7, 5, 526, 6, 583, 5, 124, 2797, 9, 5, 745, 4, 345, 58, 2710, 9, 490, 20063, 11, 5, 760, 6, 98, 79, 11464, 5, 2173, 21, 89, 13, 402, 97, 87, 10, 3298, 9, 8053, 8, 10, 1029, 1071, 4, 50118, 250, 23141, 24572, 10879, 62, 69, 7983, 12, 7771, 9211, 8, 79, 1481, 35158, 4, 264, 11224, 69, 5856, 561, 18412, 7, 5368, 103, 2859, 4, 20, 4117, 12, 3530, 10317, 4371, 69, 1730, 8, 32606, 6, 53, 69, 17507, 21, 11074, 160, 4, 50118, 2515, 875, 159, 5, 4385, 346, 25, 79, 36110, 198, 7, 5, 526, 9, 5, 3214, 1155, 4, 91, 581, 33, 10, 380, 885, 625, 9, 1055, 6, 79, 802, 4, 50118, 38544, 5078, 329, 368, 56, 95, 4425, 66, 9, 5, 512, 6, 77, 79, 26, 6, 22, 41541, 512, 6, 13834, 72, 50118, 113, 42903, 6, 2446, 72, 50118, 113, 100, 437, 25575, 4, 370, 300, 10, 4045, 13495, 3422, 1917, 50118, 894, 851, 69, 5, 683, 81, 4, 1405, 909, 2549, 18699, 10, 1256, 6, 664, 12, 3690, 652, 4, 20, 614, 12, 8267, 3089, 11556, 314, 410, 7, 5, 13670, 6, 6254, 9646, 69, 42529, 4, 264, 21, 674, 6958, 6, 53, 5, 239, 19728, 10317, 10944, 69, 7, 59, 195, 108, 398, 845, 20, 251, 5856, 58, 182, 2579, 4, 50118, 38544, 56, 393, 341, 10, 36289, 4, 91, 1017, 460, 802, 9, 24, 25, 34633, 2577, 4, 20, 1114, 9, 519, 2099, 19, 10, 693, 54, 1017, 57, 19, 2213, 9, 604, 222, 45, 2868, 7, 123, 4, 50118, 1708, 42, 399, 75, 2045, 101, 10, 6097, 9337, 254, 4, 264, 2551, 350, 2382, 5579, 26949, 8309, 4, 125, 9, 768, 6, 79, 938, 75, 4, 91, 1467, 79, 56, 7, 28, 95, 25, 2972, 30451, 25, 5, 1079, 9, 106, 4, 3180, 5579, 1594, 37, 5844, 75, 57, 11, 5, 1692, 9, 402, 505, 37, 429, 33, 57, 55, 87, 2882, 7, 907, 99, 79, 21, 2183, 4, 50118, 113, 2847, 6, 99, 109, 47, 224, 116, 7348, 7, 120, 24, 15, 1917, 264, 20185, 10195, 21491, 6608, 4, 50118, 894, 21, 6889, 14, 79, 56, 70, 69, 9927, 6, 8, 14, 51, 1415, 1104, 4, 50118, 113, 6179, 64, 38, 11942, 1917, 91, 44060, 23, 69, 8, 39422, 196, 4, 2, 2, 45641, 1907, 35, 11373, 13428, 4, 1336, 251, 21, 25575, 667, 7, 10195, 15431, 6045, 116, 45, 615, 335, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 347, 10708, 3996, 5, 38048, 313, 1305, 39, 4334, 8588, 88, 5, 9742, 1400, 2932, 319, 8, 2999, 198, 7, 5, 526, 6, 583, 5, 124, 2797, 9, 5, 745, 4, 345, 58, 2710, 9, 490, 20063, 11, 5, 760, 6, 98, 79, 11464, 5, 2173, 21, 89, 13, 402, 97, 87, 10, 3298, 9, 8053, 8, 10, 1029, 1071, 4, 50118, 250, 23141, 24572, 10879, 62, 69, 7983, 12, 7771, 9211, 8, 79, 1481, 35158, 4, 264, 11224, 69, 5856, 561, 18412, 7, 5368, 103, 2859, 4, 20, 4117, 12, 3530, 10317, 4371, 69, 1730, 8, 32606, 6, 53, 69, 17507, 21, 11074, 160, 4, 50118, 2515, 875, 159, 5, 4385, 346, 25, 79, 36110, 198, 7, 5, 526, 9, 5, 3214, 1155, 4, 91, 581, 33, 10, 380, 885, 625, 9, 1055, 6, 79, 802, 4, 50118, 38544, 5078, 329, 368, 56, 95, 4425, 66, 9, 5, 512, 6, 77, 79, 26, 6, 22, 41541, 512, 6, 13834, 72, 50118, 113, 42903, 6, 2446, 72, 50118, 113, 100, 437, 25575, 4, 370, 300, 10, 4045, 13495, 3422, 1917, 50118, 894, 851, 69, 5, 683, 81, 4, 1405, 909, 2549, 18699, 10, 1256, 6, 664, 12, 3690, 652, 4, 20, 614, 12, 8267, 3089, 11556, 314, 410, 7, 5, 13670, 6, 6254, 9646, 69, 42529, 4, 264, 21, 674, 6958, 6, 53, 5, 239, 19728, 10317, 10944, 69, 7, 59, 195, 108, 398, 845, 20, 251, 5856, 58, 182, 2579, 4, 50118, 38544, 56, 393, 341, 10, 36289, 4, 91, 1017, 460, 802, 9, 24, 25, 34633, 2577, 4, 20, 1114, 9, 519, 2099, 19, 10, 693, 54, 1017, 57, 19, 2213, 9, 604, 222, 45, 2868, 7, 123, 4, 50118, 1708, 42, 399, 75, 2045, 101, 10, 6097, 9337, 254, 4, 264, 2551, 350, 2382, 5579, 26949, 8309, 4, 125, 9, 768, 6, 79, 938, 75, 4, 91, 1467, 79, 56, 7, 28, 95, 25, 2972, 30451, 25, 5, 1079, 9, 106, 4, 3180, 5579, 1594, 37, 5844, 75, 57, 11, 5, 1692, 9, 402, 505, 37, 429, 33, 57, 55, 87, 2882, 7, 907, 99, 79, 21, 2183, 4, 50118, 113, 2847, 6, 99, 109, 47, 224, 116, 7348, 7, 120, 24, 15, 1917, 264, 20185, 10195, 21491, 6608, 4, 50118, 894, 21, 6889, 14, 79, 56, 70, 69, 9927, 6, 8, 14, 51, 1415, 1104, 4, 50118, 113, 6179, 64, 38, 11942, 1917, 91, 44060, 23, 69, 8, 39422, 196, 4, 2, 2, 45641, 1907, 35, 11373, 13428, 4, 1336, 251, 21, 25575, 667, 7, 10195, 15431, 6045, 116, 404, 183, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], attention_mask=[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], token_type_ids=None, label=0)\n",
            "11/30/2020 17:45:41 - INFO - utils_multiple_choice -   *** Example ***\n",
            "11/30/2020 17:45:41 - INFO - utils_multiple_choice -   feature: InputFeatures(example_id='f141_1', input_ids=[[0, 347, 10708, 3996, 5, 38048, 313, 1305, 39, 4334, 8588, 88, 5, 9742, 1400, 2932, 319, 8, 2999, 198, 7, 5, 526, 6, 583, 5, 124, 2797, 9, 5, 745, 4, 345, 58, 2710, 9, 490, 20063, 11, 5, 760, 6, 98, 79, 11464, 5, 2173, 21, 89, 13, 402, 97, 87, 10, 3298, 9, 8053, 8, 10, 1029, 1071, 4, 50118, 250, 23141, 24572, 10879, 62, 69, 7983, 12, 7771, 9211, 8, 79, 1481, 35158, 4, 264, 11224, 69, 5856, 561, 18412, 7, 5368, 103, 2859, 4, 20, 4117, 12, 3530, 10317, 4371, 69, 1730, 8, 32606, 6, 53, 69, 17507, 21, 11074, 160, 4, 50118, 2515, 875, 159, 5, 4385, 346, 25, 79, 36110, 198, 7, 5, 526, 9, 5, 3214, 1155, 4, 91, 581, 33, 10, 380, 885, 625, 9, 1055, 6, 79, 802, 4, 50118, 38544, 5078, 329, 368, 56, 95, 4425, 66, 9, 5, 512, 6, 77, 79, 26, 6, 22, 41541, 512, 6, 13834, 72, 50118, 113, 42903, 6, 2446, 72, 50118, 113, 100, 437, 25575, 4, 370, 300, 10, 4045, 13495, 3422, 1917, 50118, 894, 851, 69, 5, 683, 81, 4, 1405, 909, 2549, 18699, 10, 1256, 6, 664, 12, 3690, 652, 4, 20, 614, 12, 8267, 3089, 11556, 314, 410, 7, 5, 13670, 6, 6254, 9646, 69, 42529, 4, 264, 21, 674, 6958, 6, 53, 5, 239, 19728, 10317, 10944, 69, 7, 59, 195, 108, 398, 845, 20, 251, 5856, 58, 182, 2579, 4, 50118, 38544, 56, 393, 341, 10, 36289, 4, 91, 1017, 460, 802, 9, 24, 25, 34633, 2577, 4, 20, 1114, 9, 519, 2099, 19, 10, 693, 54, 1017, 57, 19, 2213, 9, 604, 222, 45, 2868, 7, 123, 4, 50118, 1708, 42, 399, 75, 2045, 101, 10, 6097, 9337, 254, 4, 264, 2551, 350, 2382, 5579, 26949, 8309, 4, 125, 9, 768, 6, 79, 938, 75, 4, 91, 1467, 79, 56, 7, 28, 95, 25, 2972, 30451, 25, 5, 1079, 9, 106, 4, 3180, 5579, 1594, 37, 5844, 75, 57, 11, 5, 1692, 9, 402, 505, 37, 429, 33, 57, 55, 87, 2882, 7, 907, 99, 79, 21, 2183, 4, 50118, 113, 2847, 6, 99, 109, 47, 224, 116, 7348, 7, 120, 24, 15, 1917, 264, 20185, 10195, 21491, 6608, 4, 50118, 894, 21, 6889, 14, 79, 56, 70, 69, 9927, 6, 8, 14, 51, 1415, 1104, 4, 50118, 113, 6179, 64, 38, 11942, 1917, 91, 44060, 23, 69, 8, 39422, 196, 4, 2, 2, 45641, 1907, 35, 46718, 3611, 4, 653, 16, 1153, 1528, 59, 6045, 4, 6045, 473, 45, 33, 615, 418, 13, 10, 36289, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 347, 10708, 3996, 5, 38048, 313, 1305, 39, 4334, 8588, 88, 5, 9742, 1400, 2932, 319, 8, 2999, 198, 7, 5, 526, 6, 583, 5, 124, 2797, 9, 5, 745, 4, 345, 58, 2710, 9, 490, 20063, 11, 5, 760, 6, 98, 79, 11464, 5, 2173, 21, 89, 13, 402, 97, 87, 10, 3298, 9, 8053, 8, 10, 1029, 1071, 4, 50118, 250, 23141, 24572, 10879, 62, 69, 7983, 12, 7771, 9211, 8, 79, 1481, 35158, 4, 264, 11224, 69, 5856, 561, 18412, 7, 5368, 103, 2859, 4, 20, 4117, 12, 3530, 10317, 4371, 69, 1730, 8, 32606, 6, 53, 69, 17507, 21, 11074, 160, 4, 50118, 2515, 875, 159, 5, 4385, 346, 25, 79, 36110, 198, 7, 5, 526, 9, 5, 3214, 1155, 4, 91, 581, 33, 10, 380, 885, 625, 9, 1055, 6, 79, 802, 4, 50118, 38544, 5078, 329, 368, 56, 95, 4425, 66, 9, 5, 512, 6, 77, 79, 26, 6, 22, 41541, 512, 6, 13834, 72, 50118, 113, 42903, 6, 2446, 72, 50118, 113, 100, 437, 25575, 4, 370, 300, 10, 4045, 13495, 3422, 1917, 50118, 894, 851, 69, 5, 683, 81, 4, 1405, 909, 2549, 18699, 10, 1256, 6, 664, 12, 3690, 652, 4, 20, 614, 12, 8267, 3089, 11556, 314, 410, 7, 5, 13670, 6, 6254, 9646, 69, 42529, 4, 264, 21, 674, 6958, 6, 53, 5, 239, 19728, 10317, 10944, 69, 7, 59, 195, 108, 398, 845, 20, 251, 5856, 58, 182, 2579, 4, 50118, 38544, 56, 393, 341, 10, 36289, 4, 91, 1017, 460, 802, 9, 24, 25, 34633, 2577, 4, 20, 1114, 9, 519, 2099, 19, 10, 693, 54, 1017, 57, 19, 2213, 9, 604, 222, 45, 2868, 7, 123, 4, 50118, 1708, 42, 399, 75, 2045, 101, 10, 6097, 9337, 254, 4, 264, 2551, 350, 2382, 5579, 26949, 8309, 4, 125, 9, 768, 6, 79, 938, 75, 4, 91, 1467, 79, 56, 7, 28, 95, 25, 2972, 30451, 25, 5, 1079, 9, 106, 4, 3180, 5579, 1594, 37, 5844, 75, 57, 11, 5, 1692, 9, 402, 505, 37, 429, 33, 57, 55, 87, 2882, 7, 907, 99, 79, 21, 2183, 4, 50118, 113, 2847, 6, 99, 109, 47, 224, 116, 7348, 7, 120, 24, 15, 1917, 264, 20185, 10195, 21491, 6608, 4, 50118, 894, 21, 6889, 14, 79, 56, 70, 69, 9927, 6, 8, 14, 51, 1415, 1104, 4, 50118, 113, 6179, 64, 38, 11942, 1917, 91, 44060, 23, 69, 8, 39422, 196, 4, 2, 2, 45641, 1907, 35, 46718, 3611, 4, 653, 16, 1153, 1528, 59, 6045, 4, 45, 615, 335, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 347, 10708, 3996, 5, 38048, 313, 1305, 39, 4334, 8588, 88, 5, 9742, 1400, 2932, 319, 8, 2999, 198, 7, 5, 526, 6, 583, 5, 124, 2797, 9, 5, 745, 4, 345, 58, 2710, 9, 490, 20063, 11, 5, 760, 6, 98, 79, 11464, 5, 2173, 21, 89, 13, 402, 97, 87, 10, 3298, 9, 8053, 8, 10, 1029, 1071, 4, 50118, 250, 23141, 24572, 10879, 62, 69, 7983, 12, 7771, 9211, 8, 79, 1481, 35158, 4, 264, 11224, 69, 5856, 561, 18412, 7, 5368, 103, 2859, 4, 20, 4117, 12, 3530, 10317, 4371, 69, 1730, 8, 32606, 6, 53, 69, 17507, 21, 11074, 160, 4, 50118, 2515, 875, 159, 5, 4385, 346, 25, 79, 36110, 198, 7, 5, 526, 9, 5, 3214, 1155, 4, 91, 581, 33, 10, 380, 885, 625, 9, 1055, 6, 79, 802, 4, 50118, 38544, 5078, 329, 368, 56, 95, 4425, 66, 9, 5, 512, 6, 77, 79, 26, 6, 22, 41541, 512, 6, 13834, 72, 50118, 113, 42903, 6, 2446, 72, 50118, 113, 100, 437, 25575, 4, 370, 300, 10, 4045, 13495, 3422, 1917, 50118, 894, 851, 69, 5, 683, 81, 4, 1405, 909, 2549, 18699, 10, 1256, 6, 664, 12, 3690, 652, 4, 20, 614, 12, 8267, 3089, 11556, 314, 410, 7, 5, 13670, 6, 6254, 9646, 69, 42529, 4, 264, 21, 674, 6958, 6, 53, 5, 239, 19728, 10317, 10944, 69, 7, 59, 195, 108, 398, 845, 20, 251, 5856, 58, 182, 2579, 4, 50118, 38544, 56, 393, 341, 10, 36289, 4, 91, 1017, 460, 802, 9, 24, 25, 34633, 2577, 4, 20, 1114, 9, 519, 2099, 19, 10, 693, 54, 1017, 57, 19, 2213, 9, 604, 222, 45, 2868, 7, 123, 4, 50118, 1708, 42, 399, 75, 2045, 101, 10, 6097, 9337, 254, 4, 264, 2551, 350, 2382, 5579, 26949, 8309, 4, 125, 9, 768, 6, 79, 938, 75, 4, 91, 1467, 79, 56, 7, 28, 95, 25, 2972, 30451, 25, 5, 1079, 9, 106, 4, 3180, 5579, 1594, 37, 5844, 75, 57, 11, 5, 1692, 9, 402, 505, 37, 429, 33, 57, 55, 87, 2882, 7, 907, 99, 79, 21, 2183, 4, 50118, 113, 2847, 6, 99, 109, 47, 224, 116, 7348, 7, 120, 24, 15, 1917, 264, 20185, 10195, 21491, 6608, 4, 50118, 894, 21, 6889, 14, 79, 56, 70, 69, 9927, 6, 8, 14, 51, 1415, 1104, 4, 50118, 113, 6179, 64, 38, 11942, 1917, 91, 44060, 23, 69, 8, 39422, 196, 4, 2, 2, 45641, 1907, 35, 46718, 3611, 4, 653, 16, 1153, 1528, 59, 6045, 4, 6045, 3829, 2099, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 347, 10708, 3996, 5, 38048, 313, 1305, 39, 4334, 8588, 88, 5, 9742, 1400, 2932, 319, 8, 2999, 198, 7, 5, 526, 6, 583, 5, 124, 2797, 9, 5, 745, 4, 345, 58, 2710, 9, 490, 20063, 11, 5, 760, 6, 98, 79, 11464, 5, 2173, 21, 89, 13, 402, 97, 87, 10, 3298, 9, 8053, 8, 10, 1029, 1071, 4, 50118, 250, 23141, 24572, 10879, 62, 69, 7983, 12, 7771, 9211, 8, 79, 1481, 35158, 4, 264, 11224, 69, 5856, 561, 18412, 7, 5368, 103, 2859, 4, 20, 4117, 12, 3530, 10317, 4371, 69, 1730, 8, 32606, 6, 53, 69, 17507, 21, 11074, 160, 4, 50118, 2515, 875, 159, 5, 4385, 346, 25, 79, 36110, 198, 7, 5, 526, 9, 5, 3214, 1155, 4, 91, 581, 33, 10, 380, 885, 625, 9, 1055, 6, 79, 802, 4, 50118, 38544, 5078, 329, 368, 56, 95, 4425, 66, 9, 5, 512, 6, 77, 79, 26, 6, 22, 41541, 512, 6, 13834, 72, 50118, 113, 42903, 6, 2446, 72, 50118, 113, 100, 437, 25575, 4, 370, 300, 10, 4045, 13495, 3422, 1917, 50118, 894, 851, 69, 5, 683, 81, 4, 1405, 909, 2549, 18699, 10, 1256, 6, 664, 12, 3690, 652, 4, 20, 614, 12, 8267, 3089, 11556, 314, 410, 7, 5, 13670, 6, 6254, 9646, 69, 42529, 4, 264, 21, 674, 6958, 6, 53, 5, 239, 19728, 10317, 10944, 69, 7, 59, 195, 108, 398, 845, 20, 251, 5856, 58, 182, 2579, 4, 50118, 38544, 56, 393, 341, 10, 36289, 4, 91, 1017, 460, 802, 9, 24, 25, 34633, 2577, 4, 20, 1114, 9, 519, 2099, 19, 10, 693, 54, 1017, 57, 19, 2213, 9, 604, 222, 45, 2868, 7, 123, 4, 50118, 1708, 42, 399, 75, 2045, 101, 10, 6097, 9337, 254, 4, 264, 2551, 350, 2382, 5579, 26949, 8309, 4, 125, 9, 768, 6, 79, 938, 75, 4, 91, 1467, 79, 56, 7, 28, 95, 25, 2972, 30451, 25, 5, 1079, 9, 106, 4, 3180, 5579, 1594, 37, 5844, 75, 57, 11, 5, 1692, 9, 402, 505, 37, 429, 33, 57, 55, 87, 2882, 7, 907, 99, 79, 21, 2183, 4, 50118, 113, 2847, 6, 99, 109, 47, 224, 116, 7348, 7, 120, 24, 15, 1917, 264, 20185, 10195, 21491, 6608, 4, 50118, 894, 21, 6889, 14, 79, 56, 70, 69, 9927, 6, 8, 14, 51, 1415, 1104, 4, 50118, 113, 6179, 64, 38, 11942, 1917, 91, 44060, 23, 69, 8, 39422, 196, 4, 2, 2, 45641, 1907, 35, 46718, 3611, 4, 653, 16, 1153, 1528, 59, 6045, 4, 6045, 3829, 2746, 13, 2099, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], attention_mask=[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], token_type_ids=None, label=2)\n",
            "11/30/2020 17:45:41 - INFO - utils_multiple_choice -   Saving features into cached file ./data/cached_dev_RobertaTokenizer_512_quail\n",
            "11/30/2020 17:45:43 - INFO - filelock -   Lock 140122281963648 released on ./data/cached_dev_RobertaTokenizer_512_quail.lock\n",
            "roberta-base--with_upsteam_reasoning_classification\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mngdodd\u001b[0m (use `wandb login --relogin` to force relogin)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.11\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mroberta-base--with_upsteam_reasoning_classification\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ngdodd/huggingface\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ngdodd/huggingface/runs/39k6tct2\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /content/wandb/run-20201130_174549-39k6tct2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n",
            "\n",
            "  2%|▏         | 25/1280 [02:29<2:05:27,  6.00s/it]\n",
            "                                                   {'loss': 1.2893585205078124, 'learning_rate': 9.609375000000001e-06, 'epoch': 0.0780274656679151}\n",
            "  6%|▌         | 75/1280 [07:29<2:00:03,  5.98s/it]\n",
            "  8%|▊         | 100/1280 [09:59<1:58:19,  6.02s/it]\n",
            " 10%|▉         | 125/1280 [12:29<1:55:23,  5.99s/it]\n",
            " 12%|█▏        | 150/1280 [14:59<1:52:45,  5.99s/it]\n",
            " 14%|█▎        | 175/1280 [17:29<1:50:00,  5.97s/it]{'loss': 0.880999755859375, 'learning_rate': 8.6328125e-06, 'epoch': 0.2730961298377029}\n",
            " 16%|█▌        | 200/1280 [19:59<1:48:17,  6.02s/it]\n",
            "{'loss': 0.8583984375, 'learning_rate': 8.242187500000001e-06, 'epoch': 0.351123595505618}\n",
            " 20%|█▉        | 250/1280 [24:58<1:42:42,  5.98s/it]{'loss': 0.872783203125, 'learning_rate': 8.046875e-06, 'epoch': 0.39013732833957554}\n",
            " 21%|██▏       | 275/1280 [27:28<1:40:08,  5.98s/it]{'loss': 0.84347412109375, 'learning_rate': 7.8515625e-06, 'epoch': 0.4291510611735331}\n",
            " 23%|██▎       | 300/1280 [29:58<1:38:08,  6.01s/it]{'loss': 0.78933349609375, 'learning_rate': 7.656250000000001e-06, 'epoch': 0.4681647940074906}\n",
            "                                                    {'loss': 0.76908203125, 'learning_rate': 7.460937500000001e-06, 'epoch': 0.5071785268414482}\n",
            " 27%|██▋       | 350/1280 [34:57<1:32:43,  5.98s/it]{'loss': 0.801021728515625, 'learning_rate': 7.265625e-06, 'epoch': 0.5461922596754057}\n",
            " 29%|██▉       | 375/1280 [37:27<1:30:07,  5.98s/it]\n",
            " 31%|███▏      | 400/1280 [39:57<1:28:08,  6.01s/it]{'loss': 0.7464501953125, 'learning_rate': 6.875e-06, 'epoch': 0.6242197253433208}\n",
            " 33%|███▎      | 425/1280 [42:27<1:25:23,  5.99s/it]{'loss': 0.744134521484375, 'learning_rate': 6.679687500000001e-06, 'epoch': 0.6632334581772784}\n",
            "                                                    \n",
            "                                                    \n",
            " 39%|███▉      | 500/1280 [49:56<1:18:06,  6.01s/it]\n",
            "{'loss': 0.671619873046875, 'learning_rate': 5.8984375e-06, 'epoch': 0.8192883895131086}\n",
            "                                                    \n",
            "                                                    {'loss': 0.680166015625, 'learning_rate': 5.5078125e-06, 'epoch': 0.8973158551810237}\n",
            "{'loss': 0.678704833984375, 'learning_rate': 5.3125e-06, 'epoch': 0.9363295880149812}\n",
            " 49%|████▉     | 625/1280 [1:02:32<1:05:31,  6.00s/it]\n",
            "                                                      \n",
            "{'loss': 0.64514892578125, 'learning_rate': 4.7265625000000005e-06, 'epoch': 1.0546192259675407}\n",
            " 55%|█████▍    | 700/1280 [1:10:06<58:10,  6.02s/it]\n",
            " 57%|█████▋    | 725/1280 [1:12:36<55:32,  6.00s/it]\n",
            " 59%|█████▊    | 750/1280 [1:15:06<52:53,  5.99s/it]\n",
            " 61%|██████    | 775/1280 [1:17:36<50:16,  5.97s/it]\n",
            " 62%|██████▎   | 800/1280 [1:20:06<48:05,  6.01s/it]{'loss': 0.64415771484375, 'learning_rate': 3.7500000000000005e-06, 'epoch': 1.2496878901373283}\n",
            "                                                    \n",
            " 66%|██████▋   | 850/1280 [1:25:06<42:55,  5.99s/it]{'loss': 0.62443359375, 'learning_rate': 3.3593750000000003e-06, 'epoch': 1.3277153558052435}\n",
            " 68%|██████▊   | 875/1280 [1:27:35<40:23,  5.98s/it]\n",
            "                                                    \n",
            "{'loss': 0.63035888671875, 'learning_rate': 2.7734375e-06, 'epoch': 1.4447565543071161}\n",
            "{'loss': 0.5781640625, 'learning_rate': 2.5781250000000004e-06, 'epoch': 1.4837702871410736}\n",
            " 76%|███████▌  | 975/1280 [1:37:35<30:25,  5.98s/it]\n",
            "{'loss': 0.61996337890625, 'learning_rate': 2.1875000000000002e-06, 'epoch': 1.5617977528089888}\n",
            "                                                     \n",
            " 82%|████████▏ | 1050/1280 [1:45:11<22:56,  5.98s/it]{'loss': 0.581943359375, 'learning_rate': 1.796875e-06, 'epoch': 1.6398252184769038}\n",
            " 84%|████████▍ | 1075/1280 [1:47:41<20:26,  5.98s/it]{'loss': 0.605205078125, 'learning_rate': 1.6015625000000002e-06, 'epoch': 1.6788389513108615}\n",
            " 86%|████████▌ | 1100/1280 [1:50:11<18:02,  6.01s/it]{'loss': 0.5685302734375, 'learning_rate': 1.40625e-06, 'epoch': 1.717852684144819}\n",
            " 88%|████████▊ | 1125/1280 [1:52:40<15:29,  6.00s/it]\n",
            " 90%|████████▉ | 1150/1280 [1:55:10<12:58,  5.99s/it]{'loss': 0.6000390625, 'learning_rate': 1.0156250000000001e-06, 'epoch': 1.7958801498127341}\n",
            "                                                     \n",
            "                                                     \n",
            " 96%|█████████▌| 1225/1280 [2:02:40<05:29,  6.00s/it]{'loss': 0.59916015625, 'learning_rate': 4.296875e-07, 'epoch': 1.9129213483146068}\n",
            "                                                     {'loss': 0.59828125, 'learning_rate': 2.3437500000000003e-07, 'epoch': 1.9519350811485643}\n",
            "                                                     {'loss': 0.60330078125, 'learning_rate': 3.90625e-08, 'epoch': 1.9909488139825218}\n",
            "                                                     \n",
            "100%|██████████| 1280/1280 [2:08:10<00:00,  6.01s/it]\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/trainer.py:1174: FutureWarning: This method is deprecated, use `Trainer.is_world_process_zero()` instead.\n",
            "  warnings.warn(\"This method is deprecated, use `Trainer.is_world_process_zero()` instead.\", FutureWarning)\n",
            "11/30/2020 19:54:03 - INFO - __main__ -   *** Evaluate ***\n",
            "100%|█████████▉| 1081/1082 [01:24<00:00, 12.80it/s]11/30/2020 19:55:27 - INFO - __main__ -   \n",
            "\n",
            "\n",
            "\n",
            "***** Quail_Dev_Eval Results *****\n",
            "11/30/2020 19:55:27 - INFO - __main__ -     eval_loss = 0.8461897969245911\n",
            "11/30/2020 19:55:27 - INFO - __main__ -     eval_acc = 0.6848428835489834\n",
            "11/30/2020 19:55:28 - INFO - utils_multiple_choice -   \n",
            "***** Reasoning Type Accuracies *****\n",
            "11/30/2020 19:55:28 - INFO - utils_multiple_choice -     Event_duration = 66.94560669456067\n",
            "11/30/2020 19:55:28 - INFO - utils_multiple_choice -     Entity_properties = 59.583333333333336\n",
            "11/30/2020 19:55:28 - INFO - utils_multiple_choice -     Factual = 73.33333333333333\n",
            "11/30/2020 19:55:28 - INFO - utils_multiple_choice -     Causality = 78.42323651452283\n",
            "11/30/2020 19:55:28 - INFO - utils_multiple_choice -     Character_identity = 79.25311203319502\n",
            "11/30/2020 19:55:28 - INFO - utils_multiple_choice -     Unanswerable = 57.5\n",
            "11/30/2020 19:55:28 - INFO - utils_multiple_choice -     Subsequent_state = 65.41666666666667\n",
            "11/30/2020 19:55:28 - INFO - utils_multiple_choice -     Temporal_order = 70.37037037037037\n",
            "11/30/2020 19:55:28 - INFO - utils_multiple_choice -     Belief_states = 65.41666666666667\n",
            "11/30/2020 19:55:28 - INFO - utils_multiple_choice -     Total = 68.48428835489834\n",
            "11/30/2020 19:55:28 - INFO - utils_multiple_choice -   \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "11/30/2020 19:55:28 - INFO - filelock -   Lock 140122247134848 acquired on ./data/cached_dev_RobertaTokenizer_512_quail.lock\n",
            "LOOKING AT ./data dev\n",
            "11/30/2020 19:55:28 - INFO - utils_multiple_choice -   Creating features from dataset file at ./data\n",
            "11/30/2020 19:55:28 - INFO - utils_multiple_choice -   Training examples: 3312\n",
            "\n",
            "convert examples to features: 0it [00:00, ?it/s]\u001b[A11/30/2020 19:55:28 - INFO - utils_multiple_choice -   Writing example 0 of 3312\n",
            "\n",
            "convert examples to features: 17it [00:00, 166.33it/s]\u001b[A\n",
            "convert examples to features: 34it [00:00, 166.47it/s]\u001b[A\n",
            "convert examples to features: 53it [00:00, 171.79it/s]\u001b[A\n",
            "convert examples to features: 72it [00:00, 175.74it/s]\u001b[A\n",
            "convert examples to features: 92it [00:00, 180.46it/s]\u001b[A\n",
            "convert examples to features: 109it [00:00, 175.26it/s]\u001b[A\n",
            "convert examples to features: 125it [00:00, 166.86it/s]\u001b[A\n",
            "convert examples to features: 142it [00:00, 165.92it/s]\u001b[A\n",
            "convert examples to features: 161it [00:00, 171.10it/s]\u001b[A\n",
            "convert examples to features: 178it [00:01, 166.64it/s]\u001b[A\n",
            "convert examples to features: 195it [00:01, 159.56it/s]\u001b[A\n",
            "convert examples to features: 211it [00:01, 153.68it/s]\u001b[A\n",
            "convert examples to features: 227it [00:01, 154.03it/s]\u001b[A\n",
            "convert examples to features: 245it [00:01, 158.91it/s]\u001b[A\n",
            "convert examples to features: 263it [00:01, 163.94it/s]\u001b[A\n",
            "convert examples to features: 280it [00:01, 156.05it/s]\u001b[A\n",
            "convert examples to features: 296it [00:01, 151.83it/s]\u001b[A\n",
            "convert examples to features: 315it [00:01, 161.21it/s]\u001b[A\n",
            "convert examples to features: 332it [00:02, 163.09it/s]\u001b[A\n",
            "convert examples to features: 349it [00:02, 159.10it/s]\u001b[A\n",
            "convert examples to features: 367it [00:02, 162.64it/s]\u001b[A\n",
            "convert examples to features: 384it [00:02, 162.81it/s]\u001b[A\n",
            "convert examples to features: 401it [00:02, 153.94it/s]\u001b[A\n",
            "convert examples to features: 418it [00:02, 158.17it/s]\u001b[A\n",
            "convert examples to features: 434it [00:02, 155.41it/s]\u001b[A\n",
            "convert examples to features: 450it [00:02, 149.40it/s]\u001b[A\n",
            "convert examples to features: 470it [00:02, 159.34it/s]\u001b[A\n",
            "convert examples to features: 488it [00:02, 162.40it/s]\u001b[A\n",
            "convert examples to features: 505it [00:03, 153.32it/s]\u001b[A\n",
            "convert examples to features: 524it [00:03, 160.96it/s]\u001b[A\n",
            "convert examples to features: 541it [00:03, 152.54it/s]\u001b[A\n",
            "convert examples to features: 559it [00:03, 156.36it/s]\u001b[A\n",
            "convert examples to features: 575it [00:03, 152.39it/s]\u001b[A\n",
            "convert examples to features: 591it [00:03, 149.81it/s]\u001b[A\n",
            "convert examples to features: 607it [00:03, 148.60it/s]\u001b[A\n",
            "convert examples to features: 626it [00:03, 158.20it/s]\u001b[A\n",
            "convert examples to features: 643it [00:04, 152.65it/s]\u001b[A\n",
            "convert examples to features: 660it [00:04, 156.11it/s]\u001b[A\n",
            "convert examples to features: 676it [00:04, 154.43it/s]\u001b[A\n",
            "convert examples to features: 692it [00:04, 148.69it/s]\u001b[A\n",
            "convert examples to features: 707it [00:04, 148.50it/s]\u001b[A\n",
            "convert examples to features: 725it [00:04, 154.11it/s]\u001b[A\n",
            "convert examples to features: 741it [00:04, 152.30it/s]\u001b[A\n",
            "convert examples to features: 758it [00:04, 155.91it/s]\u001b[A\n",
            "convert examples to features: 774it [00:04, 149.27it/s]\u001b[A\n",
            "convert examples to features: 791it [00:04, 153.39it/s]\u001b[A\n",
            "convert examples to features: 808it [00:05, 154.73it/s]\u001b[A\n",
            "convert examples to features: 824it [00:05, 155.03it/s]\u001b[A\n",
            "convert examples to features: 840it [00:05, 148.59it/s]\u001b[A\n",
            "convert examples to features: 857it [00:05, 154.30it/s]\u001b[A\n",
            "convert examples to features: 875it [00:05, 160.14it/s]\u001b[A\n",
            "convert examples to features: 892it [00:05, 161.39it/s]\u001b[A\n",
            "convert examples to features: 909it [00:05, 161.20it/s]\u001b[A\n",
            "convert examples to features: 927it [00:05, 165.09it/s]\u001b[A\n",
            "convert examples to features: 944it [00:05, 166.07it/s]\u001b[A\n",
            "convert examples to features: 961it [00:06, 162.38it/s]\u001b[A\n",
            "convert examples to features: 978it [00:06, 163.27it/s]\u001b[A\n",
            "convert examples to features: 995it [00:06, 160.74it/s]\u001b[A11/30/2020 19:55:34 - INFO - utils_multiple_choice -   Writing example 1000 of 3312\n",
            "\n",
            "convert examples to features: 1012it [00:06, 156.33it/s]\u001b[A\n",
            "convert examples to features: 1028it [00:06, 155.78it/s]\u001b[A\n",
            "convert examples to features: 1044it [00:06, 152.49it/s]\u001b[A\n",
            "convert examples to features: 1063it [00:06, 159.40it/s]\u001b[A\n",
            "convert examples to features: 1080it [00:06, 159.93it/s]\u001b[A\n",
            "convert examples to features: 1097it [00:06, 156.33it/s]\u001b[A\n",
            "convert examples to features: 1115it [00:07, 161.77it/s]\u001b[A\n",
            "convert examples to features: 1137it [00:07, 174.54it/s]\u001b[A\n",
            "convert examples to features: 1155it [00:07, 167.47it/s]\u001b[A\n",
            "convert examples to features: 1175it [00:07, 173.95it/s]\u001b[A\n",
            "convert examples to features: 1193it [00:07, 166.66it/s]\u001b[A\n",
            "convert examples to features: 1212it [00:07, 172.82it/s]\u001b[A\n",
            "convert examples to features: 1230it [00:07, 166.07it/s]\u001b[A\n",
            "convert examples to features: 1247it [00:07, 163.37it/s]\u001b[A\n",
            "convert examples to features: 1264it [00:07, 153.41it/s]\u001b[A\n",
            "convert examples to features: 1281it [00:08, 157.30it/s]\u001b[A\n",
            "convert examples to features: 1300it [00:08, 162.92it/s]\u001b[A\n",
            "convert examples to features: 1318it [00:08, 166.88it/s]\u001b[A\n",
            "convert examples to features: 1338it [00:08, 175.05it/s]\u001b[A\n",
            "convert examples to features: 1356it [00:08, 167.90it/s]\u001b[A\n",
            "convert examples to features: 1375it [00:08, 172.43it/s]\u001b[A\n",
            "convert examples to features: 1393it [00:08, 169.51it/s]\u001b[A\n",
            "convert examples to features: 1411it [00:08, 162.50it/s]\u001b[A\n",
            "convert examples to features: 1430it [00:08, 167.40it/s]\u001b[A\n",
            "convert examples to features: 1447it [00:08, 163.98it/s]\u001b[A\n",
            "convert examples to features: 1464it [00:09, 165.30it/s]\u001b[A\n",
            "convert examples to features: 1481it [00:09, 166.19it/s]\u001b[A\n",
            "convert examples to features: 1498it [00:09, 157.34it/s]\u001b[A\n",
            "convert examples to features: 1515it [00:09, 158.04it/s]\u001b[A\n",
            "convert examples to features: 1532it [00:09, 159.89it/s]\u001b[A\n",
            "convert examples to features: 1551it [00:09, 167.17it/s]\u001b[A\n",
            "convert examples to features: 1568it [00:09, 162.02it/s]\u001b[A\n",
            "convert examples to features: 1588it [00:09, 168.82it/s]\u001b[A\n",
            "convert examples to features: 1606it [00:09, 159.17it/s]\u001b[A\n",
            "convert examples to features: 1625it [00:10, 164.04it/s]\u001b[A\n",
            "convert examples to features: 1642it [00:10, 164.66it/s]\u001b[A\n",
            "convert examples to features: 1659it [00:10, 165.01it/s]\u001b[A\n",
            "convert examples to features: 1676it [00:10, 161.76it/s]\u001b[A\n",
            "convert examples to features: 1695it [00:10, 168.28it/s]\u001b[A\n",
            "convert examples to features: 1712it [00:10, 166.82it/s]\u001b[A\n",
            "convert examples to features: 1731it [00:10, 173.12it/s]\u001b[A\n",
            "convert examples to features: 1749it [00:10, 169.80it/s]\u001b[A\n",
            "convert examples to features: 1767it [00:10, 169.94it/s]\u001b[A\n",
            "convert examples to features: 1787it [00:11, 176.35it/s]\u001b[A\n",
            "convert examples to features: 1805it [00:11, 169.00it/s]\u001b[A\n",
            "convert examples to features: 1825it [00:11, 173.46it/s]\u001b[A\n",
            "convert examples to features: 1845it [00:11, 177.48it/s]\u001b[A\n",
            "convert examples to features: 1863it [00:11, 168.59it/s]\u001b[A\n",
            "convert examples to features: 1882it [00:11, 171.87it/s]\u001b[A\n",
            "convert examples to features: 1900it [00:11, 163.79it/s]\u001b[A\n",
            "convert examples to features: 1917it [00:11, 156.33it/s]\u001b[A\n",
            "convert examples to features: 1933it [00:11, 151.77it/s]\u001b[A\n",
            "convert examples to features: 1949it [00:12, 149.82it/s]\u001b[A\n",
            "convert examples to features: 1966it [00:12, 154.15it/s]\u001b[A\n",
            "convert examples to features: 1983it [00:12, 158.39it/s]\u001b[A\n",
            "convert examples to features: 1999it [00:12, 158.34it/s]\u001b[A11/30/2020 19:55:40 - INFO - utils_multiple_choice -   Writing example 2000 of 3312\n",
            "\n",
            "convert examples to features: 2015it [00:12, 151.53it/s]\u001b[A\n",
            "convert examples to features: 2033it [00:12, 156.44it/s]\u001b[A\n",
            "convert examples to features: 2050it [00:12, 160.17it/s]\u001b[A\n",
            "convert examples to features: 2067it [00:12, 160.78it/s]\u001b[A\n",
            "convert examples to features: 2084it [00:12, 155.70it/s]\u001b[A\n",
            "convert examples to features: 2100it [00:12, 151.86it/s]\u001b[A\n",
            "convert examples to features: 2116it [00:13, 148.94it/s]\u001b[A\n",
            "convert examples to features: 2132it [00:13, 149.95it/s]\u001b[A\n",
            "convert examples to features: 2149it [00:13, 153.95it/s]\u001b[A\n",
            "convert examples to features: 2165it [00:13, 149.11it/s]\u001b[A\n",
            "convert examples to features: 2181it [00:13, 151.58it/s]\u001b[A\n",
            "convert examples to features: 2199it [00:13, 158.73it/s]\u001b[A\n",
            "convert examples to features: 2216it [00:13, 160.54it/s]\u001b[A\n",
            "convert examples to features: 2233it [00:13, 152.90it/s]\u001b[A\n",
            "convert examples to features: 2249it [00:13, 153.44it/s]\u001b[A\n",
            "convert examples to features: 2265it [00:14, 150.98it/s]\u001b[A\n",
            "convert examples to features: 2281it [00:14, 145.56it/s]\u001b[A\n",
            "convert examples to features: 2297it [00:14, 147.55it/s]\u001b[A\n",
            "convert examples to features: 2312it [00:14, 147.13it/s]\u001b[A\n",
            "convert examples to features: 2329it [00:14, 152.34it/s]\u001b[A\n",
            "convert examples to features: 2350it [00:14, 162.33it/s]\u001b[A\n",
            "convert examples to features: 2367it [00:14, 158.25it/s]\u001b[A\n",
            "convert examples to features: 2387it [00:14, 166.27it/s]\u001b[A\n",
            "convert examples to features: 2408it [00:14, 175.77it/s]\u001b[A\n",
            "convert examples to features: 2426it [00:15, 175.47it/s]\u001b[A\n",
            "convert examples to features: 2444it [00:15, 168.07it/s]\u001b[A\n",
            "convert examples to features: 2462it [00:15, 165.12it/s]\u001b[A\n",
            "100%|██████████| 1082/1082 [01:40<00:00, 12.80it/s]\n",
            "convert examples to features: 2497it [00:15, 165.80it/s]\u001b[A\n",
            "convert examples to features: 2516it [00:15, 169.05it/s]\u001b[A\n",
            "convert examples to features: 2538it [00:15, 176.69it/s]\u001b[A\n",
            "convert examples to features: 2556it [00:15, 173.83it/s]\u001b[A\n",
            "convert examples to features: 2574it [00:15, 167.14it/s]\u001b[A\n",
            "convert examples to features: 2591it [00:16, 161.62it/s]\u001b[A\n",
            "convert examples to features: 2608it [00:16, 162.03it/s]\u001b[A\n",
            "convert examples to features: 2625it [00:16, 162.44it/s]\u001b[A\n",
            "convert examples to features: 2643it [00:16, 166.12it/s]\u001b[A\n",
            "convert examples to features: 2661it [00:16, 169.35it/s]\u001b[A\n",
            "convert examples to features: 2678it [00:16, 165.83it/s]\u001b[A\n",
            "convert examples to features: 2695it [00:16, 157.92it/s]\u001b[A\n",
            "convert examples to features: 2711it [00:16, 156.92it/s]\u001b[A\n",
            "convert examples to features: 2727it [00:16, 155.00it/s]\u001b[A\n",
            "convert examples to features: 2744it [00:18, 36.60it/s] \u001b[A\n",
            "convert examples to features: 2762it [00:18, 48.07it/s]\u001b[A\n",
            "convert examples to features: 2778it [00:18, 60.31it/s]\u001b[A\n",
            "convert examples to features: 2794it [00:18, 73.62it/s]\u001b[A\n",
            "convert examples to features: 2812it [00:18, 88.61it/s]\u001b[A\n",
            "convert examples to features: 2829it [00:18, 102.60it/s]\u001b[A\n",
            "convert examples to features: 2846it [00:18, 115.19it/s]\u001b[A\n",
            "convert examples to features: 2862it [00:18, 125.75it/s]\u001b[A\n",
            "convert examples to features: 2878it [00:19, 133.36it/s]\u001b[A\n",
            "convert examples to features: 2894it [00:19, 137.52it/s]\u001b[A\n",
            "convert examples to features: 2910it [00:19, 139.10it/s]\u001b[A\n",
            "convert examples to features: 2926it [00:19, 140.64it/s]\u001b[A\n",
            "convert examples to features: 2941it [00:19, 142.81it/s]\u001b[A\n",
            "convert examples to features: 2956it [00:19, 144.72it/s]\u001b[A\n",
            "convert examples to features: 2971it [00:19, 144.59it/s]\u001b[A\n",
            "convert examples to features: 2987it [00:19, 147.24it/s]\u001b[A11/30/2020 19:55:47 - INFO - utils_multiple_choice -   Writing example 3000 of 3312\n",
            "\n",
            "convert examples to features: 3002it [00:19, 147.17it/s]\u001b[A\n",
            "convert examples to features: 3019it [00:19, 148.59it/s]\u001b[A\n",
            "convert examples to features: 3036it [00:20, 153.83it/s]\u001b[A\n",
            "convert examples to features: 3052it [00:20, 149.11it/s]\u001b[A\n",
            "convert examples to features: 3068it [00:20, 151.03it/s]\u001b[A\n",
            "convert examples to features: 3085it [00:20, 155.19it/s]\u001b[A\n",
            "convert examples to features: 3104it [00:20, 162.78it/s]\u001b[A\n",
            "convert examples to features: 3121it [00:20, 158.12it/s]\u001b[A\n",
            "convert examples to features: 3139it [00:20, 164.00it/s]\u001b[A\n",
            "convert examples to features: 3157it [00:20, 166.25it/s]\u001b[A\n",
            "convert examples to features: 3176it [00:20, 170.42it/s]\u001b[A\n",
            "convert examples to features: 3194it [00:21, 159.92it/s]\u001b[A\n",
            "convert examples to features: 3211it [00:21, 160.98it/s]\u001b[A\n",
            "convert examples to features: 3228it [00:21, 160.06it/s]\u001b[A\n",
            "convert examples to features: 3245it [00:21, 158.82it/s]\u001b[A\n",
            "convert examples to features: 3263it [00:21, 162.00it/s]\u001b[A\n",
            "convert examples to features: 3280it [00:21, 163.86it/s]\u001b[A\n",
            "convert examples to features: 3312it [00:21, 151.95it/s]\n",
            "11/30/2020 19:55:49 - INFO - utils_multiple_choice -   *** Example ***\n",
            "11/30/2020 19:55:49 - INFO - utils_multiple_choice -   feature: InputFeatures(example_id='u156_15', input_ids=[[0, 791, 5471, 1174, 100, 206, 42, 2263, 127, 1354, 4, 50118, 2387, 8733, 2138, 34, 460, 56, 41, 31232, 13, 5425, 10029, 578, 37790, 5556, 6, 326, 19112, 38215, 6, 380, 7, 37994, 784, 39700, 4, 370, 766, 24, 8, 37, 17, 27, 29, 1153, 7521, 24, 4, 96, 754, 6, 37, 202, 4618, 23, 41, 19265, 3477, 5159, 61, 16, 184, 7, 10, 739, 3143, 9, 167, 15785, 15916, 6, 8, 127, 793, 1441, 735, 36330, 4, 50118, 10787, 107, 536, 6, 38, 439, 7, 825, 127, 985, 147, 37, 202, 3033, 6, 160, 8, 15, 6, 25, 24, 21, 2789, 7, 39, 633, 87, 39, 92, 3537, 4, 38, 1102, 7, 213, 88, 39, 929, 8, 5324, 10, 1637, 25114, 8319, 2233, 59, 237, 50, 292, 4877, 3925, 4, 39273, 219, 25, 38, 524, 6, 38, 56, 7, 490, 24, 4, 50118, 243, 5558, 5, 7722, 1931, 366, 44869, 9, 10, 739, 42175, 5718, 8, 909, 326, 19112, 5571, 4, 44218, 219, 25, 14, 21, 6, 24, 399, 17, 27, 90, 15304, 6, 50, 190, 2755, 162, 203, 6, 25, 38, 1467, 127, 2138, 429, 489, 402, 101, 14, 11, 39, 929, 4, 50118, 21674, 41, 1946, 423, 6, 37, 373, 7, 224, 20760, 8, 2528, 38, 185, 10, 356, 23, 5, 1637, 2233, 11, 39, 929, 4, 38, 174, 123, 14, 38, 416, 56, 6, 53, 38, 2738, 24, 62, 456, 7, 185, 277, 356, 6, 150, 37, 174, 162, 59, 2494, 39, 4716, 7722, 24, 4, 50118, 2387, 80, 76, 793, 1354, 21, 39789, 10691, 59, 5, 13654, 9, 5, 1256, 2233, 6, 98, 38, 969, 24, 7, 69, 4, 50118, 12583, 39485, 5021, 4, 83, 5021, 98, 1099, 24, 197, 33, 57, 2292, 22697, 4, 50118, 2515, 362, 65, 356, 23, 24, 6, 1224, 1104, 8, 23472, 46754, 1329, 4, 38, 17, 27, 548, 393, 450, 951, 98, 19419, 4, 50118, 10643, 768, 38, 222, 99, 38, 115, 7, 20759, 69, 4, 38, 2002, 14, 24, 21, 5, 380, 34558, 44, 48, 279, 809, 17, 46, 8, 14, 24, 888, 3033, 23, 69, 542, 20639, 97, 790, 4, 50118, 1708, 6, 1717, 5471, 4, 479, 479, 100, 4443, 38, 938, 17, 27, 90, 269, 203, 9, 10, 23303, 8, 2969, 4252, 6, 142, 81, 5, 220, 891, 107, 38, 20711, 69, 19, 10, 9755, 10771, 29499, 6, 10, 821, 22383, 326, 19112, 5571, 8, 44, 48, 34868, 2462, 219, 10802, 62, 5, 3124, 4, 17, 46, 2, 2, 45641, 1907, 35, 11373, 13428, 4, 1336, 251, 34, 5, 2138, 56, 39, 633, 116, 112, 76, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 791, 5471, 1174, 100, 206, 42, 2263, 127, 1354, 4, 50118, 2387, 8733, 2138, 34, 460, 56, 41, 31232, 13, 5425, 10029, 578, 37790, 5556, 6, 326, 19112, 38215, 6, 380, 7, 37994, 784, 39700, 4, 370, 766, 24, 8, 37, 17, 27, 29, 1153, 7521, 24, 4, 96, 754, 6, 37, 202, 4618, 23, 41, 19265, 3477, 5159, 61, 16, 184, 7, 10, 739, 3143, 9, 167, 15785, 15916, 6, 8, 127, 793, 1441, 735, 36330, 4, 50118, 10787, 107, 536, 6, 38, 439, 7, 825, 127, 985, 147, 37, 202, 3033, 6, 160, 8, 15, 6, 25, 24, 21, 2789, 7, 39, 633, 87, 39, 92, 3537, 4, 38, 1102, 7, 213, 88, 39, 929, 8, 5324, 10, 1637, 25114, 8319, 2233, 59, 237, 50, 292, 4877, 3925, 4, 39273, 219, 25, 38, 524, 6, 38, 56, 7, 490, 24, 4, 50118, 243, 5558, 5, 7722, 1931, 366, 44869, 9, 10, 739, 42175, 5718, 8, 909, 326, 19112, 5571, 4, 44218, 219, 25, 14, 21, 6, 24, 399, 17, 27, 90, 15304, 6, 50, 190, 2755, 162, 203, 6, 25, 38, 1467, 127, 2138, 429, 489, 402, 101, 14, 11, 39, 929, 4, 50118, 21674, 41, 1946, 423, 6, 37, 373, 7, 224, 20760, 8, 2528, 38, 185, 10, 356, 23, 5, 1637, 2233, 11, 39, 929, 4, 38, 174, 123, 14, 38, 416, 56, 6, 53, 38, 2738, 24, 62, 456, 7, 185, 277, 356, 6, 150, 37, 174, 162, 59, 2494, 39, 4716, 7722, 24, 4, 50118, 2387, 80, 76, 793, 1354, 21, 39789, 10691, 59, 5, 13654, 9, 5, 1256, 2233, 6, 98, 38, 969, 24, 7, 69, 4, 50118, 12583, 39485, 5021, 4, 83, 5021, 98, 1099, 24, 197, 33, 57, 2292, 22697, 4, 50118, 2515, 362, 65, 356, 23, 24, 6, 1224, 1104, 8, 23472, 46754, 1329, 4, 38, 17, 27, 548, 393, 450, 951, 98, 19419, 4, 50118, 10643, 768, 38, 222, 99, 38, 115, 7, 20759, 69, 4, 38, 2002, 14, 24, 21, 5, 380, 34558, 44, 48, 279, 809, 17, 46, 8, 14, 24, 888, 3033, 23, 69, 542, 20639, 97, 790, 4, 50118, 1708, 6, 1717, 5471, 4, 479, 479, 100, 4443, 38, 938, 17, 27, 90, 269, 203, 9, 10, 23303, 8, 2969, 4252, 6, 142, 81, 5, 220, 891, 107, 38, 20711, 69, 19, 10, 9755, 10771, 29499, 6, 10, 821, 22383, 326, 19112, 5571, 8, 44, 48, 34868, 2462, 219, 10802, 62, 5, 3124, 4, 17, 46, 2, 2, 45641, 1907, 35, 11373, 13428, 4, 1336, 251, 34, 5, 2138, 56, 39, 633, 116, 45, 615, 335, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 791, 5471, 1174, 100, 206, 42, 2263, 127, 1354, 4, 50118, 2387, 8733, 2138, 34, 460, 56, 41, 31232, 13, 5425, 10029, 578, 37790, 5556, 6, 326, 19112, 38215, 6, 380, 7, 37994, 784, 39700, 4, 370, 766, 24, 8, 37, 17, 27, 29, 1153, 7521, 24, 4, 96, 754, 6, 37, 202, 4618, 23, 41, 19265, 3477, 5159, 61, 16, 184, 7, 10, 739, 3143, 9, 167, 15785, 15916, 6, 8, 127, 793, 1441, 735, 36330, 4, 50118, 10787, 107, 536, 6, 38, 439, 7, 825, 127, 985, 147, 37, 202, 3033, 6, 160, 8, 15, 6, 25, 24, 21, 2789, 7, 39, 633, 87, 39, 92, 3537, 4, 38, 1102, 7, 213, 88, 39, 929, 8, 5324, 10, 1637, 25114, 8319, 2233, 59, 237, 50, 292, 4877, 3925, 4, 39273, 219, 25, 38, 524, 6, 38, 56, 7, 490, 24, 4, 50118, 243, 5558, 5, 7722, 1931, 366, 44869, 9, 10, 739, 42175, 5718, 8, 909, 326, 19112, 5571, 4, 44218, 219, 25, 14, 21, 6, 24, 399, 17, 27, 90, 15304, 6, 50, 190, 2755, 162, 203, 6, 25, 38, 1467, 127, 2138, 429, 489, 402, 101, 14, 11, 39, 929, 4, 50118, 21674, 41, 1946, 423, 6, 37, 373, 7, 224, 20760, 8, 2528, 38, 185, 10, 356, 23, 5, 1637, 2233, 11, 39, 929, 4, 38, 174, 123, 14, 38, 416, 56, 6, 53, 38, 2738, 24, 62, 456, 7, 185, 277, 356, 6, 150, 37, 174, 162, 59, 2494, 39, 4716, 7722, 24, 4, 50118, 2387, 80, 76, 793, 1354, 21, 39789, 10691, 59, 5, 13654, 9, 5, 1256, 2233, 6, 98, 38, 969, 24, 7, 69, 4, 50118, 12583, 39485, 5021, 4, 83, 5021, 98, 1099, 24, 197, 33, 57, 2292, 22697, 4, 50118, 2515, 362, 65, 356, 23, 24, 6, 1224, 1104, 8, 23472, 46754, 1329, 4, 38, 17, 27, 548, 393, 450, 951, 98, 19419, 4, 50118, 10643, 768, 38, 222, 99, 38, 115, 7, 20759, 69, 4, 38, 2002, 14, 24, 21, 5, 380, 34558, 44, 48, 279, 809, 17, 46, 8, 14, 24, 888, 3033, 23, 69, 542, 20639, 97, 790, 4, 50118, 1708, 6, 1717, 5471, 4, 479, 479, 100, 4443, 38, 938, 17, 27, 90, 269, 203, 9, 10, 23303, 8, 2969, 4252, 6, 142, 81, 5, 220, 891, 107, 38, 20711, 69, 19, 10, 9755, 10771, 29499, 6, 10, 821, 22383, 326, 19112, 5571, 8, 44, 48, 34868, 2462, 219, 10802, 62, 5, 3124, 4, 17, 46, 2, 2, 45641, 1907, 35, 11373, 13428, 4, 1336, 251, 34, 5, 2138, 56, 39, 633, 116, 112, 353, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 791, 5471, 1174, 100, 206, 42, 2263, 127, 1354, 4, 50118, 2387, 8733, 2138, 34, 460, 56, 41, 31232, 13, 5425, 10029, 578, 37790, 5556, 6, 326, 19112, 38215, 6, 380, 7, 37994, 784, 39700, 4, 370, 766, 24, 8, 37, 17, 27, 29, 1153, 7521, 24, 4, 96, 754, 6, 37, 202, 4618, 23, 41, 19265, 3477, 5159, 61, 16, 184, 7, 10, 739, 3143, 9, 167, 15785, 15916, 6, 8, 127, 793, 1441, 735, 36330, 4, 50118, 10787, 107, 536, 6, 38, 439, 7, 825, 127, 985, 147, 37, 202, 3033, 6, 160, 8, 15, 6, 25, 24, 21, 2789, 7, 39, 633, 87, 39, 92, 3537, 4, 38, 1102, 7, 213, 88, 39, 929, 8, 5324, 10, 1637, 25114, 8319, 2233, 59, 237, 50, 292, 4877, 3925, 4, 39273, 219, 25, 38, 524, 6, 38, 56, 7, 490, 24, 4, 50118, 243, 5558, 5, 7722, 1931, 366, 44869, 9, 10, 739, 42175, 5718, 8, 909, 326, 19112, 5571, 4, 44218, 219, 25, 14, 21, 6, 24, 399, 17, 27, 90, 15304, 6, 50, 190, 2755, 162, 203, 6, 25, 38, 1467, 127, 2138, 429, 489, 402, 101, 14, 11, 39, 929, 4, 50118, 21674, 41, 1946, 423, 6, 37, 373, 7, 224, 20760, 8, 2528, 38, 185, 10, 356, 23, 5, 1637, 2233, 11, 39, 929, 4, 38, 174, 123, 14, 38, 416, 56, 6, 53, 38, 2738, 24, 62, 456, 7, 185, 277, 356, 6, 150, 37, 174, 162, 59, 2494, 39, 4716, 7722, 24, 4, 50118, 2387, 80, 76, 793, 1354, 21, 39789, 10691, 59, 5, 13654, 9, 5, 1256, 2233, 6, 98, 38, 969, 24, 7, 69, 4, 50118, 12583, 39485, 5021, 4, 83, 5021, 98, 1099, 24, 197, 33, 57, 2292, 22697, 4, 50118, 2515, 362, 65, 356, 23, 24, 6, 1224, 1104, 8, 23472, 46754, 1329, 4, 38, 17, 27, 548, 393, 450, 951, 98, 19419, 4, 50118, 10643, 768, 38, 222, 99, 38, 115, 7, 20759, 69, 4, 38, 2002, 14, 24, 21, 5, 380, 34558, 44, 48, 279, 809, 17, 46, 8, 14, 24, 888, 3033, 23, 69, 542, 20639, 97, 790, 4, 50118, 1708, 6, 1717, 5471, 4, 479, 479, 100, 4443, 38, 938, 17, 27, 90, 269, 203, 9, 10, 23303, 8, 2969, 4252, 6, 142, 81, 5, 220, 891, 107, 38, 20711, 69, 19, 10, 9755, 10771, 29499, 6, 10, 821, 22383, 326, 19112, 5571, 8, 44, 48, 34868, 2462, 219, 10802, 62, 5, 3124, 4, 17, 46, 2, 2, 45641, 1907, 35, 11373, 13428, 4, 1336, 251, 34, 5, 2138, 56, 39, 633, 116, 195, 107, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], attention_mask=[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], token_type_ids=None, label=1)\n",
            "11/30/2020 19:55:49 - INFO - utils_multiple_choice -   *** Example ***\n",
            "11/30/2020 19:55:49 - INFO - utils_multiple_choice -   feature: InputFeatures(example_id='u141_15', input_ids=[[0, 100, 33, 57, 8, 202, 16, 11, 42, 1068, 11, 127, 284, 301, 4, 96, 1014, 6, 38, 1064, 11166, 4812, 8, 24, 362, 162, 209, 195, 107, 7, 671, 7, 2340, 301, 4, 96, 70, 209, 292, 107, 6, 38, 2220, 75, 56, 143, 23019, 3569, 50, 7654, 244, 31, 127, 1623, 4, 616, 38, 21, 11, 36021, 2400, 6, 37, 3776, 39, 301, 7, 5, 31848, 6, 11743, 8141, 66, 418, 13, 39, 36365, 101, 5651, 4, 38, 56, 7, 946, 80, 1315, 7, 582, 127, 1131, 4033, 187, 127, 474, 714, 399, 75, 1719, 5, 1042, 9, 127, 1416, 4, 38, 56, 7, 185, 80, 12, 1946, 6383, 227, 127, 1364, 298, 22833, 36, 33034, 6, 127, 320, 3504, 851, 162, 5537, 7, 304, 10, 28391, 5101, 3267, 11, 84, 3299, 18, 558, 13, 14, 43, 8, 127, 44, 48, 417, 4352, 97, 457, 17, 46, 7311, 59, 519, 7, 5555, 162, 7, 8, 31, 173, 25, 39, 512, 21, 341, 350, 747, 4, 286, 167, 6, 1207, 11, 5, 382, 6, 38, 619, 38, 240, 7, 3922, 103, 1254, 4, 96, 798, 6, 52, 218, 75, 2333, 33, 10, 2660, 284, 827, 1316, 6, 98, 38, 1705, 75, 304, 39, 418, 131, 38, 56, 7, 146, 109, 19, 99, 38, 2208, 4, 38, 553, 123, 13, 418, 6, 61, 38, 460, 18913, 31, 123, 3357, 24, 4595, 6, 129, 2330, 11, 70, 209, 107, 4, 91, 851, 162, 10, 410, 6797, 683, 129, 7, 2851, 32388, 162, 13, 1996, 5, 220, 183, 4, 91, 3179, 7, 15658, 162, 10, 38460, 6797, 13, 130, 360, 600, 37, 1467, 157, 615, 14, 114, 38, 399, 75, 120, 5, 6150, 38, 956, 6, 38, 115, 1323, 66, 11, 143, 317, 8, 143, 86, 4, 407, 122, 6, 38, 218, 75, 2416, 123, 5988, 8, 619, 182, 27810, 4, 318, 47, 1394, 162, 59, 141, 24, 2653, 7, 697, 101, 14, 6, 38, 581, 1137, 47, 14, 24, 18, 7360, 4, 1876, 82, 619, 26913, 77, 51, 32, 25177, 15, 4, 38, 129, 6675, 77, 38, 1166, 49, 1652, 4, 252, 218, 75, 216, 99, 26760, 16, 8, 99, 24, 839, 7, 33, 7, 697, 19, 10, 40048, 54, 189, 905, 47, 159, 143, 2289, 4, 2, 2, 45641, 1907, 35, 35177, 3599, 4, 3394, 34, 57, 11166, 4812, 116, 20, 920, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 100, 33, 57, 8, 202, 16, 11, 42, 1068, 11, 127, 284, 301, 4, 96, 1014, 6, 38, 1064, 11166, 4812, 8, 24, 362, 162, 209, 195, 107, 7, 671, 7, 2340, 301, 4, 96, 70, 209, 292, 107, 6, 38, 2220, 75, 56, 143, 23019, 3569, 50, 7654, 244, 31, 127, 1623, 4, 616, 38, 21, 11, 36021, 2400, 6, 37, 3776, 39, 301, 7, 5, 31848, 6, 11743, 8141, 66, 418, 13, 39, 36365, 101, 5651, 4, 38, 56, 7, 946, 80, 1315, 7, 582, 127, 1131, 4033, 187, 127, 474, 714, 399, 75, 1719, 5, 1042, 9, 127, 1416, 4, 38, 56, 7, 185, 80, 12, 1946, 6383, 227, 127, 1364, 298, 22833, 36, 33034, 6, 127, 320, 3504, 851, 162, 5537, 7, 304, 10, 28391, 5101, 3267, 11, 84, 3299, 18, 558, 13, 14, 43, 8, 127, 44, 48, 417, 4352, 97, 457, 17, 46, 7311, 59, 519, 7, 5555, 162, 7, 8, 31, 173, 25, 39, 512, 21, 341, 350, 747, 4, 286, 167, 6, 1207, 11, 5, 382, 6, 38, 619, 38, 240, 7, 3922, 103, 1254, 4, 96, 798, 6, 52, 218, 75, 2333, 33, 10, 2660, 284, 827, 1316, 6, 98, 38, 1705, 75, 304, 39, 418, 131, 38, 56, 7, 146, 109, 19, 99, 38, 2208, 4, 38, 553, 123, 13, 418, 6, 61, 38, 460, 18913, 31, 123, 3357, 24, 4595, 6, 129, 2330, 11, 70, 209, 107, 4, 91, 851, 162, 10, 410, 6797, 683, 129, 7, 2851, 32388, 162, 13, 1996, 5, 220, 183, 4, 91, 3179, 7, 15658, 162, 10, 38460, 6797, 13, 130, 360, 600, 37, 1467, 157, 615, 14, 114, 38, 399, 75, 120, 5, 6150, 38, 956, 6, 38, 115, 1323, 66, 11, 143, 317, 8, 143, 86, 4, 407, 122, 6, 38, 218, 75, 2416, 123, 5988, 8, 619, 182, 27810, 4, 318, 47, 1394, 162, 59, 141, 24, 2653, 7, 697, 101, 14, 6, 38, 581, 1137, 47, 14, 24, 18, 7360, 4, 1876, 82, 619, 26913, 77, 51, 32, 25177, 15, 4, 38, 129, 6675, 77, 38, 1166, 49, 1652, 4, 252, 218, 75, 216, 99, 26760, 16, 8, 99, 24, 839, 7, 33, 7, 697, 19, 10, 40048, 54, 189, 905, 47, 159, 143, 2289, 4, 2, 2, 45641, 1907, 35, 35177, 3599, 4, 3394, 34, 57, 11166, 4812, 116, 20, 1141, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 100, 33, 57, 8, 202, 16, 11, 42, 1068, 11, 127, 284, 301, 4, 96, 1014, 6, 38, 1064, 11166, 4812, 8, 24, 362, 162, 209, 195, 107, 7, 671, 7, 2340, 301, 4, 96, 70, 209, 292, 107, 6, 38, 2220, 75, 56, 143, 23019, 3569, 50, 7654, 244, 31, 127, 1623, 4, 616, 38, 21, 11, 36021, 2400, 6, 37, 3776, 39, 301, 7, 5, 31848, 6, 11743, 8141, 66, 418, 13, 39, 36365, 101, 5651, 4, 38, 56, 7, 946, 80, 1315, 7, 582, 127, 1131, 4033, 187, 127, 474, 714, 399, 75, 1719, 5, 1042, 9, 127, 1416, 4, 38, 56, 7, 185, 80, 12, 1946, 6383, 227, 127, 1364, 298, 22833, 36, 33034, 6, 127, 320, 3504, 851, 162, 5537, 7, 304, 10, 28391, 5101, 3267, 11, 84, 3299, 18, 558, 13, 14, 43, 8, 127, 44, 48, 417, 4352, 97, 457, 17, 46, 7311, 59, 519, 7, 5555, 162, 7, 8, 31, 173, 25, 39, 512, 21, 341, 350, 747, 4, 286, 167, 6, 1207, 11, 5, 382, 6, 38, 619, 38, 240, 7, 3922, 103, 1254, 4, 96, 798, 6, 52, 218, 75, 2333, 33, 10, 2660, 284, 827, 1316, 6, 98, 38, 1705, 75, 304, 39, 418, 131, 38, 56, 7, 146, 109, 19, 99, 38, 2208, 4, 38, 553, 123, 13, 418, 6, 61, 38, 460, 18913, 31, 123, 3357, 24, 4595, 6, 129, 2330, 11, 70, 209, 107, 4, 91, 851, 162, 10, 410, 6797, 683, 129, 7, 2851, 32388, 162, 13, 1996, 5, 220, 183, 4, 91, 3179, 7, 15658, 162, 10, 38460, 6797, 13, 130, 360, 600, 37, 1467, 157, 615, 14, 114, 38, 399, 75, 120, 5, 6150, 38, 956, 6, 38, 115, 1323, 66, 11, 143, 317, 8, 143, 86, 4, 407, 122, 6, 38, 218, 75, 2416, 123, 5988, 8, 619, 182, 27810, 4, 318, 47, 1394, 162, 59, 141, 24, 2653, 7, 697, 101, 14, 6, 38, 581, 1137, 47, 14, 24, 18, 7360, 4, 1876, 82, 619, 26913, 77, 51, 32, 25177, 15, 4, 38, 129, 6675, 77, 38, 1166, 49, 1652, 4, 252, 218, 75, 216, 99, 26760, 16, 8, 99, 24, 839, 7, 33, 7, 697, 19, 10, 40048, 54, 189, 905, 47, 159, 143, 2289, 4, 2, 2, 45641, 1907, 35, 35177, 3599, 4, 3394, 34, 57, 11166, 4812, 116, 20, 1623, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 100, 33, 57, 8, 202, 16, 11, 42, 1068, 11, 127, 284, 301, 4, 96, 1014, 6, 38, 1064, 11166, 4812, 8, 24, 362, 162, 209, 195, 107, 7, 671, 7, 2340, 301, 4, 96, 70, 209, 292, 107, 6, 38, 2220, 75, 56, 143, 23019, 3569, 50, 7654, 244, 31, 127, 1623, 4, 616, 38, 21, 11, 36021, 2400, 6, 37, 3776, 39, 301, 7, 5, 31848, 6, 11743, 8141, 66, 418, 13, 39, 36365, 101, 5651, 4, 38, 56, 7, 946, 80, 1315, 7, 582, 127, 1131, 4033, 187, 127, 474, 714, 399, 75, 1719, 5, 1042, 9, 127, 1416, 4, 38, 56, 7, 185, 80, 12, 1946, 6383, 227, 127, 1364, 298, 22833, 36, 33034, 6, 127, 320, 3504, 851, 162, 5537, 7, 304, 10, 28391, 5101, 3267, 11, 84, 3299, 18, 558, 13, 14, 43, 8, 127, 44, 48, 417, 4352, 97, 457, 17, 46, 7311, 59, 519, 7, 5555, 162, 7, 8, 31, 173, 25, 39, 512, 21, 341, 350, 747, 4, 286, 167, 6, 1207, 11, 5, 382, 6, 38, 619, 38, 240, 7, 3922, 103, 1254, 4, 96, 798, 6, 52, 218, 75, 2333, 33, 10, 2660, 284, 827, 1316, 6, 98, 38, 1705, 75, 304, 39, 418, 131, 38, 56, 7, 146, 109, 19, 99, 38, 2208, 4, 38, 553, 123, 13, 418, 6, 61, 38, 460, 18913, 31, 123, 3357, 24, 4595, 6, 129, 2330, 11, 70, 209, 107, 4, 91, 851, 162, 10, 410, 6797, 683, 129, 7, 2851, 32388, 162, 13, 1996, 5, 220, 183, 4, 91, 3179, 7, 15658, 162, 10, 38460, 6797, 13, 130, 360, 600, 37, 1467, 157, 615, 14, 114, 38, 399, 75, 120, 5, 6150, 38, 956, 6, 38, 115, 1323, 66, 11, 143, 317, 8, 143, 86, 4, 407, 122, 6, 38, 218, 75, 2416, 123, 5988, 8, 619, 182, 27810, 4, 318, 47, 1394, 162, 59, 141, 24, 2653, 7, 697, 101, 14, 6, 38, 581, 1137, 47, 14, 24, 18, 7360, 4, 1876, 82, 619, 26913, 77, 51, 32, 25177, 15, 4, 38, 129, 6675, 77, 38, 1166, 49, 1652, 4, 252, 218, 75, 216, 99, 26760, 16, 8, 99, 24, 839, 7, 33, 7, 697, 19, 10, 40048, 54, 189, 905, 47, 159, 143, 2289, 4, 2, 2, 45641, 1907, 35, 35177, 3599, 4, 3394, 34, 57, 11166, 4812, 116, 45, 615, 335, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], attention_mask=[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], token_type_ids=None, label=1)\n",
            "11/30/2020 19:55:49 - INFO - utils_multiple_choice -   Saving features into cached file ./data/cached_dev_RobertaTokenizer_512_quail\n",
            "11/30/2020 19:55:54 - INFO - filelock -   Lock 140122247134848 released on ./data/cached_dev_RobertaTokenizer_512_quail.lock\n",
            "11/30/2020 19:55:54 - INFO - __main__ -   *** Evaluate ***\n",
            "2737it [03:59, 12.81it/s]11/30/2020 19:58:03 - INFO - __main__ -   \n",
            "\n",
            "\n",
            "\n",
            "***** Custom_Dev_Eval Results *****\n",
            "11/30/2020 19:58:03 - INFO - __main__ -     eval_loss = 0.7006470561027527\n",
            "11/30/2020 19:58:03 - INFO - __main__ -     eval_acc = 0.7339975845410628\n",
            "11/30/2020 19:58:03 - INFO - utils_multiple_choice -   \n",
            "***** Reasoning Type Accuracies *****\n",
            "11/30/2020 19:58:03 - INFO - utils_multiple_choice -     Temporal_order = 70.37037037037037\n",
            "11/30/2020 19:58:03 - INFO - utils_multiple_choice -     Belief_states = 65.41666666666667\n",
            "11/30/2020 19:58:03 - INFO - utils_multiple_choice -     Character_identity = 85.6353591160221\n",
            "11/30/2020 19:58:03 - INFO - utils_multiple_choice -     Causality = 70.14388489208633\n",
            "11/30/2020 19:58:03 - INFO - utils_multiple_choice -     Entity_properties = 59.583333333333336\n",
            "11/30/2020 19:58:03 - INFO - utils_multiple_choice -     Event_duration = 66.94560669456067\n",
            "11/30/2020 19:58:03 - INFO - utils_multiple_choice -     Unanswerable = 84.86646884272997\n",
            "11/30/2020 19:58:03 - INFO - utils_multiple_choice -     Factual = 73.33333333333333\n",
            "11/30/2020 19:58:03 - INFO - utils_multiple_choice -     Subsequent_state = 65.41666666666667\n",
            "11/30/2020 19:58:03 - INFO - utils_multiple_choice -     Total = 73.39975845410628\n",
            "11/30/2020 19:58:03 - INFO - utils_multiple_choice -   \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "11/30/2020 19:58:03 - INFO - __main__ -   *** Evaluate ***\n",
            "18757it [24:50, 12.84it/s]11/30/2020 20:18:53 - INFO - __main__ -   \n",
            "\n",
            "\n",
            "\n",
            "***** Train_Eval Results *****\n",
            "11/30/2020 20:18:53 - INFO - __main__ -     eval_loss = 0.4922313392162323\n",
            "11/30/2020 20:18:53 - INFO - __main__ -     eval_acc = 0.8167857923156153\n",
            "11/30/2020 20:18:53 - INFO - utils_multiple_choice -   \n",
            "***** Reasoning Type Accuracies *****\n",
            "11/30/2020 20:18:53 - INFO - utils_multiple_choice -     Temporal_order = 73.74005305039788\n",
            "11/30/2020 20:18:53 - INFO - utils_multiple_choice -     Belief_states = 75.93582887700535\n",
            "11/30/2020 20:18:53 - INFO - utils_multiple_choice -     Character_identity = 92.08419804328491\n",
            "11/30/2020 20:18:53 - INFO - utils_multiple_choice -     Causality = 74.1175543649543\n",
            "11/30/2020 20:18:53 - INFO - utils_multiple_choice -     Entity_properties = 64.64379947229551\n",
            "11/30/2020 20:18:53 - INFO - utils_multiple_choice -     Event_duration = 68.86120996441281\n",
            "11/30/2020 20:18:53 - INFO - utils_multiple_choice -     Unanswerable = 95.55239864495684\n",
            "11/30/2020 20:18:53 - INFO - utils_multiple_choice -     Factual = 77.63713080168776\n",
            "11/30/2020 20:18:53 - INFO - utils_multiple_choice -     Subsequent_state = 70.90747330960853\n",
            "11/30/2020 20:18:53 - INFO - utils_multiple_choice -     Total = 81.67857923156153\n",
            "11/30/2020 20:18:53 - INFO - utils_multiple_choice -   \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "18758it [24:51, 12.58it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 2539\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: /content/wandb/run-20201130_174549-39k6tct2/logs/debug.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: /content/wandb/run-20201130_174549-39k6tct2/logs/debug-internal.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                  _step 1280\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                               _runtime 9185\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                             _timestamp 1606767534\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                             train/loss 0.6033\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                    train/learning_rate 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            train/epoch 1.99875\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                       train/total_flos 98085652975276032\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/loss █▇▅▅▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/learning_rate ████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           train/epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      train/total_flos ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mroberta-base--with_upsteam_reasoning_classification\u001b[0m: \u001b[34mhttps://wandb.ai/ngdodd/huggingface/runs/39k6tct2\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
